{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0f9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from torch_geometric.data import Dataset, download_url, DataLoader\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool, SAGPooling, GATConv, JumpingKnowledge, ASAPooling, GlobalAttention\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models_multimodal import *\n",
    "#from data_utils_multimodal import *\n",
    "import random\n",
    "from losses import *\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "import copy\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3a497",
   "metadata": {},
   "source": [
    "#### Use/Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac876920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 10 22:03:06 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla V100-SXM2-32GB           Off |   00000000:18:00.0 Off |                    0 |\r\n",
      "| N/A   46C    P0             63W /  300W |     900MiB /  32768MiB |      8%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2-32GB           Off |   00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0             55W /  300W |    6038MiB /  32768MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2-32GB           Off |   00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0             40W /  300W |       4MiB /  32768MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2-32GB           Off |   00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0             40W /  300W |       4MiB /  32768MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A   4042265      C   gmx_mpi                                       368MiB |\r\n",
      "|    0   N/A  N/A   4056972      C   ...4wq/.conda/envs/GNN_test/bin/python        528MiB |\r\n",
      "|    1   N/A  N/A   4056972      C   ...4wq/.conda/envs/GNN_test/bin/python       6034MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a82b1e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882d481",
   "metadata": {},
   "source": [
    "## Load DNA methylation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d9105",
   "metadata": {},
   "source": [
    "- TCGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e449bb8",
   "metadata": {},
   "source": [
    "#### Load selected CpGs info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6720c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CpG</th>\n",
       "      <th>c_index</th>\n",
       "      <th>c_index_adjusted_for_Demographics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>cg05225634</td>\n",
       "      <td>0.610713</td>\n",
       "      <td>0.660140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>cg26531551</td>\n",
       "      <td>0.602949</td>\n",
       "      <td>0.660140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>cg17019070</td>\n",
       "      <td>0.609546</td>\n",
       "      <td>0.660140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>cg00888336</td>\n",
       "      <td>0.608312</td>\n",
       "      <td>0.660140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40170</th>\n",
       "      <td>cg23471393</td>\n",
       "      <td>0.602029</td>\n",
       "      <td>0.669128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255689</th>\n",
       "      <td>cg09815377</td>\n",
       "      <td>0.603802</td>\n",
       "      <td>0.660140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255922</th>\n",
       "      <td>cg15135286</td>\n",
       "      <td>0.601961</td>\n",
       "      <td>0.679630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256684</th>\n",
       "      <td>cg13652008</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>0.679787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257026</th>\n",
       "      <td>cg20021506</td>\n",
       "      <td>0.641278</td>\n",
       "      <td>0.683670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258401</th>\n",
       "      <td>cg10939949</td>\n",
       "      <td>0.603555</td>\n",
       "      <td>0.673392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CpG   c_index  c_index_adjusted_for_Demographics\n",
       "5057    cg05225634  0.610713                           0.660140\n",
       "5139    cg26531551  0.602949                           0.660140\n",
       "8686    cg17019070  0.609546                           0.660140\n",
       "15595   cg00888336  0.608312                           0.660140\n",
       "40170   cg23471393  0.602029                           0.669128\n",
       "...            ...       ...                                ...\n",
       "255689  cg09815377  0.603802                           0.660140\n",
       "255922  cg15135286  0.601961                           0.679630\n",
       "256684  cg13652008  0.604789                           0.679787\n",
       "257026  cg20021506  0.641278                           0.683670\n",
       "258401  cg10939949  0.603555                           0.673392\n",
       "\n",
       "[134 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_index = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/DNAm/CpGs_c_indices.csv\",\n",
    "                         index_col=0)\n",
    "\n",
    "c_index_larger_06 = df_c_index[df_c_index['c_index'] >= 0.60].copy()\n",
    "c_index_larger_06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07fda22",
   "metadata": {},
   "source": [
    "#### Get a list that we are going to use for retriving necessary info from TCGA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0efb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bcr_patient_barcode',\n",
       " 'cg05225634',\n",
       " 'cg26531551',\n",
       " 'cg17019070',\n",
       " 'cg00888336',\n",
       " 'cg23471393',\n",
       " 'cg27504195',\n",
       " 'cg22840556',\n",
       " 'cg08111960',\n",
       " 'cg06742628',\n",
       " 'cg22301418',\n",
       " 'cg00675891',\n",
       " 'cg10002850',\n",
       " 'cg25940946',\n",
       " 'cg06572115',\n",
       " 'cg14845609',\n",
       " 'cg26472225',\n",
       " 'cg05956608',\n",
       " 'cg23459424',\n",
       " 'cg06985664',\n",
       " 'cg00691123',\n",
       " 'cg18118490',\n",
       " 'cg26443646',\n",
       " 'cg18396403',\n",
       " 'cg12147622',\n",
       " 'cg13823492',\n",
       " 'cg14153654',\n",
       " 'cg11876492',\n",
       " 'cg09315662',\n",
       " 'cg25768108',\n",
       " 'cg20337860',\n",
       " 'cg21795221',\n",
       " 'cg01798266',\n",
       " 'cg10655396',\n",
       " 'cg01971590',\n",
       " 'cg02101812',\n",
       " 'cg03216823',\n",
       " 'cg09816282',\n",
       " 'cg26640901',\n",
       " 'cg05103064',\n",
       " 'cg19091779',\n",
       " 'cg08818866',\n",
       " 'cg16264004',\n",
       " 'cg17280129',\n",
       " 'cg24144853',\n",
       " 'cg14781778',\n",
       " 'cg07921759',\n",
       " 'cg15519096',\n",
       " 'cg20078807',\n",
       " 'cg00221794',\n",
       " 'cg03147185',\n",
       " 'cg23316191',\n",
       " 'cg16734981',\n",
       " 'cg25545323',\n",
       " 'cg15227982',\n",
       " 'cg11897736',\n",
       " 'cg20148334',\n",
       " 'cg00613113',\n",
       " 'cg22230912',\n",
       " 'cg02347312',\n",
       " 'cg04118190',\n",
       " 'cg25978218',\n",
       " 'cg22277567',\n",
       " 'cg15085205',\n",
       " 'cg22495636',\n",
       " 'cg07339236',\n",
       " 'cg21820394',\n",
       " 'cg16903174',\n",
       " 'cg13261106',\n",
       " 'cg17268483',\n",
       " 'cg03268942',\n",
       " 'cg06038133',\n",
       " 'cg07367601',\n",
       " 'cg26655772',\n",
       " 'cg23989119',\n",
       " 'cg10087556',\n",
       " 'cg10803218',\n",
       " 'cg01765152',\n",
       " 'cg17250770',\n",
       " 'cg02858512',\n",
       " 'cg04747693',\n",
       " 'cg14568971',\n",
       " 'cg04921068',\n",
       " 'cg06579738',\n",
       " 'cg16151960',\n",
       " 'cg16223079',\n",
       " 'cg27482571',\n",
       " 'cg23550429',\n",
       " 'cg13677043',\n",
       " 'cg04314652',\n",
       " 'cg12895631',\n",
       " 'cg17173423',\n",
       " 'cg12242474',\n",
       " 'cg13209368',\n",
       " 'cg24847625',\n",
       " 'cg24506604',\n",
       " 'cg08326300',\n",
       " 'cg07084941',\n",
       " 'cg03006588',\n",
       " 'cg13979274',\n",
       " 'cg01734772',\n",
       " 'cg00936935',\n",
       " 'cg19253831',\n",
       " 'cg09075327',\n",
       " 'cg02220365',\n",
       " 'cg16306654',\n",
       " 'cg09293534',\n",
       " 'cg21949194',\n",
       " 'cg11009695',\n",
       " 'cg14114282',\n",
       " 'cg04280493',\n",
       " 'cg02854554',\n",
       " 'cg14071612',\n",
       " 'cg24557048',\n",
       " 'cg06256596',\n",
       " 'cg21333665',\n",
       " 'cg09121378',\n",
       " 'cg06703222',\n",
       " 'cg04951476',\n",
       " 'cg08860083',\n",
       " 'cg26180383',\n",
       " 'cg17897187',\n",
       " 'cg12546582',\n",
       " 'cg12753009',\n",
       " 'cg20893203',\n",
       " 'cg10495270',\n",
       " 'cg14945937',\n",
       " 'cg24810242',\n",
       " 'cg19832832',\n",
       " 'cg16936094',\n",
       " 'cg09815377',\n",
       " 'cg15135286',\n",
       " 'cg13652008',\n",
       " 'cg20021506',\n",
       " 'cg10939949']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CpG_list = c_index_larger_06['CpG'].tolist()\n",
    "Final_list_TCGA = ['bcr_patient_barcode'] + CpG_list\n",
    "Final_list_TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7cbd762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcr_patient_barcode</th>\n",
       "      <th>cg05225634</th>\n",
       "      <th>cg26531551</th>\n",
       "      <th>cg17019070</th>\n",
       "      <th>cg00888336</th>\n",
       "      <th>cg23471393</th>\n",
       "      <th>cg27504195</th>\n",
       "      <th>cg22840556</th>\n",
       "      <th>cg08111960</th>\n",
       "      <th>cg06742628</th>\n",
       "      <th>...</th>\n",
       "      <th>cg10495270</th>\n",
       "      <th>cg14945937</th>\n",
       "      <th>cg24810242</th>\n",
       "      <th>cg19832832</th>\n",
       "      <th>cg16936094</th>\n",
       "      <th>cg09815377</th>\n",
       "      <th>cg15135286</th>\n",
       "      <th>cg13652008</th>\n",
       "      <th>cg20021506</th>\n",
       "      <th>cg10939949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-2F-A9KO-01A-11D-A38H-05</th>\n",
       "      <td>TCGA-2F-A9KO</td>\n",
       "      <td>0.837784</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.951071</td>\n",
       "      <td>0.937605</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.944755</td>\n",
       "      <td>0.932084</td>\n",
       "      <td>0.603330</td>\n",
       "      <td>0.741496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151724</td>\n",
       "      <td>0.277698</td>\n",
       "      <td>0.750416</td>\n",
       "      <td>0.882155</td>\n",
       "      <td>0.600138</td>\n",
       "      <td>0.918051</td>\n",
       "      <td>0.664477</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.841669</td>\n",
       "      <td>0.890933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2F-A9KP-01A-11D-A38H-05</th>\n",
       "      <td>TCGA-2F-A9KP</td>\n",
       "      <td>0.899319</td>\n",
       "      <td>0.981357</td>\n",
       "      <td>0.988850</td>\n",
       "      <td>0.686949</td>\n",
       "      <td>0.807301</td>\n",
       "      <td>0.940359</td>\n",
       "      <td>0.979809</td>\n",
       "      <td>0.700172</td>\n",
       "      <td>0.393091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146651</td>\n",
       "      <td>0.300981</td>\n",
       "      <td>0.821290</td>\n",
       "      <td>0.722304</td>\n",
       "      <td>0.762778</td>\n",
       "      <td>0.925459</td>\n",
       "      <td>0.714181</td>\n",
       "      <td>0.705476</td>\n",
       "      <td>0.827397</td>\n",
       "      <td>0.821370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2F-A9KQ-01A-11D-A38H-05</th>\n",
       "      <td>TCGA-2F-A9KQ</td>\n",
       "      <td>0.982691</td>\n",
       "      <td>0.979576</td>\n",
       "      <td>0.988919</td>\n",
       "      <td>0.961668</td>\n",
       "      <td>0.947546</td>\n",
       "      <td>0.948513</td>\n",
       "      <td>0.984863</td>\n",
       "      <td>0.913353</td>\n",
       "      <td>0.632312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.146920</td>\n",
       "      <td>0.886119</td>\n",
       "      <td>0.833670</td>\n",
       "      <td>0.404773</td>\n",
       "      <td>0.712327</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>0.852450</td>\n",
       "      <td>0.876744</td>\n",
       "      <td>0.904580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2F-A9KR-01A-11D-A38H-05</th>\n",
       "      <td>TCGA-2F-A9KR</td>\n",
       "      <td>0.967681</td>\n",
       "      <td>0.980804</td>\n",
       "      <td>0.989286</td>\n",
       "      <td>0.963762</td>\n",
       "      <td>0.517386</td>\n",
       "      <td>0.606263</td>\n",
       "      <td>0.977937</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.553982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105844</td>\n",
       "      <td>0.195873</td>\n",
       "      <td>0.815282</td>\n",
       "      <td>0.862418</td>\n",
       "      <td>0.827871</td>\n",
       "      <td>0.695567</td>\n",
       "      <td>0.353144</td>\n",
       "      <td>0.342960</td>\n",
       "      <td>0.879421</td>\n",
       "      <td>0.898443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2F-A9KT-01A-11D-A38H-05</th>\n",
       "      <td>TCGA-2F-A9KT</td>\n",
       "      <td>0.966785</td>\n",
       "      <td>0.978021</td>\n",
       "      <td>0.987715</td>\n",
       "      <td>0.571738</td>\n",
       "      <td>0.560154</td>\n",
       "      <td>0.279121</td>\n",
       "      <td>0.977911</td>\n",
       "      <td>0.356490</td>\n",
       "      <td>0.594080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184155</td>\n",
       "      <td>0.277295</td>\n",
       "      <td>0.606930</td>\n",
       "      <td>0.804098</td>\n",
       "      <td>0.929534</td>\n",
       "      <td>0.947407</td>\n",
       "      <td>0.523803</td>\n",
       "      <td>0.551288</td>\n",
       "      <td>0.774564</td>\n",
       "      <td>0.893740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-ZF-AA56-01A-31D-A392-05</th>\n",
       "      <td>TCGA-ZF-AA56</td>\n",
       "      <td>0.705956</td>\n",
       "      <td>0.970438</td>\n",
       "      <td>0.912332</td>\n",
       "      <td>0.944262</td>\n",
       "      <td>0.830663</td>\n",
       "      <td>0.911957</td>\n",
       "      <td>0.867241</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.656783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104621</td>\n",
       "      <td>0.207807</td>\n",
       "      <td>0.711217</td>\n",
       "      <td>0.849144</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>0.947649</td>\n",
       "      <td>0.427439</td>\n",
       "      <td>0.418104</td>\n",
       "      <td>0.795927</td>\n",
       "      <td>0.794004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-ZF-AA58-01A-12D-A42F-05</th>\n",
       "      <td>TCGA-ZF-AA58</td>\n",
       "      <td>0.790278</td>\n",
       "      <td>0.977962</td>\n",
       "      <td>0.990405</td>\n",
       "      <td>0.964094</td>\n",
       "      <td>0.818960</td>\n",
       "      <td>0.892965</td>\n",
       "      <td>0.981020</td>\n",
       "      <td>0.529384</td>\n",
       "      <td>0.744260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139107</td>\n",
       "      <td>0.217533</td>\n",
       "      <td>0.706081</td>\n",
       "      <td>0.863055</td>\n",
       "      <td>0.868221</td>\n",
       "      <td>0.960161</td>\n",
       "      <td>0.515115</td>\n",
       "      <td>0.545605</td>\n",
       "      <td>0.708026</td>\n",
       "      <td>0.904428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-ZF-AA5H-01A-11D-A392-05</th>\n",
       "      <td>TCGA-ZF-AA5H</td>\n",
       "      <td>0.542398</td>\n",
       "      <td>0.293778</td>\n",
       "      <td>0.494823</td>\n",
       "      <td>0.411380</td>\n",
       "      <td>0.283506</td>\n",
       "      <td>0.718350</td>\n",
       "      <td>0.890105</td>\n",
       "      <td>0.458030</td>\n",
       "      <td>0.119492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165180</td>\n",
       "      <td>0.187344</td>\n",
       "      <td>0.407292</td>\n",
       "      <td>0.625627</td>\n",
       "      <td>0.914021</td>\n",
       "      <td>0.949705</td>\n",
       "      <td>0.397196</td>\n",
       "      <td>0.446391</td>\n",
       "      <td>0.434656</td>\n",
       "      <td>0.902235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-ZF-AA5N-01A-11D-A42F-05</th>\n",
       "      <td>TCGA-ZF-AA5N</td>\n",
       "      <td>0.717706</td>\n",
       "      <td>0.853315</td>\n",
       "      <td>0.979398</td>\n",
       "      <td>0.538592</td>\n",
       "      <td>0.207609</td>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.242520</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078221</td>\n",
       "      <td>0.470969</td>\n",
       "      <td>0.690921</td>\n",
       "      <td>0.821566</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>0.941019</td>\n",
       "      <td>0.679370</td>\n",
       "      <td>0.760047</td>\n",
       "      <td>0.535489</td>\n",
       "      <td>0.357302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-ZF-AA5P-01A-11D-A392-05</th>\n",
       "      <td>TCGA-ZF-AA5P</td>\n",
       "      <td>0.747547</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.982908</td>\n",
       "      <td>0.604229</td>\n",
       "      <td>0.718475</td>\n",
       "      <td>0.776047</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>0.650314</td>\n",
       "      <td>0.763782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262515</td>\n",
       "      <td>0.337282</td>\n",
       "      <td>0.759699</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.738162</td>\n",
       "      <td>0.903660</td>\n",
       "      <td>0.499415</td>\n",
       "      <td>0.563790</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.845393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bcr_patient_barcode  cg05225634  cg26531551  \\\n",
       "TCGA-2F-A9KO-01A-11D-A38H-05        TCGA-2F-A9KO    0.837784    0.981013   \n",
       "TCGA-2F-A9KP-01A-11D-A38H-05        TCGA-2F-A9KP    0.899319    0.981357   \n",
       "TCGA-2F-A9KQ-01A-11D-A38H-05        TCGA-2F-A9KQ    0.982691    0.979576   \n",
       "TCGA-2F-A9KR-01A-11D-A38H-05        TCGA-2F-A9KR    0.967681    0.980804   \n",
       "TCGA-2F-A9KT-01A-11D-A38H-05        TCGA-2F-A9KT    0.966785    0.978021   \n",
       "...                                          ...         ...         ...   \n",
       "TCGA-ZF-AA56-01A-31D-A392-05        TCGA-ZF-AA56    0.705956    0.970438   \n",
       "TCGA-ZF-AA58-01A-12D-A42F-05        TCGA-ZF-AA58    0.790278    0.977962   \n",
       "TCGA-ZF-AA5H-01A-11D-A392-05        TCGA-ZF-AA5H    0.542398    0.293778   \n",
       "TCGA-ZF-AA5N-01A-11D-A42F-05        TCGA-ZF-AA5N    0.717706    0.853315   \n",
       "TCGA-ZF-AA5P-01A-11D-A392-05        TCGA-ZF-AA5P    0.747547    0.967949   \n",
       "\n",
       "                              cg17019070  cg00888336  cg23471393  cg27504195  \\\n",
       "TCGA-2F-A9KO-01A-11D-A38H-05    0.951071    0.937605    0.749643    0.944755   \n",
       "TCGA-2F-A9KP-01A-11D-A38H-05    0.988850    0.686949    0.807301    0.940359   \n",
       "TCGA-2F-A9KQ-01A-11D-A38H-05    0.988919    0.961668    0.947546    0.948513   \n",
       "TCGA-2F-A9KR-01A-11D-A38H-05    0.989286    0.963762    0.517386    0.606263   \n",
       "TCGA-2F-A9KT-01A-11D-A38H-05    0.987715    0.571738    0.560154    0.279121   \n",
       "...                                  ...         ...         ...         ...   \n",
       "TCGA-ZF-AA56-01A-31D-A392-05    0.912332    0.944262    0.830663    0.911957   \n",
       "TCGA-ZF-AA58-01A-12D-A42F-05    0.990405    0.964094    0.818960    0.892965   \n",
       "TCGA-ZF-AA5H-01A-11D-A392-05    0.494823    0.411380    0.283506    0.718350   \n",
       "TCGA-ZF-AA5N-01A-11D-A42F-05    0.979398    0.538592    0.207609    0.146909   \n",
       "TCGA-ZF-AA5P-01A-11D-A392-05    0.982908    0.604229    0.718475    0.776047   \n",
       "\n",
       "                              cg22840556  cg08111960  cg06742628  ...  \\\n",
       "TCGA-2F-A9KO-01A-11D-A38H-05    0.932084    0.603330    0.741496  ...   \n",
       "TCGA-2F-A9KP-01A-11D-A38H-05    0.979809    0.700172    0.393091  ...   \n",
       "TCGA-2F-A9KQ-01A-11D-A38H-05    0.984863    0.913353    0.632312  ...   \n",
       "TCGA-2F-A9KR-01A-11D-A38H-05    0.977937    0.789238    0.553982  ...   \n",
       "TCGA-2F-A9KT-01A-11D-A38H-05    0.977911    0.356490    0.594080  ...   \n",
       "...                                  ...         ...         ...  ...   \n",
       "TCGA-ZF-AA56-01A-31D-A392-05    0.867241    0.443131    0.656783  ...   \n",
       "TCGA-ZF-AA58-01A-12D-A42F-05    0.981020    0.529384    0.744260  ...   \n",
       "TCGA-ZF-AA5H-01A-11D-A392-05    0.890105    0.458030    0.119492  ...   \n",
       "TCGA-ZF-AA5N-01A-11D-A42F-05    0.774580    0.242520    0.236341  ...   \n",
       "TCGA-ZF-AA5P-01A-11D-A392-05    0.975063    0.650314    0.763782  ...   \n",
       "\n",
       "                              cg10495270  cg14945937  cg24810242  cg19832832  \\\n",
       "TCGA-2F-A9KO-01A-11D-A38H-05    0.151724    0.277698    0.750416    0.882155   \n",
       "TCGA-2F-A9KP-01A-11D-A38H-05    0.146651    0.300981    0.821290    0.722304   \n",
       "TCGA-2F-A9KQ-01A-11D-A38H-05    0.079379    0.146920    0.886119    0.833670   \n",
       "TCGA-2F-A9KR-01A-11D-A38H-05    0.105844    0.195873    0.815282    0.862418   \n",
       "TCGA-2F-A9KT-01A-11D-A38H-05    0.184155    0.277295    0.606930    0.804098   \n",
       "...                                  ...         ...         ...         ...   \n",
       "TCGA-ZF-AA56-01A-31D-A392-05    0.104621    0.207807    0.711217    0.849144   \n",
       "TCGA-ZF-AA58-01A-12D-A42F-05    0.139107    0.217533    0.706081    0.863055   \n",
       "TCGA-ZF-AA5H-01A-11D-A392-05    0.165180    0.187344    0.407292    0.625627   \n",
       "TCGA-ZF-AA5N-01A-11D-A42F-05    0.078221    0.470969    0.690921    0.821566   \n",
       "TCGA-ZF-AA5P-01A-11D-A392-05    0.262515    0.337282    0.759699    0.822034   \n",
       "\n",
       "                              cg16936094  cg09815377  cg15135286  cg13652008  \\\n",
       "TCGA-2F-A9KO-01A-11D-A38H-05    0.600138    0.918051    0.664477    0.773110   \n",
       "TCGA-2F-A9KP-01A-11D-A38H-05    0.762778    0.925459    0.714181    0.705476   \n",
       "TCGA-2F-A9KQ-01A-11D-A38H-05    0.404773    0.712327    0.814167    0.852450   \n",
       "TCGA-2F-A9KR-01A-11D-A38H-05    0.827871    0.695567    0.353144    0.342960   \n",
       "TCGA-2F-A9KT-01A-11D-A38H-05    0.929534    0.947407    0.523803    0.551288   \n",
       "...                                  ...         ...         ...         ...   \n",
       "TCGA-ZF-AA56-01A-31D-A392-05    0.806734    0.947649    0.427439    0.418104   \n",
       "TCGA-ZF-AA58-01A-12D-A42F-05    0.868221    0.960161    0.515115    0.545605   \n",
       "TCGA-ZF-AA5H-01A-11D-A392-05    0.914021    0.949705    0.397196    0.446391   \n",
       "TCGA-ZF-AA5N-01A-11D-A42F-05    0.950479    0.941019    0.679370    0.760047   \n",
       "TCGA-ZF-AA5P-01A-11D-A392-05    0.738162    0.903660    0.499415    0.563790   \n",
       "\n",
       "                              cg20021506  cg10939949  \n",
       "TCGA-2F-A9KO-01A-11D-A38H-05    0.841669    0.890933  \n",
       "TCGA-2F-A9KP-01A-11D-A38H-05    0.827397    0.821370  \n",
       "TCGA-2F-A9KQ-01A-11D-A38H-05    0.876744    0.904580  \n",
       "TCGA-2F-A9KR-01A-11D-A38H-05    0.879421    0.898443  \n",
       "TCGA-2F-A9KT-01A-11D-A38H-05    0.774564    0.893740  \n",
       "...                                  ...         ...  \n",
       "TCGA-ZF-AA56-01A-31D-A392-05    0.795927    0.794004  \n",
       "TCGA-ZF-AA58-01A-12D-A42F-05    0.708026    0.904428  \n",
       "TCGA-ZF-AA5H-01A-11D-A392-05    0.434656    0.902235  \n",
       "TCGA-ZF-AA5N-01A-11D-A42F-05    0.535489    0.357302  \n",
       "TCGA-ZF-AA5P-01A-11D-A392-05    0.751020    0.845393  \n",
       "\n",
       "[411 rows x 135 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAm_TCGA = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/DNAm/betas_filtered.csv\", index_col=0)\n",
    "\n",
    "DNAm_TCGA['Patient ID'] = DNAm_TCGA['Patient ID'].str.slice(0, 12) \n",
    "DNAm_TCGA = DNAm_TCGA.drop_duplicates(subset=['Patient ID'])\n",
    "DNAm_TCGA = DNAm_TCGA.drop(['vital_status', 'survival_time'], axis=1)\n",
    "DNAm_TCGA.rename(columns={'Patient ID':'bcr_patient_barcode'}, inplace=True)\n",
    "\n",
    "# Select required CpGs\n",
    "DNAm_TCGA = DNAm_TCGA[Final_list_TCGA]\n",
    "\n",
    "DNAm_TCGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de1a1d",
   "metadata": {},
   "source": [
    "- DH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2030c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/q/f0034wq/.conda/envs/GNN_test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2878: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFPE.DNA.ID</th>\n",
       "      <th>cg05225634</th>\n",
       "      <th>cg26531551</th>\n",
       "      <th>cg17019070</th>\n",
       "      <th>cg00888336</th>\n",
       "      <th>cg23471393</th>\n",
       "      <th>cg27504195</th>\n",
       "      <th>cg22840556</th>\n",
       "      <th>cg08111960</th>\n",
       "      <th>cg06742628</th>\n",
       "      <th>...</th>\n",
       "      <th>cg10495270</th>\n",
       "      <th>cg14945937</th>\n",
       "      <th>cg24810242</th>\n",
       "      <th>cg19832832</th>\n",
       "      <th>cg16936094</th>\n",
       "      <th>cg09815377</th>\n",
       "      <th>cg15135286</th>\n",
       "      <th>cg13652008</th>\n",
       "      <th>cg20021506</th>\n",
       "      <th>cg10939949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLD050</td>\n",
       "      <td>0.877704</td>\n",
       "      <td>0.786659</td>\n",
       "      <td>0.839499</td>\n",
       "      <td>0.865888</td>\n",
       "      <td>0.728421</td>\n",
       "      <td>0.808506</td>\n",
       "      <td>0.852304</td>\n",
       "      <td>0.707109</td>\n",
       "      <td>0.515407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207127</td>\n",
       "      <td>0.282681</td>\n",
       "      <td>0.842091</td>\n",
       "      <td>0.903338</td>\n",
       "      <td>0.616532</td>\n",
       "      <td>0.849071</td>\n",
       "      <td>0.747588</td>\n",
       "      <td>0.764547</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.814271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>0.903778</td>\n",
       "      <td>0.867272</td>\n",
       "      <td>0.900368</td>\n",
       "      <td>0.869694</td>\n",
       "      <td>0.731232</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.856771</td>\n",
       "      <td>0.601102</td>\n",
       "      <td>0.701621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128019</td>\n",
       "      <td>0.202235</td>\n",
       "      <td>0.904845</td>\n",
       "      <td>0.836256</td>\n",
       "      <td>0.740190</td>\n",
       "      <td>0.903272</td>\n",
       "      <td>0.773686</td>\n",
       "      <td>0.888653</td>\n",
       "      <td>0.906822</td>\n",
       "      <td>0.925455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>0.902834</td>\n",
       "      <td>0.867456</td>\n",
       "      <td>0.917442</td>\n",
       "      <td>0.891382</td>\n",
       "      <td>0.803706</td>\n",
       "      <td>0.879241</td>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.744796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>0.899061</td>\n",
       "      <td>0.898545</td>\n",
       "      <td>0.428867</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.810281</td>\n",
       "      <td>0.878705</td>\n",
       "      <td>0.886499</td>\n",
       "      <td>0.922573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BLD046</td>\n",
       "      <td>0.754699</td>\n",
       "      <td>0.819857</td>\n",
       "      <td>0.866117</td>\n",
       "      <td>0.840502</td>\n",
       "      <td>0.686702</td>\n",
       "      <td>0.798214</td>\n",
       "      <td>0.886572</td>\n",
       "      <td>0.533913</td>\n",
       "      <td>0.645897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299376</td>\n",
       "      <td>0.247461</td>\n",
       "      <td>0.843026</td>\n",
       "      <td>0.872031</td>\n",
       "      <td>0.766565</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.628902</td>\n",
       "      <td>0.664677</td>\n",
       "      <td>0.860748</td>\n",
       "      <td>0.879639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BLD080</td>\n",
       "      <td>0.893368</td>\n",
       "      <td>0.856649</td>\n",
       "      <td>0.918326</td>\n",
       "      <td>0.888892</td>\n",
       "      <td>0.808537</td>\n",
       "      <td>0.860444</td>\n",
       "      <td>0.893033</td>\n",
       "      <td>0.830059</td>\n",
       "      <td>0.700348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134661</td>\n",
       "      <td>0.144009</td>\n",
       "      <td>0.869246</td>\n",
       "      <td>0.890036</td>\n",
       "      <td>0.285618</td>\n",
       "      <td>0.766759</td>\n",
       "      <td>0.756864</td>\n",
       "      <td>0.805967</td>\n",
       "      <td>0.882804</td>\n",
       "      <td>0.943498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BLD048</td>\n",
       "      <td>0.879058</td>\n",
       "      <td>0.834640</td>\n",
       "      <td>0.912846</td>\n",
       "      <td>0.897745</td>\n",
       "      <td>0.711923</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.910825</td>\n",
       "      <td>0.758210</td>\n",
       "      <td>0.535456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095472</td>\n",
       "      <td>0.114265</td>\n",
       "      <td>0.879650</td>\n",
       "      <td>0.840989</td>\n",
       "      <td>0.308320</td>\n",
       "      <td>0.666527</td>\n",
       "      <td>0.793871</td>\n",
       "      <td>0.811860</td>\n",
       "      <td>0.737637</td>\n",
       "      <td>0.626453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>BLD075</td>\n",
       "      <td>0.911727</td>\n",
       "      <td>0.821464</td>\n",
       "      <td>0.893815</td>\n",
       "      <td>0.871907</td>\n",
       "      <td>0.812076</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>0.894164</td>\n",
       "      <td>0.754496</td>\n",
       "      <td>0.571225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082056</td>\n",
       "      <td>0.167338</td>\n",
       "      <td>0.881925</td>\n",
       "      <td>0.890591</td>\n",
       "      <td>0.581825</td>\n",
       "      <td>0.869454</td>\n",
       "      <td>0.831428</td>\n",
       "      <td>0.718227</td>\n",
       "      <td>0.873276</td>\n",
       "      <td>0.888269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>BLD024</td>\n",
       "      <td>0.912582</td>\n",
       "      <td>0.845036</td>\n",
       "      <td>0.917029</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>0.825074</td>\n",
       "      <td>0.867046</td>\n",
       "      <td>0.873076</td>\n",
       "      <td>0.846477</td>\n",
       "      <td>0.676634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147564</td>\n",
       "      <td>0.188355</td>\n",
       "      <td>0.900222</td>\n",
       "      <td>0.873125</td>\n",
       "      <td>0.262840</td>\n",
       "      <td>0.816359</td>\n",
       "      <td>0.784172</td>\n",
       "      <td>0.826778</td>\n",
       "      <td>0.858617</td>\n",
       "      <td>0.894181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>BLD094</td>\n",
       "      <td>0.914064</td>\n",
       "      <td>0.847266</td>\n",
       "      <td>0.919755</td>\n",
       "      <td>0.859747</td>\n",
       "      <td>0.787815</td>\n",
       "      <td>0.870577</td>\n",
       "      <td>0.898136</td>\n",
       "      <td>0.814811</td>\n",
       "      <td>0.569457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193725</td>\n",
       "      <td>0.160923</td>\n",
       "      <td>0.843627</td>\n",
       "      <td>0.858990</td>\n",
       "      <td>0.376555</td>\n",
       "      <td>0.708235</td>\n",
       "      <td>0.731184</td>\n",
       "      <td>0.785713</td>\n",
       "      <td>0.919905</td>\n",
       "      <td>0.904419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>BLD014</td>\n",
       "      <td>0.887401</td>\n",
       "      <td>0.798438</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.847837</td>\n",
       "      <td>0.746386</td>\n",
       "      <td>0.755309</td>\n",
       "      <td>0.859859</td>\n",
       "      <td>0.739173</td>\n",
       "      <td>0.741039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141010</td>\n",
       "      <td>0.153693</td>\n",
       "      <td>0.845629</td>\n",
       "      <td>0.919391</td>\n",
       "      <td>0.223388</td>\n",
       "      <td>0.681099</td>\n",
       "      <td>0.906134</td>\n",
       "      <td>0.895079</td>\n",
       "      <td>0.871785</td>\n",
       "      <td>0.925355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FFPE.DNA.ID  cg05225634  cg26531551  cg17019070  cg00888336  cg23471393  \\\n",
       "0        BLD050    0.877704    0.786659    0.839499    0.865888    0.728421   \n",
       "1        BLD043    0.903778    0.867272    0.900368    0.869694    0.731232   \n",
       "3        BLD061    0.902834    0.867456    0.917442    0.891382    0.803706   \n",
       "5        BLD046    0.754699    0.819857    0.866117    0.840502    0.686702   \n",
       "6        BLD080    0.893368    0.856649    0.918326    0.888892    0.808537   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "136      BLD048    0.879058    0.834640    0.912846    0.897745    0.711923   \n",
       "137      BLD075    0.911727    0.821464    0.893815    0.871907    0.812076   \n",
       "138      BLD024    0.912582    0.845036    0.917029    0.838250    0.825074   \n",
       "139      BLD094    0.914064    0.847266    0.919755    0.859747    0.787815   \n",
       "140      BLD014    0.887401    0.798438    0.849635    0.847837    0.746386   \n",
       "\n",
       "     cg27504195  cg22840556  cg08111960  cg06742628  ...  cg10495270  \\\n",
       "0      0.808506    0.852304    0.707109    0.515407  ...    0.207127   \n",
       "1      0.856934    0.856771    0.601102    0.701621  ...    0.128019   \n",
       "3      0.879241    0.898172    0.827605    0.744796  ...    0.133984   \n",
       "5      0.798214    0.886572    0.533913    0.645897  ...    0.299376   \n",
       "6      0.860444    0.893033    0.830059    0.700348  ...    0.134661   \n",
       "..          ...         ...         ...         ...  ...         ...   \n",
       "136    0.824190    0.910825    0.758210    0.535456  ...    0.095472   \n",
       "137    0.862533    0.894164    0.754496    0.571225  ...    0.082056   \n",
       "138    0.867046    0.873076    0.846477    0.676634  ...    0.147564   \n",
       "139    0.870577    0.898136    0.814811    0.569457  ...    0.193725   \n",
       "140    0.755309    0.859859    0.739173    0.741039  ...    0.141010   \n",
       "\n",
       "     cg14945937  cg24810242  cg19832832  cg16936094  cg09815377  cg15135286  \\\n",
       "0      0.282681    0.842091    0.903338    0.616532    0.849071    0.747588   \n",
       "1      0.202235    0.904845    0.836256    0.740190    0.903272    0.773686   \n",
       "3      0.284466    0.899061    0.898545    0.428867    0.860190    0.810281   \n",
       "5      0.247461    0.843026    0.872031    0.766565    0.903650    0.628902   \n",
       "6      0.144009    0.869246    0.890036    0.285618    0.766759    0.756864   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "136    0.114265    0.879650    0.840989    0.308320    0.666527    0.793871   \n",
       "137    0.167338    0.881925    0.890591    0.581825    0.869454    0.831428   \n",
       "138    0.188355    0.900222    0.873125    0.262840    0.816359    0.784172   \n",
       "139    0.160923    0.843627    0.858990    0.376555    0.708235    0.731184   \n",
       "140    0.153693    0.845629    0.919391    0.223388    0.681099    0.906134   \n",
       "\n",
       "     cg13652008  cg20021506  cg10939949  \n",
       "0      0.764547    0.852336    0.814271  \n",
       "1      0.888653    0.906822    0.925455  \n",
       "3      0.878705    0.886499    0.922573  \n",
       "5      0.664677    0.860748    0.879639  \n",
       "6      0.805967    0.882804    0.943498  \n",
       "..          ...         ...         ...  \n",
       "136    0.811860    0.737637    0.626453  \n",
       "137    0.718227    0.873276    0.888269  \n",
       "138    0.826778    0.858617    0.894181  \n",
       "139    0.785713    0.919905    0.904419  \n",
       "140    0.895079    0.871785    0.925355  \n",
       "\n",
       "[84 rows x 135 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAm_df = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/Bladder_DNAm_HiTIMED/Total_88_subjects_WSI_Pheno_DNAm.csv\")\n",
    "DNAm_df = DNAm_df.dropna(subset=['file_name']) # Remove subjects without WSI files\n",
    "DNAm_df['TenYearSurv'] = DNAm_df['TenYearSurv'].transform(lambda x: x*30)\n",
    "DNAm_df['TenYearRFS'] = DNAm_df['TenYearRFS'].transform(lambda x: x*30)\n",
    "\n",
    "# Select columns that we are going to use\n",
    "Final_list_DH = ['FFPE.DNA.ID'] + CpG_list\n",
    "\n",
    "DNAm_df = DNAm_df[Final_list_DH]\n",
    "DNAm_df = DNAm_df.drop_duplicates()\n",
    "DNAm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab05ad",
   "metadata": {},
   "source": [
    "## Load HiTIMED Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477328ce",
   "metadata": {},
   "source": [
    "- TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4205b711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcr_patient_barcode</th>\n",
       "      <th>Tumor</th>\n",
       "      <th>Endothelial</th>\n",
       "      <th>Epithelial</th>\n",
       "      <th>Stromal</th>\n",
       "      <th>Bnv</th>\n",
       "      <th>Bmem</th>\n",
       "      <th>CD4nv</th>\n",
       "      <th>CD4mem</th>\n",
       "      <th>Treg</th>\n",
       "      <th>CD8nv</th>\n",
       "      <th>CD8mem</th>\n",
       "      <th>Mono</th>\n",
       "      <th>DC</th>\n",
       "      <th>NK</th>\n",
       "      <th>Bas</th>\n",
       "      <th>Eos</th>\n",
       "      <th>Neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>TCGA-2F-A9KO</td>\n",
       "      <td>59.496435</td>\n",
       "      <td>3.061159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.502154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.404918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.838353</td>\n",
       "      <td>1.508797</td>\n",
       "      <td>0.220441</td>\n",
       "      <td>14.009471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.085653</td>\n",
       "      <td>1.872621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>TCGA-2F-A9KP</td>\n",
       "      <td>77.559634</td>\n",
       "      <td>6.398107</td>\n",
       "      <td>0.079715</td>\n",
       "      <td>3.772901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.361156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237921</td>\n",
       "      <td>1.102857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.418432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.673416</td>\n",
       "      <td>1.764794</td>\n",
       "      <td>0.858058</td>\n",
       "      <td>1.773009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>TCGA-2F-A9KQ</td>\n",
       "      <td>88.570479</td>\n",
       "      <td>1.588447</td>\n",
       "      <td>4.246925</td>\n",
       "      <td>1.060853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.533296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>TCGA-2F-A9KR</td>\n",
       "      <td>82.046167</td>\n",
       "      <td>5.968081</td>\n",
       "      <td>7.698402</td>\n",
       "      <td>0.615840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.403660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884687</td>\n",
       "      <td>0.383162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>TCGA-2F-A9KT</td>\n",
       "      <td>58.215044</td>\n",
       "      <td>5.653344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.275757</td>\n",
       "      <td>3.080379</td>\n",
       "      <td>6.837927</td>\n",
       "      <td>3.283591</td>\n",
       "      <td>1.241541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.744043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TCGA-ZF-AA56</td>\n",
       "      <td>56.032282</td>\n",
       "      <td>6.010198</td>\n",
       "      <td>6.312032</td>\n",
       "      <td>4.271523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.938654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.126088</td>\n",
       "      <td>1.146210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.198236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.094663</td>\n",
       "      <td>0.699691</td>\n",
       "      <td>0.464068</td>\n",
       "      <td>1.607831</td>\n",
       "      <td>3.098525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TCGA-ZF-AA58</td>\n",
       "      <td>45.918822</td>\n",
       "      <td>4.505245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.165651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.744179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.206508</td>\n",
       "      <td>5.394365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.456026</td>\n",
       "      <td>3.687531</td>\n",
       "      <td>0.099868</td>\n",
       "      <td>1.865883</td>\n",
       "      <td>5.884833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>TCGA-ZF-AA5H</td>\n",
       "      <td>73.982262</td>\n",
       "      <td>1.632842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.839488</td>\n",
       "      <td>2.697143</td>\n",
       "      <td>2.343099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.801079</td>\n",
       "      <td>9.184619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.294674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>TCGA-ZF-AA5N</td>\n",
       "      <td>72.724511</td>\n",
       "      <td>1.721571</td>\n",
       "      <td>0.495669</td>\n",
       "      <td>7.179986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.173312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.358315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.327464</td>\n",
       "      <td>4.807795</td>\n",
       "      <td>0.311276</td>\n",
       "      <td>0.297592</td>\n",
       "      <td>3.602511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TCGA-ZF-AA5P</td>\n",
       "      <td>37.746373</td>\n",
       "      <td>14.380607</td>\n",
       "      <td>2.964540</td>\n",
       "      <td>9.457298</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>9.389015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297206</td>\n",
       "      <td>0.325339</td>\n",
       "      <td>1.365966</td>\n",
       "      <td>9.377219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.249905</td>\n",
       "      <td>1.638611</td>\n",
       "      <td>0.661854</td>\n",
       "      <td>0.318850</td>\n",
       "      <td>1.925518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bcr_patient_barcode      Tumor  Endothelial  Epithelial   Stromal  \\\n",
       "277        TCGA-2F-A9KO  59.496435     3.061159    0.000000  4.502154   \n",
       "96         TCGA-2F-A9KP  77.559634     6.398107    0.079715  3.772901   \n",
       "301        TCGA-2F-A9KQ  88.570479     1.588447    4.246925  1.060853   \n",
       "191        TCGA-2F-A9KR  82.046167     5.968081    7.698402  0.615840   \n",
       "81         TCGA-2F-A9KT  58.215044     5.653344    0.000000  6.824711   \n",
       "..                  ...        ...          ...         ...       ...   \n",
       "53         TCGA-ZF-AA56  56.032282     6.010198    6.312032  4.271523   \n",
       "41         TCGA-ZF-AA58  45.918822     4.505245    0.000000  9.165651   \n",
       "79         TCGA-ZF-AA5H  73.982262     1.632842    0.000000  6.839488   \n",
       "218        TCGA-ZF-AA5N  72.724511     1.721571    0.495669  7.179986   \n",
       "91         TCGA-ZF-AA5P  37.746373    14.380607    2.964540  9.457298   \n",
       "\n",
       "          Bnv      Bmem  CD4nv    CD4mem      Treg     CD8nv     CD8mem  \\\n",
       "277  0.000000  8.404918    0.0  1.838353  1.508797  0.220441  14.009471   \n",
       "96   0.000000  2.361156    0.0  0.237921  1.102857  0.000000   1.418432   \n",
       "301  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   0.000000   \n",
       "191  0.000000  0.000000    0.0  2.403660  0.000000  0.884687   0.383162   \n",
       "81   0.000000  0.843665    0.0  0.000000  0.000000  0.000000   3.275757   \n",
       "..        ...       ...    ...       ...       ...       ...        ...   \n",
       "53   0.000000  6.938654    0.0  3.126088  1.146210  0.000000   3.198236   \n",
       "41   0.000000  3.744179    0.0  4.206508  5.394365  0.000000   1.071090   \n",
       "79   2.697143  2.343099    0.0  1.801079  9.184619  0.000000   1.294674   \n",
       "218  0.000000  4.173312    0.0  0.000000  1.358315  0.000000   0.000000   \n",
       "91   0.901700  9.389015    0.0  0.297206  0.325339  1.365966   9.377219   \n",
       "\n",
       "         Mono         DC        NK       Bas       Eos        Neu  \n",
       "277  0.000000   5.085653  1.872621  0.000000  0.000000   0.000000  \n",
       "96   0.000000   2.673416  1.764794  0.858058  1.773009   0.000000  \n",
       "301  0.000000   0.000000  0.000000  4.533296  0.000000   0.000000  \n",
       "191  0.000000   0.000000  0.000000  0.000000  0.000000   0.000000  \n",
       "81   3.080379   6.837927  3.283591  1.241541  0.000000  10.744043  \n",
       "..        ...        ...       ...       ...       ...        ...  \n",
       "53   0.000000   7.094663  0.699691  0.464068  1.607831   3.098525  \n",
       "41   0.000000  14.456026  3.687531  0.099868  1.865883   5.884833  \n",
       "79   0.000000   0.000000  0.224793  0.000000  0.000000   0.000000  \n",
       "218  0.000000   3.327464  4.807795  0.311276  0.297592   3.602511  \n",
       "91   0.000000   9.249905  1.638611  0.661854  0.318850   1.925518  \n",
       "\n",
       "[395 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiTIMED_TCGA_df = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/HiTIMED/TCGA_HiTIMED_with_Survival_20240509.csv\",\n",
    "                             index_col=0)\n",
    "HiTIMED_TCGA_df = HiTIMED_TCGA_df.drop_duplicates(subset=['submitter_id'])\n",
    "HiTIMED_TCGA_df = HiTIMED_TCGA_df.drop(['vital_status', 'survival_time'], axis=1)\n",
    "HiTIMED_TCGA_df.rename(columns={'submitter_id':'bcr_patient_barcode'}, inplace=True)\n",
    "\n",
    "HiTIMED_TCGA_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e67420",
   "metadata": {},
   "source": [
    "- DH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90717c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFPE.DNA.ID</th>\n",
       "      <th>Blood.Sample.ID</th>\n",
       "      <th>ChIP_ID_Blood</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Grade2</th>\n",
       "      <th>Muscle_Invasive</th>\n",
       "      <th>BCG</th>\n",
       "      <th>...</th>\n",
       "      <th>CD4mem</th>\n",
       "      <th>Treg</th>\n",
       "      <th>CD8nv</th>\n",
       "      <th>CD8mem</th>\n",
       "      <th>Mono</th>\n",
       "      <th>DC</th>\n",
       "      <th>NK</th>\n",
       "      <th>Bas</th>\n",
       "      <th>Eos</th>\n",
       "      <th>Neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLD050</td>\n",
       "      <td>A00000FBK</td>\n",
       "      <td>203723190040_R08C01</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>male</td>\n",
       "      <td>77</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>Grade 3 + 4</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.580140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.652840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>A00000FC3</td>\n",
       "      <td>203752100070_R04C01</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>Grade 3 + 4</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185204</td>\n",
       "      <td>1.613221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.676642</td>\n",
       "      <td>1.383615</td>\n",
       "      <td>5.232480</td>\n",
       "      <td>1.701208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>A00000FC3</td>\n",
       "      <td>203752100070_R04C01</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>Grade 3 + 4</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185204</td>\n",
       "      <td>1.613221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.676642</td>\n",
       "      <td>1.383615</td>\n",
       "      <td>5.232480</td>\n",
       "      <td>1.701208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>A00000EH7</td>\n",
       "      <td>203789410029_R03C01</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>female</td>\n",
       "      <td>76</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.589810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.141940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.534836</td>\n",
       "      <td>2.254315</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>0.205418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>A00000EH7</td>\n",
       "      <td>203789410029_R03C01</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>female</td>\n",
       "      <td>76</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>1.589810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.141940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.534836</td>\n",
       "      <td>2.254315</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>0.205418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BLD048</td>\n",
       "      <td>BDB1P03023</td>\n",
       "      <td>202163530099_R07C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>58</td>\n",
       "      <td>grade 2</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428655</td>\n",
       "      <td>1.116786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.827982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.453588</td>\n",
       "      <td>0.618560</td>\n",
       "      <td>0.974700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>BLD075</td>\n",
       "      <td>BDB1P04022</td>\n",
       "      <td>202172220150_R06C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>51</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010792</td>\n",
       "      <td>2.579993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>BLD024</td>\n",
       "      <td>BDB1P02094</td>\n",
       "      <td>202163530080_R06C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>68</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>1.592609</td>\n",
       "      <td>2.059939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.649354</td>\n",
       "      <td>3.207488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704491</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.487317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>BLD094</td>\n",
       "      <td>BDB1P03058</td>\n",
       "      <td>202163550181_R02C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>53</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620439</td>\n",
       "      <td>0.556929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.327215</td>\n",
       "      <td>0.388502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287847</td>\n",
       "      <td>0.132852</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>BLD014</td>\n",
       "      <td>BDB1P01044</td>\n",
       "      <td>202172220075_R04C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>68</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346014</td>\n",
       "      <td>2.866750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540538</td>\n",
       "      <td>1.122356</td>\n",
       "      <td>0.407776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FFPE.DNA.ID Blood.Sample.ID        ChIP_ID_Blood    Batch     Sex  Age  \\\n",
       "0        BLD050       A00000FBK  203723190040_R08C01  Batch_3    male   77   \n",
       "1        BLD043       A00000FC3  203752100070_R04C01  Batch_2  female   77   \n",
       "2        BLD043       A00000FC3  203752100070_R04C01  Batch_2  female   77   \n",
       "3        BLD061       A00000EH7  203789410029_R03C01  Batch_3  female   76   \n",
       "4        BLD061       A00000EH7  203789410029_R03C01  Batch_3  female   76   \n",
       "..          ...             ...                  ...      ...     ...  ...   \n",
       "136      BLD048      BDB1P03023  202163530099_R07C01  Batch_1    male   58   \n",
       "137      BLD075      BDB1P04022  202172220150_R06C01  Batch_1    male   51   \n",
       "138      BLD024      BDB1P02094  202163530080_R06C01  Batch_1    male   68   \n",
       "139      BLD094      BDB1P03058  202163550181_R02C01  Batch_1    male   53   \n",
       "140      BLD014      BDB1P01044  202172220075_R04C01  Batch_1    male   68   \n",
       "\n",
       "       Grade       Grade2 Muscle_Invasive             BCG  ...    CD4mem  \\\n",
       "0    grade 3  Grade 3 + 4              no  Without Immuno  ...  0.000000   \n",
       "1    grade 3  Grade 3 + 4              no  Without Immuno  ...  0.185204   \n",
       "2    grade 3  Grade 3 + 4              no  Without Immuno  ...  0.185204   \n",
       "3    grade 1  Grade 1 + 2              no  Without Immuno  ...  0.997968   \n",
       "4    grade 1  Grade 1 + 2              no  Without Immuno  ...  0.997968   \n",
       "..       ...          ...             ...             ...  ...       ...   \n",
       "136  grade 2  Grade 1 + 2              no  Without Immuno  ...  2.428655   \n",
       "137  grade 1  Grade 1 + 2              no  Without Immuno  ...  1.010792   \n",
       "138  grade 1  Grade 1 + 2              no  Without Immuno  ...  1.592609   \n",
       "139  grade 1  Grade 1 + 2              no  Without Immuno  ...  0.620439   \n",
       "140  grade 1  Grade 1 + 2              no  Without Immuno  ...  1.346014   \n",
       "\n",
       "         Treg  CD8nv    CD8mem      Mono        DC        NK       Bas  \\\n",
       "0    5.580140    0.0  3.388986  0.000000  0.000000  2.652840  0.000000   \n",
       "1    1.613221    0.0  3.676642  1.383615  5.232480  1.701208  0.000000   \n",
       "2    1.613221    0.0  3.676642  1.383615  5.232480  1.701208  0.000000   \n",
       "3    1.589810    0.0  3.141940  0.000000  4.534836  2.254315  0.073649   \n",
       "4    1.589810    0.0  3.141940  0.000000  4.534836  2.254315  0.073649   \n",
       "..        ...    ...       ...       ...       ...       ...       ...   \n",
       "136  1.116786    0.0  2.827982  0.000000  0.000000  1.453588  0.618560   \n",
       "137  2.579993    0.0  0.000000  0.000000  0.000000  0.000000  2.200406   \n",
       "138  2.059939    0.0  1.649354  3.207488  0.000000  0.704491  0.724507   \n",
       "139  0.556929    0.0  1.327215  0.388502  0.000000  0.000000  0.287847   \n",
       "140  2.866750    0.0  0.000000  0.000000  0.000000  0.540538  1.122356   \n",
       "\n",
       "          Eos  Neu  \n",
       "0    0.000000  0.0  \n",
       "1    0.000000  0.0  \n",
       "2    0.000000  0.0  \n",
       "3    0.205418  0.0  \n",
       "4    0.205418  0.0  \n",
       "..        ...  ...  \n",
       "136  0.974700  0.0  \n",
       "137  0.000000  0.0  \n",
       "138  0.487317  0.0  \n",
       "139  0.132852  0.0  \n",
       "140  0.407776  0.0  \n",
       "\n",
       "[136 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiTIMED_df = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/Bladder_DNAm_HiTIMED/Total_88_subjects_WSI_Pheno_HiTIMED.csv\")\n",
    "HiTIMED_df = HiTIMED_df.dropna(subset=['file_name']) # Remove subjects without WSI files\n",
    "HiTIMED_df = HiTIMED_df[HiTIMED_df['file_name'] != '205943_.svs'] # \"205943_.pkl\" < 810 byte\n",
    "HiTIMED_df['TenYearSurv'] = HiTIMED_df['TenYearSurv'].transform(lambda x: x*30)\n",
    "HiTIMED_df['TenYearRFS'] = HiTIMED_df['TenYearRFS'].transform(lambda x: x*30)\n",
    "HiTIMED_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891ff320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     115\n",
       "yes     21\n",
       "Name: Muscle_Invasive, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Muscle_invasive_count = HiTIMED_df['Muscle_Invasive'].value_counts()\n",
    "Muscle_invasive_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441c50f",
   "metadata": {},
   "source": [
    "## Load WSI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd0fcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcr_patient_barcode</th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>cigarettes_per_day</th>\n",
       "      <th>primary_diagnosis</th>\n",
       "      <th>tissue_or_organ_of_origin</th>\n",
       "      <th>ajcc_pathologic_stage</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>prior_malignancy</th>\n",
       "      <th>vital_status</th>\n",
       "      <th>ajcc_pathologic_t</th>\n",
       "      <th>ajcc_pathologic_n</th>\n",
       "      <th>ajcc_pathologic_m</th>\n",
       "      <th>survival_time</th>\n",
       "      <th>patches_npy</th>\n",
       "      <th>patches_pkl</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>graphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-2F-A9KO</td>\n",
       "      <td>63.898630</td>\n",
       "      <td>3.780822</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Posterior wall of bladder</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>T3</td>\n",
       "      <td>N1</td>\n",
       "      <td>M0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-2F-A9KP</td>\n",
       "      <td>66.926027</td>\n",
       "      <td>3.397260</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Lateral wall of bladder</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>T3a</td>\n",
       "      <td>N2</td>\n",
       "      <td>MX</td>\n",
       "      <td>364.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-2F-A9KP</td>\n",
       "      <td>66.926027</td>\n",
       "      <td>3.397260</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Lateral wall of bladder</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>T3a</td>\n",
       "      <td>N2</td>\n",
       "      <td>MX</td>\n",
       "      <td>364.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-2F-A9KQ</td>\n",
       "      <td>69.202740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>T3a</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-2F-A9KR</td>\n",
       "      <td>59.857534</td>\n",
       "      <td>1.232877</td>\n",
       "      <td>Papillary transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>not reported</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>T3a</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>3183.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>TCGA-ZF-AA54</td>\n",
       "      <td>71.583562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Lateral wall of bladder</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>T3</td>\n",
       "      <td>NX</td>\n",
       "      <td>MX</td>\n",
       "      <td>590.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>TCGA-ZF-AA58</td>\n",
       "      <td>61.778082</td>\n",
       "      <td>2.136986</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>T3a</td>\n",
       "      <td>N2</td>\n",
       "      <td>MX</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>TCGA-ZF-AA5H</td>\n",
       "      <td>60.608219</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>T3b</td>\n",
       "      <td>N2</td>\n",
       "      <td>M0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>TCGA-ZF-AA5N</td>\n",
       "      <td>62.304110</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>NX</td>\n",
       "      <td>M1</td>\n",
       "      <td>168.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>TCGA-ZF-AA5P</td>\n",
       "      <td>65.673973</td>\n",
       "      <td>3.397260</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Posterior wall of bladder</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>T2b</td>\n",
       "      <td>N2</td>\n",
       "      <td>M0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "      <td>/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bcr_patient_barcode  age_at_diagnosis  cigarettes_per_day  \\\n",
       "0          TCGA-2F-A9KO         63.898630            3.780822   \n",
       "1          TCGA-2F-A9KP         66.926027            3.397260   \n",
       "2          TCGA-2F-A9KP         66.926027            3.397260   \n",
       "3          TCGA-2F-A9KQ         69.202740            0.000000   \n",
       "4          TCGA-2F-A9KR         59.857534            1.232877   \n",
       "..                  ...               ...                 ...   \n",
       "451        TCGA-ZF-AA54         71.583562            0.000000   \n",
       "452        TCGA-ZF-AA58         61.778082            2.136986   \n",
       "453        TCGA-ZF-AA5H         60.608219            0.438356   \n",
       "454        TCGA-ZF-AA5N         62.304110            0.547945   \n",
       "455        TCGA-ZF-AA5P         65.673973            3.397260   \n",
       "\n",
       "                         primary_diagnosis  tissue_or_organ_of_origin  \\\n",
       "0              Transitional cell carcinoma  Posterior wall of bladder   \n",
       "1              Transitional cell carcinoma    Lateral wall of bladder   \n",
       "2              Transitional cell carcinoma    Lateral wall of bladder   \n",
       "3              Transitional cell carcinoma               Bladder, NOS   \n",
       "4    Papillary transitional cell carcinoma               Bladder, NOS   \n",
       "..                                     ...                        ...   \n",
       "451            Transitional cell carcinoma    Lateral wall of bladder   \n",
       "452            Transitional cell carcinoma               Bladder, NOS   \n",
       "453            Transitional cell carcinoma               Bladder, NOS   \n",
       "454            Transitional cell carcinoma               Bladder, NOS   \n",
       "455            Transitional cell carcinoma  Posterior wall of bladder   \n",
       "\n",
       "    ajcc_pathologic_stage          race  gender prior_malignancy  \\\n",
       "0                Stage IV         white    male               no   \n",
       "1                Stage IV         white    male               no   \n",
       "2                Stage IV         white    male               no   \n",
       "3               Stage III         white    male               no   \n",
       "4               Stage III  not reported  female               no   \n",
       "..                    ...           ...     ...              ...   \n",
       "451             Stage III         white    male               no   \n",
       "452              Stage IV         white  female               no   \n",
       "453              Stage IV         white  female               no   \n",
       "454              Stage IV         white  female               no   \n",
       "455              Stage IV         white    male               no   \n",
       "\n",
       "     vital_status ajcc_pathologic_t ajcc_pathologic_n ajcc_pathologic_m  \\\n",
       "0               1                T3                N1                M0   \n",
       "1               1               T3a                N2                MX   \n",
       "2               1               T3a                N2                MX   \n",
       "3               0               T3a                N0                M0   \n",
       "4               1               T3a                N0                M0   \n",
       "..            ...               ...               ...               ...   \n",
       "451             1                T3                NX                MX   \n",
       "452             0               T3a                N2                MX   \n",
       "453             0               T3b                N2                M0   \n",
       "454             1                T2                NX                M1   \n",
       "455             0               T2b                N2                M0   \n",
       "\n",
       "     survival_time                                        patches_npy  \\\n",
       "0            734.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "1            364.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "2            364.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "3           2886.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "4           3183.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "..             ...                                                ...   \n",
       "451          590.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "452         1649.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "453          897.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "454          168.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "455          372.0  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "\n",
       "                                           patches_pkl  \\\n",
       "0    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "1    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "2    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "3    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "4    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "..                                                 ...   \n",
       "451  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "452  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "453  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "454  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "455  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "\n",
       "                                            embeddings  \\\n",
       "0    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "1    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "2    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "3    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "4    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "..                                                 ...   \n",
       "451  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "452  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "453  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "454  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "455  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...   \n",
       "\n",
       "                                                graphs  \n",
       "0    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "1    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "2    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "3    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "4    /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "..                                                 ...  \n",
       "451  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "452  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "453  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "454  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "455  /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Inte...  \n",
       "\n",
       "[456 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSI_TCGA_info = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/WSI/wsi_metadata_with_patches_and_embeddings_and_graphs.csv\",index_col=0)\n",
    "WSI_TCGA_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e813a",
   "metadata": {},
   "source": [
    "## Get Demogrphics and Tumor stage, then, Convert categorical variables into dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96f2ca",
   "metadata": {},
   "source": [
    "- TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f30e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcr_patient_barcode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_stand</th>\n",
       "      <th>Stage_Stage_I</th>\n",
       "      <th>Stage_Stage_II</th>\n",
       "      <th>Stage_Stage_III</th>\n",
       "      <th>Stage_Stage_IV</th>\n",
       "      <th>Stage_cis_Stage_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-2F-A9KO</td>\n",
       "      <td>63.898630</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.408341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-2F-A9KP</td>\n",
       "      <td>66.926027</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.135424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-2F-A9KQ</td>\n",
       "      <td>69.202740</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-2F-A9KR</td>\n",
       "      <td>59.857534</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.772643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-2F-A9KT</td>\n",
       "      <td>83.616438</td>\n",
       "      <td>1</td>\n",
       "      <td>1.369205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>TCGA-ZF-AA56</td>\n",
       "      <td>79.279452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>TCGA-ZF-AA58</td>\n",
       "      <td>61.778082</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.599507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>TCGA-ZF-AA5H</td>\n",
       "      <td>60.608219</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.704970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>TCGA-ZF-AA5N</td>\n",
       "      <td>62.304110</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.552086</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>TCGA-ZF-AA5P</td>\n",
       "      <td>65.673973</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.248295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bcr_patient_barcode        Age  Gender  Age_stand  Stage_Stage_I  \\\n",
       "0          TCGA-2F-A9KO  63.898630       1  -0.408341              0   \n",
       "1          TCGA-2F-A9KP  66.926027       1  -0.135424              0   \n",
       "2          TCGA-2F-A9KQ  69.202740       1   0.069820              0   \n",
       "3          TCGA-2F-A9KR  59.857534       0  -0.772643              0   \n",
       "4          TCGA-2F-A9KT  83.616438       1   1.369205              0   \n",
       "..                  ...        ...     ...        ...            ...   \n",
       "407        TCGA-ZF-AA56  79.279452       0   0.978229              0   \n",
       "408        TCGA-ZF-AA58  61.778082       0  -0.599507              0   \n",
       "409        TCGA-ZF-AA5H  60.608219       0  -0.704970              0   \n",
       "410        TCGA-ZF-AA5N  62.304110       0  -0.552086              0   \n",
       "411        TCGA-ZF-AA5P  65.673973       1  -0.248295              0   \n",
       "\n",
       "     Stage_Stage_II  Stage_Stage_III  Stage_Stage_IV  Stage_cis_Stage_0  \n",
       "0                 0                0               1                  0  \n",
       "1                 0                0               1                  0  \n",
       "2                 0                1               0                  0  \n",
       "3                 0                1               0                  0  \n",
       "4                 1                0               0                  0  \n",
       "..              ...              ...             ...                ...  \n",
       "407               0                1               0                  0  \n",
       "408               0                0               1                  0  \n",
       "409               0                0               1                  0  \n",
       "410               0                0               1                  0  \n",
       "411               0                0               1                  0  \n",
       "\n",
       "[412 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCGA_Pheno = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/BLCA_TCGA_meta_data.csv\").sort_values(by='bcr_patient_barcode', ascending=True).reset_index(drop=True)\n",
    "TCGA_Pheno = TCGA_Pheno[['bcr_patient_barcode', 'age_at_diagnosis', 'gender', 'ajcc_pathologic_stage']].copy()\n",
    "TCGA_Pheno.rename({'age_at_diagnosis': 'Age',\n",
    "                   'gender': 'Gender',\n",
    "                   'ajcc_pathologic_stage': 'Tumor_Stage'}, axis=1, inplace=True)\n",
    "TCGA_Pheno.replace({'Tumor_Stage': {\"0\": 'cis_Stage_0',\n",
    "                                    'Stage I':'Stage_I', 'Stage II':'Stage_II',\n",
    "                                    'Stage III':'Stage_III', 'Stage IV':'Stage_IV'},\n",
    "                    'Gender':{'female':0, 'male':1}}, inplace = True)\n",
    "\n",
    "TCGA_Pheno = TCGA_Pheno.drop_duplicates()\n",
    "\n",
    "stand = StandardScaler()\n",
    "TCGA_Pheno['Age_stand'] = stand.fit_transform(TCGA_Pheno['Age'].values.reshape(-1,1))\n",
    "\n",
    "TCGA_Pheno_Dummy = pd.get_dummies(TCGA_Pheno, columns=['Tumor_Stage'],\n",
    "                                  drop_first=False, prefix=['Stage'])\n",
    "\n",
    "TCGA_Pheno_Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe9de4",
   "metadata": {},
   "source": [
    "- DH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdbf4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFPE.DNA.ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_stand</th>\n",
       "      <th>Stage_Stage_I</th>\n",
       "      <th>Stage_Stage_II</th>\n",
       "      <th>Stage_Stage_III</th>\n",
       "      <th>Stage_Stage_IV</th>\n",
       "      <th>Stage_cis_Stage_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLD050</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BLD046</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BLD080</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BLD048</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.940099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>BLD075</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.571144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>BLD024</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.038606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>BLD094</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.390845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>BLD014</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.038606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FFPE.DNA.ID  Age  Gender  Age_stand  Stage_Stage_I  Stage_Stage_II  \\\n",
       "0        BLD050   77       1   0.772738              0               0   \n",
       "1        BLD043   77       0   0.772738              1               0   \n",
       "3        BLD061   76       0   0.682589              0               0   \n",
       "5        BLD046   69       1   0.051544              0               0   \n",
       "6        BLD080   66       1  -0.218904              0               0   \n",
       "..          ...  ...     ...        ...            ...             ...   \n",
       "136      BLD048   58       1  -0.940099              0               0   \n",
       "137      BLD075   51       1  -1.571144              0               0   \n",
       "138      BLD024   68       1  -0.038606              0               0   \n",
       "139      BLD094   53       1  -1.390845              0               0   \n",
       "140      BLD014   68       1  -0.038606              0               0   \n",
       "\n",
       "     Stage_Stage_III  Stage_Stage_IV  Stage_cis_Stage_0  \n",
       "0                  0               0                  1  \n",
       "1                  0               0                  0  \n",
       "3                  0               0                  1  \n",
       "5                  0               1                  0  \n",
       "6                  0               0                  1  \n",
       "..               ...             ...                ...  \n",
       "136                0               0                  1  \n",
       "137                0               0                  1  \n",
       "138                0               0                  1  \n",
       "139                0               0                  1  \n",
       "140                0               0                  1  \n",
       "\n",
       "[88 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DH_pheno = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/Bladder_DNAm_HiTIMED/Total_88_subjects_WSI_Pheno_HiTIMED.csv\")\n",
    "DH_pheno = DH_pheno.loc[:,['FFPE.DNA.ID', 'Age', 'Sex', 'stage2']]\n",
    "DH_pheno = DH_pheno.drop_duplicates()\n",
    "DH_pheno.rename({'Sex': 'Gender',\n",
    "                 'stage2': 'Tumor_Stage'}, axis=1, inplace=True)\n",
    "DH_pheno.replace({'Tumor_Stage': {\"cis + stage 0a\": 'cis_Stage_0',\n",
    "                                  'stage I':'Stage_I', 'stage II':'Stage_II',\n",
    "                                  'stage III':'Stage_III', 'stage IV':'Stage_IV'},\n",
    "                  'Gender':{'female':0, 'male':1}}, inplace = True)\n",
    "\n",
    "DH_pheno = DH_pheno[['FFPE.DNA.ID', 'Age', 'Gender', 'Tumor_Stage']].copy()\n",
    "\n",
    "DH_pheno['Age_stand'] = stand.transform(DH_pheno['Age'].values.reshape(-1,1))\n",
    "DH_pheno = pd.get_dummies(DH_pheno, columns=['Tumor_Stage'],\n",
    "                          drop_first=False, prefix=['Stage'])\n",
    "DH_pheno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeac201",
   "metadata": {},
   "source": [
    "### Keep same order of patient ID for DNAm, HiTIMED, and WSI dataset; Then, merge all modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1c8bf",
   "metadata": {},
   "source": [
    "- TCGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c099bb",
   "metadata": {},
   "source": [
    "#### Get only patients who have all three data modalities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1207496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 395 385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnam_patients = {name for name in DNAm_TCGA['bcr_patient_barcode']}\n",
    "hitimed_patients = {name for name in HiTIMED_TCGA_df['bcr_patient_barcode']}\n",
    "wsi_patients = {name for name in WSI_TCGA_info['bcr_patient_barcode']}\n",
    "print(len(dnam_patients), len(hitimed_patients), len(wsi_patients))\n",
    "\n",
    "relevant_patients = dnam_patients & hitimed_patients & wsi_patients\n",
    "len(relevant_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519d8d2",
   "metadata": {},
   "source": [
    "#### Create a final dataset for those patients with all three data modalities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f5ba20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcr_patient_barcode</th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>cigarettes_per_day</th>\n",
       "      <th>primary_diagnosis</th>\n",
       "      <th>tissue_or_organ_of_origin</th>\n",
       "      <th>ajcc_pathologic_stage</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>prior_malignancy</th>\n",
       "      <th>vital_status</th>\n",
       "      <th>...</th>\n",
       "      <th>cg20021506</th>\n",
       "      <th>cg10939949</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_stand</th>\n",
       "      <th>Stage_Stage_I</th>\n",
       "      <th>Stage_Stage_II</th>\n",
       "      <th>Stage_Stage_III</th>\n",
       "      <th>Stage_Stage_IV</th>\n",
       "      <th>Stage_cis_Stage_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-BL-A3JM</td>\n",
       "      <td>63.013699</td>\n",
       "      <td>2.684932</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708370</td>\n",
       "      <td>0.696522</td>\n",
       "      <td>63.013699</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.488117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-ZF-A9R9</td>\n",
       "      <td>58.879452</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690168</td>\n",
       "      <td>0.858918</td>\n",
       "      <td>58.879452</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.860817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-FD-A5BX</td>\n",
       "      <td>82.947945</td>\n",
       "      <td>6.082192</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Posterior wall of bladder</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799663</td>\n",
       "      <td>0.532836</td>\n",
       "      <td>82.947945</td>\n",
       "      <td>1</td>\n",
       "      <td>1.308941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-G2-A3IB</td>\n",
       "      <td>66.161644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage II</td>\n",
       "      <td>black or african american</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211621</td>\n",
       "      <td>0.573952</td>\n",
       "      <td>66.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-G2-A3IB</td>\n",
       "      <td>66.161644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage II</td>\n",
       "      <td>black or african american</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211621</td>\n",
       "      <td>0.573952</td>\n",
       "      <td>66.161644</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>TCGA-G2-AA3C</td>\n",
       "      <td>66.484932</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487583</td>\n",
       "      <td>0.469828</td>\n",
       "      <td>66.484932</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.175188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>TCGA-G2-AA3C</td>\n",
       "      <td>66.484932</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487583</td>\n",
       "      <td>0.469828</td>\n",
       "      <td>66.484932</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.175188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>TCGA-XF-A9T8</td>\n",
       "      <td>64.117808</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718323</td>\n",
       "      <td>0.616255</td>\n",
       "      <td>64.117808</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.388583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>TCGA-PQ-A6FI</td>\n",
       "      <td>70.334247</td>\n",
       "      <td>3.178082</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Bladder, NOS</td>\n",
       "      <td>Stage II</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557005</td>\n",
       "      <td>0.516983</td>\n",
       "      <td>70.334247</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171825</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>TCGA-BT-A20O</td>\n",
       "      <td>75.435616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Transitional cell carcinoma</td>\n",
       "      <td>Lateral wall of bladder</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773212</td>\n",
       "      <td>0.884328</td>\n",
       "      <td>75.435616</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bcr_patient_barcode  age_at_diagnosis  cigarettes_per_day  \\\n",
       "0          TCGA-BL-A3JM         63.013699            2.684932   \n",
       "1          TCGA-ZF-A9R9         58.879452            0.164384   \n",
       "2          TCGA-FD-A5BX         82.947945            6.082192   \n",
       "3          TCGA-G2-A3IB         66.161644            0.000000   \n",
       "4          TCGA-G2-A3IB         66.161644            0.000000   \n",
       "..                  ...               ...                 ...   \n",
       "437        TCGA-G2-AA3C         66.484932            0.219178   \n",
       "438        TCGA-G2-AA3C         66.484932            0.219178   \n",
       "439        TCGA-XF-A9T8         64.117808            0.821918   \n",
       "440        TCGA-PQ-A6FI         70.334247            3.178082   \n",
       "441        TCGA-BT-A20O         75.435616            0.000000   \n",
       "\n",
       "               primary_diagnosis  tissue_or_organ_of_origin  \\\n",
       "0    Transitional cell carcinoma               Bladder, NOS   \n",
       "1    Transitional cell carcinoma               Bladder, NOS   \n",
       "2    Transitional cell carcinoma  Posterior wall of bladder   \n",
       "3    Transitional cell carcinoma               Bladder, NOS   \n",
       "4    Transitional cell carcinoma               Bladder, NOS   \n",
       "..                           ...                        ...   \n",
       "437  Transitional cell carcinoma               Bladder, NOS   \n",
       "438  Transitional cell carcinoma               Bladder, NOS   \n",
       "439  Transitional cell carcinoma               Bladder, NOS   \n",
       "440  Transitional cell carcinoma               Bladder, NOS   \n",
       "441  Transitional cell carcinoma    Lateral wall of bladder   \n",
       "\n",
       "    ajcc_pathologic_stage                       race gender prior_malignancy  \\\n",
       "0               Stage III                      white   male               no   \n",
       "1                Stage IV                      white   male               no   \n",
       "2                Stage IV                      white   male              yes   \n",
       "3                Stage II  black or african american   male               no   \n",
       "4                Stage II  black or african american   male               no   \n",
       "..                    ...                        ...    ...              ...   \n",
       "437              Stage IV                      white   male               no   \n",
       "438              Stage IV                      white   male               no   \n",
       "439             Stage III                      white   male              yes   \n",
       "440              Stage II                      white   male               no   \n",
       "441             Stage III                      white   male               no   \n",
       "\n",
       "     vital_status  ... cg20021506 cg10939949        Age  Gender Age_stand  \\\n",
       "0               1  ...   0.708370   0.696522  63.013699       1 -0.488117   \n",
       "1               1  ...   0.690168   0.858918  58.879452       1 -0.860817   \n",
       "2               1  ...   0.799663   0.532836  82.947945       1  1.308941   \n",
       "3               1  ...   0.211621   0.573952  66.161644       1 -0.204332   \n",
       "4               1  ...   0.211621   0.573952  66.161644       1 -0.204332   \n",
       "..            ...  ...        ...        ...        ...     ...       ...   \n",
       "437             1  ...   0.487583   0.469828  66.484932       1 -0.175188   \n",
       "438             1  ...   0.487583   0.469828  66.484932       1 -0.175188   \n",
       "439             1  ...   0.718323   0.616255  64.117808       1 -0.388583   \n",
       "440             0  ...   0.557005   0.516983  70.334247       1  0.171825   \n",
       "441             1  ...   0.773212   0.884328  75.435616       1  0.631710   \n",
       "\n",
       "    Stage_Stage_I Stage_Stage_II Stage_Stage_III  Stage_Stage_IV  \\\n",
       "0               0              0               1               0   \n",
       "1               0              0               0               1   \n",
       "2               0              0               0               1   \n",
       "3               0              1               0               0   \n",
       "4               0              1               0               0   \n",
       "..            ...            ...             ...             ...   \n",
       "437             0              0               0               1   \n",
       "438             0              0               0               1   \n",
       "439             0              0               1               0   \n",
       "440             0              1               0               0   \n",
       "441             0              0               1               0   \n",
       "\n",
       "     Stage_cis_Stage_0  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "..                 ...  \n",
       "437                  0  \n",
       "438                  0  \n",
       "439                  0  \n",
       "440                  0  \n",
       "441                  0  \n",
       "\n",
       "[442 rows x 177 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_TCGA_final = pd.DataFrame()\n",
    "for id in relevant_patients:\n",
    "    row = WSI_TCGA_info[WSI_TCGA_info[\"bcr_patient_barcode\"] == id]\n",
    "    Data_TCGA_final = pd.concat([Data_TCGA_final, row], ignore_index=True)\n",
    "\n",
    "Data_TCGA_final = Data_TCGA_final.merge(HiTIMED_TCGA_df, left_on=\"bcr_patient_barcode\", right_on=\"bcr_patient_barcode\", how=\"left\")\n",
    "Data_TCGA_final = Data_TCGA_final.merge(DNAm_TCGA, left_on=\"bcr_patient_barcode\", right_on=\"bcr_patient_barcode\", how=\"left\")\n",
    "Data_TCGA_final = Data_TCGA_final.merge(TCGA_Pheno_Dummy, left_on=\"bcr_patient_barcode\", right_on=\"bcr_patient_barcode\", how=\"left\")\n",
    "Data_TCGA_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80936522",
   "metadata": {},
   "source": [
    "- DH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e58d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFPE.DNA.ID</th>\n",
       "      <th>Blood.Sample.ID</th>\n",
       "      <th>ChIP_ID_Blood</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Grade2</th>\n",
       "      <th>Muscle_Invasive</th>\n",
       "      <th>BCG</th>\n",
       "      <th>ImToBlood</th>\n",
       "      <th>...</th>\n",
       "      <th>cg20021506</th>\n",
       "      <th>cg10939949</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_stand</th>\n",
       "      <th>Stage_Stage_I</th>\n",
       "      <th>Stage_Stage_II</th>\n",
       "      <th>Stage_Stage_III</th>\n",
       "      <th>Stage_Stage_IV</th>\n",
       "      <th>Stage_cis_Stage_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLD050</td>\n",
       "      <td>A00000FBK</td>\n",
       "      <td>203723190040_R08C01</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>male</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>Grade 3 + 4</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.814271</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>A00000FC3</td>\n",
       "      <td>203752100070_R04C01</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>female</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>Grade 3 + 4</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906822</td>\n",
       "      <td>0.925455</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>A00000FC3</td>\n",
       "      <td>203752100070_R04C01</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>female</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>Grade 3 + 4</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906822</td>\n",
       "      <td>0.925455</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>A00000EH7</td>\n",
       "      <td>203789410029_R03C01</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>female</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886499</td>\n",
       "      <td>0.922573</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>A00000EH7</td>\n",
       "      <td>203789410029_R03C01</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>female</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886499</td>\n",
       "      <td>0.922573</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>BLD048</td>\n",
       "      <td>BDB1P03023</td>\n",
       "      <td>202163530099_R07C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>grade 2</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737637</td>\n",
       "      <td>0.626453</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.940099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>BLD075</td>\n",
       "      <td>BDB1P04022</td>\n",
       "      <td>202172220150_R06C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873276</td>\n",
       "      <td>0.888269</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.571144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>BLD024</td>\n",
       "      <td>BDB1P02094</td>\n",
       "      <td>202163530080_R06C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858617</td>\n",
       "      <td>0.894181</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.038606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BLD094</td>\n",
       "      <td>BDB1P03058</td>\n",
       "      <td>202163550181_R02C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919905</td>\n",
       "      <td>0.904419</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.390845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>BLD014</td>\n",
       "      <td>BDB1P01044</td>\n",
       "      <td>202172220075_R04C01</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>male</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>Grade 1 + 2</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Immuno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871785</td>\n",
       "      <td>0.925355</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.038606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FFPE.DNA.ID Blood.Sample.ID        ChIP_ID_Blood    Batch     Sex  \\\n",
       "0        BLD050       A00000FBK  203723190040_R08C01  Batch_3    male   \n",
       "1        BLD043       A00000FC3  203752100070_R04C01  Batch_2  female   \n",
       "2        BLD043       A00000FC3  203752100070_R04C01  Batch_2  female   \n",
       "3        BLD061       A00000EH7  203789410029_R03C01  Batch_3  female   \n",
       "4        BLD061       A00000EH7  203789410029_R03C01  Batch_3  female   \n",
       "..          ...             ...                  ...      ...     ...   \n",
       "131      BLD048      BDB1P03023  202163530099_R07C01  Batch_1    male   \n",
       "132      BLD075      BDB1P04022  202172220150_R06C01  Batch_1    male   \n",
       "133      BLD024      BDB1P02094  202163530080_R06C01  Batch_1    male   \n",
       "134      BLD094      BDB1P03058  202163550181_R02C01  Batch_1    male   \n",
       "135      BLD014      BDB1P01044  202172220075_R04C01  Batch_1    male   \n",
       "\n",
       "       Grade       Grade2 Muscle_Invasive             BCG  ImToBlood  ...  \\\n",
       "0    grade 3  Grade 3 + 4              no  Without Immuno        NaN  ...   \n",
       "1    grade 3  Grade 3 + 4              no  Without Immuno        NaN  ...   \n",
       "2    grade 3  Grade 3 + 4              no  Without Immuno        NaN  ...   \n",
       "3    grade 1  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "4    grade 1  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "..       ...          ...             ...             ...        ...  ...   \n",
       "131  grade 2  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "132  grade 1  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "133  grade 1  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "134  grade 1  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "135  grade 1  Grade 1 + 2              no  Without Immuno        NaN  ...   \n",
       "\n",
       "     cg20021506  cg10939949 Age  Gender  Age_stand  Stage_Stage_I  \\\n",
       "0      0.852336    0.814271  77       1   0.772738              0   \n",
       "1      0.906822    0.925455  77       0   0.772738              1   \n",
       "2      0.906822    0.925455  77       0   0.772738              1   \n",
       "3      0.886499    0.922573  76       0   0.682589              0   \n",
       "4      0.886499    0.922573  76       0   0.682589              0   \n",
       "..          ...         ...  ..     ...        ...            ...   \n",
       "131    0.737637    0.626453  58       1  -0.940099              0   \n",
       "132    0.873276    0.888269  51       1  -1.571144              0   \n",
       "133    0.858617    0.894181  68       1  -0.038606              0   \n",
       "134    0.919905    0.904419  53       1  -1.390845              0   \n",
       "135    0.871785    0.925355  68       1  -0.038606              0   \n",
       "\n",
       "     Stage_Stage_II Stage_Stage_III Stage_Stage_IV Stage_cis_Stage_0  \n",
       "0                 0               0              0                 1  \n",
       "1                 0               0              0                 0  \n",
       "2                 0               0              0                 0  \n",
       "3                 0               0              0                 1  \n",
       "4                 0               0              0                 1  \n",
       "..              ...             ...            ...               ...  \n",
       "131               0               0              0                 1  \n",
       "132               0               0              0                 1  \n",
       "133               0               0              0                 1  \n",
       "134               0               0              0                 1  \n",
       "135               0               0              0                 1  \n",
       "\n",
       "[136 rows x 184 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_DH_final = HiTIMED_df.copy()\n",
    "Data_DH_final = Data_DH_final.drop('Age', axis=1)\n",
    "Data_DH_final = Data_DH_final.merge(DNAm_df, left_on=\"FFPE.DNA.ID\", right_on=\"FFPE.DNA.ID\", how=\"left\")\n",
    "Data_DH_final = Data_DH_final.merge(DH_pheno, left_on=\"FFPE.DNA.ID\", right_on=\"FFPE.DNA.ID\", how=\"left\")\n",
    "Data_DH_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5c927",
   "metadata": {},
   "source": [
    "#### Check NA in each important modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d4ef5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TCGA\n",
    "print(Data_TCGA_final['vital_status'].isna().sum())\n",
    "print(Data_TCGA_final['survival_time'].isna().sum())\n",
    "print(Data_TCGA_final['cg20021506'].isna().sum())\n",
    "print(Data_TCGA_final['Bmem'].isna().sum())\n",
    "print(Data_TCGA_final['Age_stand'].isna().sum())\n",
    "\n",
    "# DH\n",
    "print(Data_DH_final['death_stat'].isna().sum())\n",
    "print(Data_DH_final['death_censor_time'].isna().sum())\n",
    "print(Data_DH_final['cg20021506'].isna().sum())\n",
    "print(Data_DH_final['Bmem'].isna().sum())\n",
    "print(Data_DH_final['Age_stand'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34b3b8",
   "metadata": {},
   "source": [
    "### Split into trainging, validation Dataset = 310:132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38e7ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(Data_TCGA_final)).tolist()\n",
    "\n",
    "train_indices = indices[:-132]\n",
    "val_indices = indices[-132:]\n",
    "\n",
    "Data_TCGA_final_train = Data_TCGA_final.iloc[train_indices,].copy()\n",
    "Data_TCGA_final_val = Data_TCGA_final.iloc[val_indices,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73f6eaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 177)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_TCGA_final_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b025bae",
   "metadata": {},
   "source": [
    "## Generate Dataset Objects for Each Unimodality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388d330",
   "metadata": {},
   "source": [
    "### For WSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bed84",
   "metadata": {},
   "source": [
    "- TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d55676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSISurvivalDataset_TCGA(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        super().__init__()\n",
    "        self.samples = samples.copy()['graphs'].tolist()\n",
    "        self.demographic = samples.loc[:, 'Gender':'Stage_cis_Stage_0']\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        graph_data_object = pickle.load(open(sample,'rb'))\n",
    "        demographics = torch.tensor(self.demographic.iloc[idx])\n",
    "        return graph_data_object, demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c3bac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_wsi = WSISurvivalDataset_TCGA(Data_TCGA_final_train)\n",
    "val_dataset_wsi = WSISurvivalDataset_TCGA(Data_TCGA_final_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb2cf8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[21856, 2048], edge_index=[2, 196704], y=[21856, 2], pos=[21856, 2], censor=1, duration=674.0),\n",
       " tensor([ 1.0000, -1.0505,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_wsi.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecd31401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[20582, 2048], edge_index=[2, 185238], y=[20582, 2], pos=[20582, 2], censor=0, duration=469.0),\n",
       " tensor([ 1.0000, -0.3241,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset_wsi.get(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2084bbc",
   "metadata": {},
   "source": [
    "- DH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7596ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSISurvivalDataset_DH(Dataset):\n",
    "    def __init__(self, graph_dataset_dict_path, dataframe):\n",
    "        super().__init__()\n",
    "        self.datasets_path = graph_dataset_dict_path # path to subtype pkl, they contain the Data objects\n",
    "        self.list_svs = dataframe.copy()['file_name'].tolist()\n",
    "        self.samples = [a.replace('.svs','Graph.pkl') for a in self.list_svs] # list of samples, ex; ['214671_Graph.pkl','214810_Graph.pkl']\n",
    "        self.demographic = dataframe.loc[:, 'Gender':'Stage_cis_Stage_0']\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        graph_data_object = pickle.load(open(self.datasets_path+'/'+sample,'rb'))\n",
    "        demographics = torch.tensor(self.demographic.iloc[idx])\n",
    "        return graph_data_object, demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a59c5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dataset_path = '/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/Bladder_Graphs'\n",
    "#graph_dataset_path_trunc_10year = '/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/Bladder_Graphs_trunc_10year'\n",
    "\n",
    "test_dataset_wsi = WSISurvivalDataset_DH(graph_dataset_path, Data_DH_final)\n",
    "#test_dataset_wsi_trunc_10year = WSISurvivalDataset_DH(graph_dataset_path_trunc_10year, Data_DH_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed417086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[7603, 2048], edge_index=[2, 68427], y=[7603, 2], pos=[7603, 2], censor=1, duration=3816.34497),\n",
       " tensor([1.0000, 0.7727, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_wsi.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_wsi_trunc_10year.get(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edaea5",
   "metadata": {},
   "source": [
    "### For DNA methylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b6c953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAMSurvivalDataset(Dataset):\n",
    "    def __init__(self, dataframe, trunc_10year = False, TCGA = False):\n",
    "        super().__init__()\n",
    "        self.df = dataframe\n",
    "        self.dnam_array = dataframe.loc[:, 'cg05225634':'cg10939949']\n",
    "        self.demographic = dataframe.loc[:, 'Gender':'Stage_cis_Stage_0']\n",
    "        if trunc_10year:\n",
    "            self.time_array = dataframe['TenYearSurv']\n",
    "            self.status_array = dataframe['TenDead']\n",
    "        elif TCGA:\n",
    "            self.time_array = dataframe['survival_time']\n",
    "            self.status_array = dataframe['vital_status']\n",
    "        else:\n",
    "            self.time_array = dataframe['death_censor_time']\n",
    "            self.status_array = dataframe['death_stat']\n",
    "        \n",
    "    def get(): pass\n",
    "    def len(): pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dnam_array = torch.tensor(self.dnam_array.iloc[idx], dtype=torch.float64)\n",
    "        demographics = torch.tensor(self.demographic.iloc[idx])\n",
    "        time = torch.tensor(self.time_array.iloc[idx], dtype=torch.int32)\n",
    "        status = torch.tensor(self.status_array.iloc[idx])\n",
    "        return dnam_array, demographics, time, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37f0b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_Data_train = DNAMSurvivalDataset(Data_TCGA_final_train, TCGA = True)\n",
    "DNAm_Data_val = DNAMSurvivalDataset(Data_TCGA_final_val, TCGA = True)\n",
    "DNAm_Data_test = DNAMSurvivalDataset(Data_DH_final)\n",
    "#DNAm_Data_test_trunc_10year = DNAMSurvivalDataset(Data_DH_final, trunc_10year = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fe59b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9527, 0.9789, 0.9901, 0.9485, 0.8936, 0.8996, 0.9448, 0.7228, 0.8050,\n",
       "         0.5127, 0.8897, 0.9849, 0.0573, 0.9164, 0.8768, 0.4430, 0.1224, 0.3998,\n",
       "         0.8352, 0.5521, 0.0837, 0.7682, 0.2368, 0.1468, 0.1571, 0.1653, 0.6518,\n",
       "         0.8006, 0.4633, 0.8890, 0.8141, 0.5629, 0.1234, 0.2730, 0.1016, 0.0204,\n",
       "         0.6576, 0.6807, 0.1841, 0.4166, 0.2364, 0.9209, 0.9441, 0.1115, 0.7619,\n",
       "         0.3404, 0.4912, 0.8879, 0.4046, 0.1335, 0.8473, 0.0489, 0.8533, 0.7608,\n",
       "         0.9401, 0.7289, 0.8385, 0.4214, 0.8826, 0.2587, 0.0707, 0.3382, 0.8865,\n",
       "         0.7499, 0.0667, 0.2692, 0.3674, 0.7972, 0.9508, 0.6632, 0.1488, 0.1239,\n",
       "         0.7514, 0.1027, 0.2061, 0.9180, 0.1994, 0.4344, 0.0729, 0.8596, 0.4936,\n",
       "         0.1629, 0.9140, 0.3469, 0.1664, 0.6196, 0.5112, 0.3200, 0.1410, 0.2068,\n",
       "         0.5424, 0.8538, 0.8434, 0.2173, 0.3934, 0.8253, 0.2621, 0.8011, 0.7845,\n",
       "         0.7199, 0.2719, 0.8883, 0.6972, 0.0796, 0.1264, 0.8602, 0.0827, 0.5053,\n",
       "         0.8607, 0.0941, 0.1542, 0.1063, 0.6421, 0.7021, 0.0632, 0.4721, 0.1990,\n",
       "         0.3985, 0.8678, 0.4290, 0.9041, 0.9285, 0.2051, 0.0529, 0.1103, 0.0955,\n",
       "         0.8863, 0.8300, 0.1888, 0.8020, 0.4999, 0.5517, 0.8752, 0.8373],\n",
       "        dtype=torch.float64),\n",
       " tensor([ 1.0000, -1.0505,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "        dtype=torch.float64),\n",
       " tensor(674, dtype=torch.int32),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAm_Data_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "227ae0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8777, 0.7867, 0.8395, 0.8659, 0.7284, 0.8085, 0.8523, 0.7071, 0.5154,\n",
       "         0.3747, 0.8179, 0.8445, 0.0815, 0.9088, 0.8136, 0.6498, 0.1595, 0.3316,\n",
       "         0.3774, 0.8422, 0.1129, 0.7647, 0.3758, 0.2385, 0.1930, 0.2070, 0.6239,\n",
       "         0.8652, 0.7426, 0.9281, 0.7572, 0.5846, 0.2807, 0.2200, 0.1969, 0.0710,\n",
       "         0.7267, 0.7038, 0.2647, 0.5162, 0.3622, 0.7987, 0.7820, 0.1356, 0.6639,\n",
       "         0.3320, 0.4600, 0.7528, 0.5971, 0.2111, 0.7121, 0.1715, 0.8592, 0.7455,\n",
       "         0.8429, 0.7429, 0.6865, 0.5412, 0.7633, 0.3389, 0.3126, 0.3369, 0.8419,\n",
       "         0.7937, 0.1613, 0.1725, 0.4354, 0.8842, 0.8572, 0.7414, 0.2195, 0.2070,\n",
       "         0.8372, 0.1813, 0.3024, 0.8500, 0.2672, 0.4117, 0.2763, 0.7447, 0.5504,\n",
       "         0.2989, 0.7443, 0.2488, 0.1593, 0.7926, 0.4734, 0.4186, 0.1578, 0.3286,\n",
       "         0.7502, 0.8918, 0.9328, 0.3241, 0.4545, 0.8130, 0.3500, 0.7951, 0.6788,\n",
       "         0.7819, 0.3003, 0.8317, 0.5604, 0.1667, 0.1734, 0.6562, 0.1656, 0.7645,\n",
       "         0.6406, 0.0938, 0.2725, 0.2154, 0.6362, 0.7587, 0.1530, 0.8762, 0.1556,\n",
       "         0.5557, 0.8643, 0.6909, 0.7796, 0.8245, 0.5328, 0.1540, 0.2071, 0.2827,\n",
       "         0.8421, 0.9033, 0.6165, 0.8491, 0.7476, 0.7645, 0.8523, 0.8143],\n",
       "        dtype=torch.float64),\n",
       " tensor([1.0000, 0.7727, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        dtype=torch.float64),\n",
       " tensor(3816, dtype=torch.int32),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAm_Data_test.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_Data_test_trunc_10year.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332335cf",
   "metadata": {},
   "source": [
    "### For HiTIMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c11f65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiTIMED_Dataset(Dataset):\n",
    "    def __init__(self, dataframe, recurrence = False, TCGA = False):\n",
    "        super().__init__()\n",
    "        self.df = dataframe\n",
    "        self.cell_types = dataframe.loc[:, 'Tumor':'Neu'] # inputs/features\n",
    "        self.demographic = dataframe.loc[:, 'Gender':'Stage_cis_Stage_0']\n",
    "        if recurrence:\n",
    "            self.death = dataframe['RFS_censor_time'] # ouput\n",
    "            self.status = dataframe['RFS_stat'] # output\n",
    "        elif TCGA:\n",
    "            self.death = dataframe['survival_time'] # ouput\n",
    "            self.status = dataframe['vital_status'] # output\n",
    "        else:\n",
    "            self.death = dataframe['death_censor_time'] # ouput\n",
    "            self.status = dataframe['death_stat'] # output\n",
    "    \n",
    "    def get(): pass\n",
    "    def len(): pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        cell_types = torch.tensor(self.cell_types.iloc[idx])\n",
    "        demographics = torch.tensor(self.demographic.iloc[idx])\n",
    "        death = torch.tensor(int(float(self.death.iloc[idx])))\n",
    "        status = torch.tensor(self.status.iloc[idx])\n",
    "        return cell_types, demographics, status, death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aa022c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HiTIMED_Data_train = HiTIMED_Dataset(Data_TCGA_final_train, TCGA = True)\n",
    "HiTIMED_Data_val = HiTIMED_Dataset(Data_TCGA_final_val, TCGA = True)\n",
    "HiTIMED_Data_test = HiTIMED_Dataset(Data_DH_final)\n",
    "#HiTIMED_Data_test_trunc_10year = HiTIMED_Dataset(Data_DH_final, trunc_10year = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bd0c5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.1845e+01, 7.7456e+00, 1.2803e+00, 3.7420e+00, 0.0000e+00, 4.4559e-01,\n",
       "         0.0000e+00, 4.2453e-01, 1.8751e+00, 0.0000e+00, 6.3335e+00, 0.0000e+00,\n",
       "         3.0778e+00, 1.2034e+00, 2.0219e+00, 5.4564e-03, 0.0000e+00],\n",
       "        dtype=torch.float64),\n",
       " tensor([ 1.0000, -1.0505,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "        dtype=torch.float64),\n",
       " tensor(1),\n",
       " tensor(674))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiTIMED_Data_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e543b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([61.6124,  5.9809,  4.6928, 10.2977,  0.0000,  5.7941,  0.0000,  0.0000,\n",
       "          5.5801,  0.0000,  3.3890,  0.0000,  0.0000,  2.6528,  0.0000,  0.0000,\n",
       "          0.0000], dtype=torch.float64),\n",
       " tensor([1.0000, 0.7727, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        dtype=torch.float64),\n",
       " tensor(1),\n",
       " tensor(3816))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiTIMED_Data_test.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da67c8",
   "metadata": {},
   "source": [
    "### Full DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ec2d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalSurvivalDataset(Dataset):\n",
    "    def __init__(self, HiTIMED_dataset, DNAM_dataset, WSI_dataset, transform=None):\n",
    "        self.HiTIMED_dataset = HiTIMED_dataset\n",
    "        self.DNAM_dataset = DNAM_dataset\n",
    "        self.WSI_dataset = WSI_dataset\n",
    "        self.n_samples = len(WSI_dataset.samples)\n",
    "    \n",
    "    def get(): pass\n",
    "    def len(): pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        HiTIMED_data, HiTIMED_demog, HiTIMED_event, HiTIMED_time = self.HiTIMED_dataset.__getitem__(idx)\n",
    "        DNAM_data, DNAM_demog, DNAM_time, DNAM_event = self.DNAM_dataset.__getitem__(idx)\n",
    "        WSI_object, WSI_demog = self.WSI_dataset.__getitem__(idx)\n",
    "        return HiTIMED_data, DNAM_data, WSI_object, DNAM_demog #WSI object will contain survival info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d074669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultimodalSurvivalDataset(HiTIMED_Data_train, DNAm_Data_train, train_dataset_wsi)\n",
    "val_dataset = MultimodalSurvivalDataset(HiTIMED_Data_val, DNAm_Data_val, val_dataset_wsi)\n",
    "test_dataset = MultimodalSurvivalDataset(HiTIMED_Data_test, DNAm_Data_test, test_dataset_wsi)\n",
    "#test_dataset_trunc_10year = MultimodalSurvivalDataset(HiTIMED_Data_test_trunc_10year, DNAm_Data_test_trunc_10year, test_dataset_wsi_trunc_10year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d92c80a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.1845e+01, 7.7456e+00, 1.2803e+00, 3.7420e+00, 0.0000e+00, 4.4559e-01,\n",
       "         0.0000e+00, 4.2453e-01, 1.8751e+00, 0.0000e+00, 6.3335e+00, 0.0000e+00,\n",
       "         3.0778e+00, 1.2034e+00, 2.0219e+00, 5.4564e-03, 0.0000e+00],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.9527, 0.9789, 0.9901, 0.9485, 0.8936, 0.8996, 0.9448, 0.7228, 0.8050,\n",
       "         0.5127, 0.8897, 0.9849, 0.0573, 0.9164, 0.8768, 0.4430, 0.1224, 0.3998,\n",
       "         0.8352, 0.5521, 0.0837, 0.7682, 0.2368, 0.1468, 0.1571, 0.1653, 0.6518,\n",
       "         0.8006, 0.4633, 0.8890, 0.8141, 0.5629, 0.1234, 0.2730, 0.1016, 0.0204,\n",
       "         0.6576, 0.6807, 0.1841, 0.4166, 0.2364, 0.9209, 0.9441, 0.1115, 0.7619,\n",
       "         0.3404, 0.4912, 0.8879, 0.4046, 0.1335, 0.8473, 0.0489, 0.8533, 0.7608,\n",
       "         0.9401, 0.7289, 0.8385, 0.4214, 0.8826, 0.2587, 0.0707, 0.3382, 0.8865,\n",
       "         0.7499, 0.0667, 0.2692, 0.3674, 0.7972, 0.9508, 0.6632, 0.1488, 0.1239,\n",
       "         0.7514, 0.1027, 0.2061, 0.9180, 0.1994, 0.4344, 0.0729, 0.8596, 0.4936,\n",
       "         0.1629, 0.9140, 0.3469, 0.1664, 0.6196, 0.5112, 0.3200, 0.1410, 0.2068,\n",
       "         0.5424, 0.8538, 0.8434, 0.2173, 0.3934, 0.8253, 0.2621, 0.8011, 0.7845,\n",
       "         0.7199, 0.2719, 0.8883, 0.6972, 0.0796, 0.1264, 0.8602, 0.0827, 0.5053,\n",
       "         0.8607, 0.0941, 0.1542, 0.1063, 0.6421, 0.7021, 0.0632, 0.4721, 0.1990,\n",
       "         0.3985, 0.8678, 0.4290, 0.9041, 0.9285, 0.2051, 0.0529, 0.1103, 0.0955,\n",
       "         0.8863, 0.8300, 0.1888, 0.8020, 0.4999, 0.5517, 0.8752, 0.8373],\n",
       "        dtype=torch.float64),\n",
       " Data(x=[21856, 2048], edge_index=[2, 196704], y=[21856, 2], pos=[21856, 2], censor=1, duration=674.0),\n",
       " tensor([ 1.0000, -1.0505,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34aeeb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([61.6124,  5.9809,  4.6928, 10.2977,  0.0000,  5.7941,  0.0000,  0.0000,\n",
       "          5.5801,  0.0000,  3.3890,  0.0000,  0.0000,  2.6528,  0.0000,  0.0000,\n",
       "          0.0000], dtype=torch.float64),\n",
       " tensor([0.8777, 0.7867, 0.8395, 0.8659, 0.7284, 0.8085, 0.8523, 0.7071, 0.5154,\n",
       "         0.3747, 0.8179, 0.8445, 0.0815, 0.9088, 0.8136, 0.6498, 0.1595, 0.3316,\n",
       "         0.3774, 0.8422, 0.1129, 0.7647, 0.3758, 0.2385, 0.1930, 0.2070, 0.6239,\n",
       "         0.8652, 0.7426, 0.9281, 0.7572, 0.5846, 0.2807, 0.2200, 0.1969, 0.0710,\n",
       "         0.7267, 0.7038, 0.2647, 0.5162, 0.3622, 0.7987, 0.7820, 0.1356, 0.6639,\n",
       "         0.3320, 0.4600, 0.7528, 0.5971, 0.2111, 0.7121, 0.1715, 0.8592, 0.7455,\n",
       "         0.8429, 0.7429, 0.6865, 0.5412, 0.7633, 0.3389, 0.3126, 0.3369, 0.8419,\n",
       "         0.7937, 0.1613, 0.1725, 0.4354, 0.8842, 0.8572, 0.7414, 0.2195, 0.2070,\n",
       "         0.8372, 0.1813, 0.3024, 0.8500, 0.2672, 0.4117, 0.2763, 0.7447, 0.5504,\n",
       "         0.2989, 0.7443, 0.2488, 0.1593, 0.7926, 0.4734, 0.4186, 0.1578, 0.3286,\n",
       "         0.7502, 0.8918, 0.9328, 0.3241, 0.4545, 0.8130, 0.3500, 0.7951, 0.6788,\n",
       "         0.7819, 0.3003, 0.8317, 0.5604, 0.1667, 0.1734, 0.6562, 0.1656, 0.7645,\n",
       "         0.6406, 0.0938, 0.2725, 0.2154, 0.6362, 0.7587, 0.1530, 0.8762, 0.1556,\n",
       "         0.5557, 0.8643, 0.6909, 0.7796, 0.8245, 0.5328, 0.1540, 0.2071, 0.2827,\n",
       "         0.8421, 0.9033, 0.6165, 0.8491, 0.7476, 0.7645, 0.8523, 0.8143],\n",
       "        dtype=torch.float64),\n",
       " Data(x=[7603, 2048], edge_index=[2, 68427], y=[7603, 2], pos=[7603, 2], censor=1, duration=3816.34497),\n",
       " tensor([1.0000, 0.7727, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98698e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/q/f0034wq/.conda/envs/GNN_test/lib/python3.7/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE)\n",
    "#test_loader_trunc_10year = DataLoader(test_dataset_trunc_10year, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e65b94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  0\n",
      "Data[0]:  tensor([[5.3723e+01, 1.0525e+01, 2.4747e+00, 9.9177e+00, 0.0000e+00, 2.8648e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.7601e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.6755e+00, 4.2313e+00, 1.9050e+00, 6.4561e-01, 5.2770e+00],\n",
      "        [5.9075e+01, 4.6627e+00, 2.5080e+00, 6.6199e+00, 0.0000e+00, 2.7878e+00,\n",
      "         0.0000e+00, 5.7515e-02, 4.4062e+00, 0.0000e+00, 4.1218e+00, 0.0000e+00,\n",
      "         7.6499e+00, 3.1343e+00, 2.1994e+00, 9.7504e-01, 1.8020e+00],\n",
      "        [8.2046e+01, 5.9681e+00, 7.6984e+00, 6.1584e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4037e+00, 0.0000e+00, 8.8469e-01, 3.8316e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.4714e+01, 7.7420e-01, 5.1775e+00, 3.1080e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7468e+00, 1.4109e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0346e+00, 0.0000e+00, 0.0000e+00, 1.0340e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6093, 0.9618, 0.9860, 0.8953, 0.7205, 0.7143, 0.9648, 0.5055, 0.6706,\n",
      "         0.8266, 0.6961, 0.5201, 0.0806, 0.9402, 0.6201, 0.2251, 0.1451, 0.6457,\n",
      "         0.8992, 0.5161, 0.0757, 0.8307, 0.4505, 0.3592, 0.2395, 0.2607, 0.8733,\n",
      "         0.8168, 0.9590, 0.8375, 0.4990, 0.6702, 0.5058, 0.7515, 0.2029, 0.0289,\n",
      "         0.7724, 0.5353, 0.5765, 0.8898, 0.8971, 0.6743, 0.8037, 0.3953, 0.5742,\n",
      "         0.8851, 0.8849, 0.6636, 0.6241, 0.3833, 0.6511, 0.0969, 0.6535, 0.4598,\n",
      "         0.7479, 0.6082, 0.6502, 0.8107, 0.6701, 0.3720, 0.4447, 0.7901, 0.6841,\n",
      "         0.6842, 0.7283, 0.3832, 0.8029, 0.7225, 0.9504, 0.6194, 0.2013, 0.5305,\n",
      "         0.8865, 0.0603, 0.3910, 0.6566, 0.7083, 0.8884, 0.1721, 0.9549, 0.9354,\n",
      "         0.6539, 0.8838, 0.4799, 0.3558, 0.9496, 0.4547, 0.4851, 0.2646, 0.3828,\n",
      "         0.5368, 0.5081, 0.6460, 0.3523, 0.8379, 0.6388, 0.8259, 0.6032, 0.8180,\n",
      "         0.8468, 0.5122, 0.7825, 0.6001, 0.1472, 0.2735, 0.8235, 0.3021, 0.6429,\n",
      "         0.5899, 0.0711, 0.2853, 0.1117, 0.5468, 0.5361, 0.1000, 0.6909, 0.4648,\n",
      "         0.8874, 0.8607, 0.8125, 0.9352, 0.9260, 0.6319, 0.1217, 0.2026, 0.3639,\n",
      "         0.8467, 0.8578, 0.9420, 0.9572, 0.5627, 0.6666, 0.6453, 0.7752],\n",
      "        [0.9208, 0.9801, 0.9891, 0.5663, 0.8576, 0.9528, 0.9807, 0.7836, 0.7840,\n",
      "         0.5350, 0.9217, 0.5832, 0.0133, 0.9189, 0.8900, 0.3092, 0.0881, 0.3509,\n",
      "         0.7670, 0.7106, 0.0771, 0.7918, 0.2655, 0.2614, 0.1504, 0.2481, 0.4411,\n",
      "         0.5672, 0.7620, 0.8890, 0.7896, 0.3748, 0.2212, 0.6266, 0.1175, 0.0415,\n",
      "         0.6607, 0.6166, 0.2812, 0.8211, 0.4323, 0.8314, 0.9372, 0.1843, 0.7878,\n",
      "         0.3744, 0.7681, 0.8417, 0.4954, 0.2074, 0.6406, 0.0813, 0.8749, 0.6394,\n",
      "         0.9539, 0.6913, 0.8095, 0.7364, 0.8718, 0.3778, 0.1138, 0.5329, 0.9353,\n",
      "         0.8532, 0.0864, 0.2289, 0.4778, 0.8456, 0.9536, 0.6951, 0.1582, 0.2659,\n",
      "         0.9018, 0.0663, 0.2413, 0.9234, 0.3143, 0.7815, 0.1039, 0.8388, 0.5382,\n",
      "         0.1955, 0.8407, 0.3602, 0.2403, 0.9270, 0.3118, 0.4817, 0.1039, 0.1913,\n",
      "         0.6188, 0.7542, 0.8814, 0.3194, 0.6958, 0.6301, 0.3666, 0.8561, 0.5186,\n",
      "         0.8482, 0.3614, 0.9041, 0.7403, 0.0582, 0.1863, 0.5380, 0.1145, 0.4518,\n",
      "         0.8383, 0.1003, 0.2000, 0.1423, 0.3080, 0.6153, 0.0556, 0.6542, 0.1369,\n",
      "         0.5698, 0.8569, 0.5837, 0.9038, 0.8999, 0.2078, 0.0695, 0.1575, 0.2012,\n",
      "         0.7474, 0.7713, 0.3545, 0.9305, 0.7036, 0.7710, 0.6757, 0.8334],\n",
      "        [0.9677, 0.9808, 0.9893, 0.9638, 0.5174, 0.6063, 0.9779, 0.7892, 0.5540,\n",
      "         0.2634, 0.7983, 0.4804, 0.0138, 0.8616, 0.9006, 0.4549, 0.0455, 0.1890,\n",
      "         0.5185, 0.6553, 0.0437, 0.8620, 0.3564, 0.2494, 0.1370, 0.1509, 0.4672,\n",
      "         0.7980, 0.4465, 0.8498, 0.8271, 0.7507, 0.1472, 0.1456, 0.0802, 0.0217,\n",
      "         0.6156, 0.6175, 0.1637, 0.4878, 0.4738, 0.6628, 0.5836, 0.1409, 0.3611,\n",
      "         0.3089, 0.5045, 0.7539, 0.2216, 0.0999, 0.8897, 0.1643, 0.5658, 0.6606,\n",
      "         0.7049, 0.3868, 0.7795, 0.3365, 0.8862, 0.6053, 0.0856, 0.1537, 0.9337,\n",
      "         0.5425, 0.0529, 0.2056, 0.1603, 0.7360, 0.9508, 0.6172, 0.3873, 0.2409,\n",
      "         0.8350, 0.0371, 0.3165, 0.8756, 0.0700, 0.4028, 0.0930, 0.5279, 0.4794,\n",
      "         0.1214, 0.8801, 0.2628, 0.1213, 0.6013, 0.4906, 0.2703, 0.1323, 0.1570,\n",
      "         0.5518, 0.7185, 0.8449, 0.1908, 0.2003, 0.7783, 0.4292, 0.4584, 0.7938,\n",
      "         0.8636, 0.2623, 0.7751, 0.6264, 0.0873, 0.1636, 0.7268, 0.0984, 0.7560,\n",
      "         0.7988, 0.0552, 0.1280, 0.2603, 0.6657, 0.5128, 0.0502, 0.8549, 0.2760,\n",
      "         0.3180, 0.9165, 0.8319, 0.9658, 0.9238, 0.2452, 0.0729, 0.1058, 0.1959,\n",
      "         0.8153, 0.8624, 0.8279, 0.6956, 0.3531, 0.3430, 0.8794, 0.8984],\n",
      "        [0.9230, 0.9776, 0.9892, 0.9470, 0.9356, 0.9611, 0.9812, 0.8737, 0.6897,\n",
      "         0.1820, 0.9523, 0.8771, 0.1937, 0.9433, 0.9027, 0.7153, 0.0891, 0.1956,\n",
      "         0.2755, 0.7542, 0.0561, 0.9009, 0.2000, 0.0869, 0.1064, 0.1828, 0.7231,\n",
      "         0.8859, 0.6960, 0.8555, 0.7858, 0.7269, 0.1349, 0.3207, 0.0562, 0.0278,\n",
      "         0.7208, 0.7190, 0.1254, 0.3293, 0.1900, 0.8754, 0.9477, 0.0977, 0.8138,\n",
      "         0.2814, 0.5000, 0.9141, 0.4789, 0.1140, 0.6933, 0.0423, 0.8812, 0.8184,\n",
      "         0.8943, 0.7764, 0.7691, 0.6837, 0.9101, 0.1875, 0.0528, 0.1858, 0.9437,\n",
      "         0.8260, 0.0764, 0.1379, 0.2438, 0.6213, 0.9301, 0.7381, 0.2713, 0.1073,\n",
      "         0.9025, 0.0528, 0.2036, 0.9201, 0.2808, 0.4199, 0.0555, 0.5317, 0.5000,\n",
      "         0.0818, 0.9269, 0.3035, 0.0901, 0.8974, 0.7170, 0.2349, 0.1178, 0.1094,\n",
      "         0.8339, 0.8707, 0.8634, 0.2550, 0.2400, 0.8573, 0.2108, 0.7583, 0.9357,\n",
      "         0.9493, 0.1444, 0.8715, 0.7587, 0.1399, 0.1040, 0.8543, 0.0844, 0.7962,\n",
      "         0.8588, 0.0615, 0.1585, 0.0739, 0.8591, 0.7371, 0.0441, 0.8706, 0.2109,\n",
      "         0.3174, 0.8119, 0.5307, 0.9239, 0.9335, 0.1366, 0.0617, 0.1114, 0.1138,\n",
      "         0.8892, 0.8990, 0.7711, 0.8674, 0.9075, 0.9452, 0.8010, 0.9091]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[129219, 2048], edge_index=[2, 1162971], y=[129219, 2], pos=[129219, 2], censor=[4], duration=[4], batch=[129219], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  1.0185,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.7509,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.7726,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.2137,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  1\n",
      "Data[0]:  tensor([[6.4745e+01, 6.8940e+00, 6.8996e+00, 6.7568e+00, 0.0000e+00, 4.2879e-01,\n",
      "         0.0000e+00, 3.8299e+00, 2.8983e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.6253e+00, 7.0200e-01, 2.1982e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.0463e+01, 3.7333e+00, 1.6012e+00, 5.8941e+00, 0.0000e+00, 1.1276e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1968e-01, 0.0000e+00,\n",
      "         5.0845e+00, 4.0040e-01, 7.6792e-01, 3.8125e-01, 1.2414e+00],\n",
      "        [7.2710e+01, 5.4105e+00, 7.3895e+00, 6.3156e+00, 0.0000e+00, 1.2761e+00,\n",
      "         0.0000e+00, 1.9979e-01, 5.0692e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.6297e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.5723e+01, 1.1666e+01, 0.0000e+00, 5.1085e+00, 6.3237e-01, 6.6140e-01,\n",
      "         0.0000e+00, 4.2720e+00, 1.0018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.8714e+00, 2.8172e+00, 9.1432e-01, 2.3336e-02, 2.1081e-01]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6358, 0.9802, 0.9892, 0.9417, 0.8766, 0.8858, 0.9788, 0.6202, 0.6752,\n",
      "         0.4841, 0.9254, 0.4719, 0.0183, 0.9487, 0.8778, 0.4554, 0.1273, 0.2963,\n",
      "         0.8296, 0.6148, 0.0701, 0.8492, 0.4598, 0.1970, 0.3211, 0.1768, 0.6901,\n",
      "         0.6871, 0.9249, 0.8919, 0.5771, 0.7787, 0.2494, 0.4076, 0.1266, 0.0464,\n",
      "         0.3661, 0.6217, 0.2658, 0.9050, 0.8733, 0.6351, 0.9401, 0.1642, 0.2644,\n",
      "         0.3667, 0.8818, 0.3007, 0.2467, 0.1616, 0.8042, 0.2918, 0.6794, 0.6260,\n",
      "         0.8765, 0.4838, 0.4294, 0.7853, 0.8569, 0.6221, 0.1827, 0.5283, 0.6039,\n",
      "         0.7910, 0.1188, 0.1698, 0.3997, 0.7496, 0.9354, 0.5028, 0.5877, 0.2465,\n",
      "         0.9086, 0.0659, 0.4831, 0.8477, 0.1560, 0.8398, 0.0401, 0.9444, 0.8715,\n",
      "         0.1525, 0.8611, 0.3326, 0.2222, 0.9479, 0.5013, 0.4414, 0.1310, 0.2920,\n",
      "         0.3803, 0.8043, 0.8444, 0.3696, 0.3337, 0.7297, 0.8038, 0.8101, 0.6014,\n",
      "         0.7282, 0.2635, 0.7526, 0.5785, 0.0799, 0.1723, 0.8233, 0.0828, 0.3265,\n",
      "         0.6897, 0.2269, 0.1809, 0.1230, 0.5425, 0.5976, 0.0453, 0.5326, 0.2172,\n",
      "         0.8699, 0.8461, 0.7837, 0.9436, 0.8850, 0.7174, 0.1160, 0.1878, 0.2659,\n",
      "         0.9009, 0.8557, 0.9225, 0.9589, 0.3440, 0.3235, 0.7262, 0.8904],\n",
      "        [0.7315, 0.9537, 0.9808, 0.8678, 0.8699, 0.7549, 0.9283, 0.5580, 0.2316,\n",
      "         0.6052, 0.8010, 0.8162, 0.0152, 0.9381, 0.6693, 0.4264, 0.0567, 0.7936,\n",
      "         0.8408, 0.8260, 0.0657, 0.8613, 0.6135, 0.2615, 0.4923, 0.2815, 0.9048,\n",
      "         0.7511, 0.9522, 0.9137, 0.6681, 0.5162, 0.7242, 0.8859, 0.0836, 0.1533,\n",
      "         0.8031, 0.5499, 0.8268, 0.3688, 0.8971, 0.9008, 0.9369, 0.5555, 0.8681,\n",
      "         0.5784, 0.9238, 0.9209, 0.7103, 0.2877, 0.8821, 0.7753, 0.9205, 0.6369,\n",
      "         0.9451, 0.3716, 0.8150, 0.9266, 0.9227, 0.4827, 0.0721, 0.7983, 0.9466,\n",
      "         0.8406, 0.7442, 0.4534, 0.8443, 0.7167, 0.7608, 0.6356, 0.3452, 0.4339,\n",
      "         0.9350, 0.5305, 0.5690, 0.9149, 0.8182, 0.9333, 0.4852, 0.9394, 0.9195,\n",
      "         0.5688, 0.9161, 0.7267, 0.1914, 0.9468, 0.8214, 0.7687, 0.2450, 0.5819,\n",
      "         0.8173, 0.8331, 0.8680, 0.7798, 0.7636, 0.8122, 0.8135, 0.9156, 0.6006,\n",
      "         0.9448, 0.3259, 0.9459, 0.7732, 0.1364, 0.2388, 0.5087, 0.3582, 0.3163,\n",
      "         0.8833, 0.0684, 0.3465, 0.6302, 0.7853, 0.7646, 0.0622, 0.7822, 0.6869,\n",
      "         0.7759, 0.8786, 0.9013, 0.9129, 0.9044, 0.8092, 0.5902, 0.5909, 0.2860,\n",
      "         0.9097, 0.8203, 0.9298, 0.9137, 0.8671, 0.8714, 0.4848, 0.7826],\n",
      "        [0.4787, 0.9491, 0.6059, 0.8969, 0.5718, 0.8324, 0.9597, 0.4929, 0.7153,\n",
      "         0.5380, 0.8500, 0.8884, 0.0222, 0.9224, 0.8621, 0.6571, 0.3129, 0.5299,\n",
      "         0.5453, 0.6682, 0.0826, 0.7201, 0.3139, 0.1567, 0.5017, 0.2369, 0.7333,\n",
      "         0.8878, 0.8336, 0.9063, 0.6271, 0.3658, 0.4305, 0.3279, 0.1647, 0.0302,\n",
      "         0.3770, 0.6311, 0.3330, 0.7286, 0.2606, 0.7381, 0.9365, 0.1529, 0.6536,\n",
      "         0.3777, 0.5356, 0.6720, 0.7815, 0.1321, 0.8720, 0.0863, 0.7821, 0.6405,\n",
      "         0.9104, 0.6269, 0.6727, 0.7885, 0.8426, 0.6870, 0.2650, 0.1906, 0.8825,\n",
      "         0.7152, 0.1314, 0.6736, 0.3561, 0.8255, 0.9394, 0.6932, 0.2003, 0.4398,\n",
      "         0.8968, 0.0573, 0.3708, 0.8670, 0.6989, 0.9389, 0.1169, 0.9144, 0.9358,\n",
      "         0.2449, 0.7487, 0.2797, 0.1965, 0.9457, 0.4904, 0.3677, 0.4931, 0.3146,\n",
      "         0.6336, 0.7130, 0.8432, 0.3403, 0.6375, 0.7714, 0.6564, 0.8071, 0.5919,\n",
      "         0.8946, 0.2475, 0.9370, 0.6452, 0.2063, 0.4245, 0.4465, 0.1307, 0.8549,\n",
      "         0.7784, 0.0823, 0.1748, 0.5570, 0.5927, 0.6773, 0.0867, 0.7380, 0.8173,\n",
      "         0.6211, 0.8754, 0.8126, 0.8867, 0.9037, 0.7133, 0.1918, 0.2606, 0.2462,\n",
      "         0.7679, 0.8534, 0.3541, 0.8704, 0.7087, 0.7412, 0.8842, 0.9271],\n",
      "        [0.8599, 0.9866, 0.9655, 0.7107, 0.9101, 0.9511, 0.9875, 0.7502, 0.7684,\n",
      "         0.2874, 0.8600, 0.9872, 0.0149, 0.9500, 0.7930, 0.1960, 0.5791, 0.7372,\n",
      "         0.6432, 0.5343, 0.0699, 0.8373, 0.2620, 0.3951, 0.3144, 0.1972, 0.8839,\n",
      "         0.8051, 0.6373, 0.8984, 0.7418, 0.7477, 0.2050, 0.7610, 0.1028, 0.0307,\n",
      "         0.7669, 0.6095, 0.2534, 0.4960, 0.3131, 0.8684, 0.9555, 0.2268, 0.7423,\n",
      "         0.6234, 0.7196, 0.7831, 0.7834, 0.2698, 0.7195, 0.2127, 0.8131, 0.6038,\n",
      "         0.9318, 0.6279, 0.7605, 0.4404, 0.9146, 0.7640, 0.1239, 0.5337, 0.9079,\n",
      "         0.7975, 0.0721, 0.5998, 0.2266, 0.6995, 0.9090, 0.7339, 0.1508, 0.1587,\n",
      "         0.9174, 0.1406, 0.1883, 0.8327, 0.4539, 0.8113, 0.0462, 0.9535, 0.7993,\n",
      "         0.2235, 0.9157, 0.4013, 0.1365, 0.9505, 0.5014, 0.5681, 0.1487, 0.2264,\n",
      "         0.5224, 0.8645, 0.7889, 0.4397, 0.6178, 0.8198, 0.4101, 0.8582, 0.8798,\n",
      "         0.9224, 0.4523, 0.9220, 0.7487, 0.1407, 0.1843, 0.5106, 0.2390, 0.4175,\n",
      "         0.8923, 0.0733, 0.1839, 0.1722, 0.7322, 0.7381, 0.0857, 0.8327, 0.4062,\n",
      "         0.5835, 0.8886, 0.5869, 0.9556, 0.8731, 0.3409, 0.0578, 0.1198, 0.1793,\n",
      "         0.8375, 0.8918, 0.7882, 0.9128, 0.7534, 0.8520, 0.7533, 0.9129]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[58009, 2048], edge_index=[2, 522081], y=[58009, 2], pos=[58009, 2], censor=[4], duration=[4], batch=[58009], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  0.7243,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.4551,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0959,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.7596,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2\n",
      "Data[0]:  tensor([[8.9090e+01, 0.0000e+00, 3.4066e+00, 2.0424e+00, 0.0000e+00, 7.7873e-01,\n",
      "         0.0000e+00, 3.1267e-01, 5.0320e-01, 0.0000e+00, 0.0000e+00, 1.2247e+00,\n",
      "         0.0000e+00, 5.7404e-02, 1.0112e+00, 3.7418e-01, 1.1992e+00],\n",
      "        [9.2661e+01, 3.1168e+00, 1.6659e+00, 0.0000e+00, 0.0000e+00, 8.9790e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6589e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.0463e+01, 3.7333e+00, 1.6012e+00, 5.8941e+00, 0.0000e+00, 1.1276e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1968e-01, 0.0000e+00,\n",
      "         5.0845e+00, 4.0040e-01, 7.6792e-01, 3.8125e-01, 1.2414e+00],\n",
      "        [6.6185e+01, 5.8012e+00, 0.0000e+00, 9.2839e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.3580e-01, 5.6768e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.9619e+00, 9.5958e-01, 8.9220e-01, 9.0573e-01, 7.2073e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9776, 0.9870, 0.9897, 0.9689, 0.9464, 0.9695, 0.9869, 0.9647, 0.7666,\n",
      "         0.0458, 0.9799, 0.9881, 0.0154, 0.9685, 0.9747, 0.8278, 0.0412, 0.1604,\n",
      "         0.2679, 0.8534, 0.0497, 0.7715, 0.1214, 0.0786, 0.1150, 0.1740, 0.8310,\n",
      "         0.8834, 0.3855, 0.8922, 0.8975, 0.6351, 0.0953, 0.0653, 0.0592, 0.0253,\n",
      "         0.8580, 0.7711, 0.0862, 0.8538, 0.1089, 0.8433, 0.7051, 0.0529, 0.8424,\n",
      "         0.1137, 0.4425, 0.9250, 0.2801, 0.0862, 0.8812, 0.0327, 0.8669, 0.8098,\n",
      "         0.9033, 0.7775, 0.9098, 0.4221, 0.8957, 0.2592, 0.0544, 0.1393, 0.9604,\n",
      "         0.8887, 0.0430, 0.1420, 0.1285, 0.8667, 0.9610, 0.7867, 0.0845, 0.0807,\n",
      "         0.9192, 0.0343, 0.2197, 0.9086, 0.0670, 0.2090, 0.0408, 0.6368, 0.1172,\n",
      "         0.0691, 0.9568, 0.1392, 0.0928, 0.8279, 0.6688, 0.1474, 0.0789, 0.0848,\n",
      "         0.9112, 0.7399, 0.8717, 0.1705, 0.1416, 0.8566, 0.1261, 0.8335, 0.8984,\n",
      "         0.9096, 0.0898, 0.8869, 0.8312, 0.0704, 0.0844, 0.8608, 0.0467, 0.8534,\n",
      "         0.8835, 0.0700, 0.0899, 0.1192, 0.7835, 0.7390, 0.0379, 0.5276, 0.1151,\n",
      "         0.3554, 0.9051, 0.2762, 0.9568, 0.9522, 0.1024, 0.0438, 0.0604, 0.0966,\n",
      "         0.8705, 0.9197, 0.5868, 0.8493, 0.6969, 0.8057, 0.9559, 0.9117],\n",
      "        [0.1647, 0.9143, 0.2404, 0.3356, 0.0641, 0.9655, 0.7006, 0.0548, 0.1995,\n",
      "         0.5129, 0.2330, 0.9852, 0.0097, 0.9291, 0.6496, 0.4452, 0.5526, 0.5858,\n",
      "         0.8897, 0.8913, 0.0978, 0.1567, 0.4413, 0.1342, 0.5347, 0.1903, 0.4853,\n",
      "         0.2398, 0.7383, 0.7969, 0.1152, 0.1198, 0.1175, 0.1675, 0.1847, 0.0432,\n",
      "         0.0520, 0.6437, 0.1153, 0.8955, 0.5626, 0.1823, 0.8252, 0.1790, 0.1217,\n",
      "         0.8898, 0.5401, 0.2186, 0.8930, 0.1034, 0.9048, 0.1156, 0.3444, 0.6985,\n",
      "         0.4116, 0.4296, 0.2213, 0.9554, 0.6246, 0.6006, 0.3918, 0.5984, 0.9592,\n",
      "         0.1801, 0.8208, 0.5214, 0.9186, 0.6128, 0.9500, 0.2123, 0.0707, 0.4946,\n",
      "         0.8184, 0.0263, 0.5861, 0.4850, 0.0351, 0.6700, 0.4804, 0.8981, 0.7619,\n",
      "         0.7576, 0.8911, 0.6825, 0.7432, 0.9545, 0.1192, 0.1214, 0.3304, 0.0493,\n",
      "         0.0426, 0.2306, 0.8275, 0.1468, 0.5834, 0.1021, 0.1154, 0.2832, 0.0629,\n",
      "         0.7274, 0.9033, 0.2306, 0.6614, 0.0413, 0.6360, 0.7406, 0.7869, 0.0584,\n",
      "         0.4205, 0.0685, 0.2871, 0.1020, 0.0764, 0.0945, 0.0669, 0.2311, 0.3710,\n",
      "         0.5335, 0.5111, 0.4427, 0.9380, 0.7024, 0.0996, 0.1169, 0.1715, 0.1206,\n",
      "         0.7578, 0.6423, 0.8828, 0.9566, 0.0666, 0.0765, 0.1030, 0.1686],\n",
      "        [0.7315, 0.9537, 0.9808, 0.8678, 0.8699, 0.7549, 0.9283, 0.5580, 0.2316,\n",
      "         0.6052, 0.8010, 0.8162, 0.0152, 0.9381, 0.6693, 0.4264, 0.0567, 0.7936,\n",
      "         0.8408, 0.8260, 0.0657, 0.8613, 0.6135, 0.2615, 0.4923, 0.2815, 0.9048,\n",
      "         0.7511, 0.9522, 0.9137, 0.6681, 0.5162, 0.7242, 0.8859, 0.0836, 0.1533,\n",
      "         0.8031, 0.5499, 0.8268, 0.3688, 0.8971, 0.9008, 0.9369, 0.5555, 0.8681,\n",
      "         0.5784, 0.9238, 0.9209, 0.7103, 0.2877, 0.8821, 0.7753, 0.9205, 0.6369,\n",
      "         0.9451, 0.3716, 0.8150, 0.9266, 0.9227, 0.4827, 0.0721, 0.7983, 0.9466,\n",
      "         0.8406, 0.7442, 0.4534, 0.8443, 0.7167, 0.7608, 0.6356, 0.3452, 0.4339,\n",
      "         0.9350, 0.5305, 0.5690, 0.9149, 0.8182, 0.9333, 0.4852, 0.9394, 0.9195,\n",
      "         0.5688, 0.9161, 0.7267, 0.1914, 0.9468, 0.8214, 0.7687, 0.2450, 0.5819,\n",
      "         0.8173, 0.8331, 0.8680, 0.7798, 0.7636, 0.8122, 0.8135, 0.9156, 0.6006,\n",
      "         0.9448, 0.3259, 0.9459, 0.7732, 0.1364, 0.2388, 0.5087, 0.3582, 0.3163,\n",
      "         0.8833, 0.0684, 0.3465, 0.6302, 0.7853, 0.7646, 0.0622, 0.7822, 0.6869,\n",
      "         0.7759, 0.8786, 0.9013, 0.9129, 0.9044, 0.8092, 0.5902, 0.5909, 0.2860,\n",
      "         0.9097, 0.8203, 0.9298, 0.9137, 0.8671, 0.8714, 0.4848, 0.7826],\n",
      "        [0.8796, 0.9844, 0.9849, 0.9540, 0.7799, 0.7552, 0.9640, 0.2768, 0.2309,\n",
      "         0.8781, 0.3045, 0.8980, 0.0098, 0.9082, 0.9384, 0.2503, 0.3276, 0.3383,\n",
      "         0.9294, 0.1547, 0.0684, 0.5140, 0.4443, 0.2799, 0.2236, 0.2079, 0.4023,\n",
      "         0.8690, 0.9046, 0.8991, 0.6452, 0.5762, 0.2418, 0.5741, 0.0769, 0.0253,\n",
      "         0.5534, 0.1958, 0.3234, 0.8931, 0.9264, 0.2077, 0.8472, 0.0834, 0.4328,\n",
      "         0.6776, 0.9547, 0.3812, 0.6199, 0.2643, 0.7054, 0.0608, 0.3193, 0.1214,\n",
      "         0.8613, 0.3681, 0.5536, 0.8889, 0.3036, 0.6909, 0.2419, 0.7089, 0.6440,\n",
      "         0.2934, 0.1236, 0.4264, 0.8290, 0.6806, 0.9619, 0.6955, 0.6969, 0.3602,\n",
      "         0.9128, 0.0390, 0.4618, 0.9434, 0.6808, 0.9019, 0.1446, 0.9446, 0.9530,\n",
      "         0.1377, 0.9071, 0.4061, 0.1947, 0.9348, 0.7575, 0.5097, 0.3172, 0.3361,\n",
      "         0.1496, 0.8115, 0.8853, 0.4959, 0.8849, 0.7400, 0.8387, 0.8362, 0.3048,\n",
      "         0.4025, 0.7665, 0.9399, 0.4113, 0.1064, 0.4381, 0.8539, 0.4634, 0.7179,\n",
      "         0.2104, 0.1172, 0.1082, 0.1240, 0.1798, 0.5758, 0.0436, 0.9234, 0.4102,\n",
      "         0.9449, 0.8209, 0.7809, 0.9349, 0.6089, 0.7320, 0.3742, 0.2318, 0.5248,\n",
      "         0.7018, 0.8751, 0.9619, 0.9613, 0.1428, 0.1734, 0.8204, 0.9173]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[64811, 2048], edge_index=[2, 583299], y=[64811, 2], pos=[64811, 2], censor=[4], duration=[4], batch=[64811], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -1.9038,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.8382,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.4551,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -1.2844,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  3\n",
      "Data[0]:  tensor([[83.8559,  1.4866,  9.4517,  0.8653,  0.0000,  0.3579,  0.0000,  1.3853,\n",
      "          0.2274,  0.0000,  0.2031,  0.0000,  0.0000,  0.0000,  2.1669,  0.0000,\n",
      "          0.0000],\n",
      "        [53.3232,  7.1235,  0.0000,  6.4013,  0.4966,  1.5888,  0.0000,  0.8922,\n",
      "          2.2430,  0.0000,  2.3773,  0.0000, 14.4551,  3.0191,  0.0000,  0.1873,\n",
      "          7.8925],\n",
      "        [50.9116,  5.9793,  0.8958,  5.7391,  0.0000,  3.3608,  0.0000,  1.1088,\n",
      "          1.1875,  0.0000, 13.7089,  0.0000,  8.1491,  0.8514,  0.7965,  1.6484,\n",
      "          5.6629],\n",
      "        [66.5431,  4.9285,  0.0000,  6.0226,  0.0000,  8.7797,  0.0000,  0.1416,\n",
      "          0.4229,  0.0000,  7.6206,  0.0000,  4.6685,  0.8723,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9495, 0.9783, 0.9893, 0.9510, 0.9523, 0.9491, 0.9839, 0.8058, 0.7358,\n",
      "         0.0778, 0.9788, 0.8840, 0.0157, 0.9562, 0.9286, 0.8286, 0.0466, 0.2021,\n",
      "         0.3844, 0.8348, 0.0930, 0.8943, 0.1116, 0.0851, 0.1101, 0.1717, 0.7732,\n",
      "         0.8265, 0.5146, 0.9095, 0.8866, 0.5858, 0.1046, 0.1103, 0.0526, 0.0483,\n",
      "         0.6693, 0.7553, 0.1113, 0.6688, 0.2089, 0.8829, 0.7921, 0.1077, 0.7708,\n",
      "         0.1447, 0.4273, 0.8667, 0.1455, 0.0877, 0.8554, 0.0583, 0.9320, 0.7717,\n",
      "         0.8588, 0.6306, 0.7399, 0.3323, 0.9300, 0.1777, 0.0528, 0.2056, 0.9551,\n",
      "         0.8932, 0.0575, 0.1750, 0.1591, 0.7959, 0.9515, 0.5630, 0.0878, 0.1085,\n",
      "         0.7688, 0.0608, 0.1870, 0.8755, 0.0843, 0.2425, 0.0640, 0.6951, 0.1783,\n",
      "         0.0932, 0.9244, 0.2071, 0.0927, 0.5867, 0.6428, 0.2344, 0.0968, 0.1103,\n",
      "         0.7695, 0.8833, 0.8612, 0.1920, 0.1641, 0.7912, 0.2842, 0.7500, 0.9167,\n",
      "         0.9613, 0.1181, 0.8779, 0.7336, 0.0579, 0.1400, 0.8091, 0.0665, 0.7759,\n",
      "         0.8983, 0.0804, 0.0890, 0.1426, 0.8282, 0.6668, 0.0456, 0.6739, 0.1184,\n",
      "         0.2796, 0.8481, 0.4319, 0.9637, 0.9517, 0.1246, 0.0535, 0.0788, 0.0817,\n",
      "         0.8781, 0.8077, 0.1773, 0.7249, 0.7625, 0.8826, 0.9035, 0.9225],\n",
      "        [0.6947, 0.9755, 0.9817, 0.6231, 0.7660, 0.9259, 0.9416, 0.3572, 0.8138,\n",
      "         0.5143, 0.9161, 0.9346, 0.0176, 0.9182, 0.5440, 0.2726, 0.5754, 0.3759,\n",
      "         0.8932, 0.3612, 0.0841, 0.7789, 0.4117, 0.4687, 0.4479, 0.3321, 0.5897,\n",
      "         0.6626, 0.9242, 0.8953, 0.5162, 0.6950, 0.1952, 0.8285, 0.1194, 0.0353,\n",
      "         0.7313, 0.4064, 0.5310, 0.9064, 0.8930, 0.6721, 0.8216, 0.1534, 0.4904,\n",
      "         0.8486, 0.9275, 0.5643, 0.6367, 0.3291, 0.5769, 0.1268, 0.8106, 0.3448,\n",
      "         0.8734, 0.6490, 0.6515, 0.8438, 0.7781, 0.6759, 0.4140, 0.8209, 0.7141,\n",
      "         0.8256, 0.6552, 0.4786, 0.6859, 0.8602, 0.9622, 0.7570, 0.4204, 0.5084,\n",
      "         0.9262, 0.1139, 0.4857, 0.8651, 0.5437, 0.8325, 0.4338, 0.9551, 0.9359,\n",
      "         0.1918, 0.6944, 0.6639, 0.2304, 0.9643, 0.4220, 0.7703, 0.2535, 0.2416,\n",
      "         0.1534, 0.8098, 0.8531, 0.4622, 0.8096, 0.8278, 0.6646, 0.7792, 0.4897,\n",
      "         0.8629, 0.6594, 0.8059, 0.7274, 0.1101, 0.4704, 0.8229, 0.4424, 0.5833,\n",
      "         0.6356, 0.0907, 0.3371, 0.2907, 0.3796, 0.3563, 0.0683, 0.4400, 0.3994,\n",
      "         0.8949, 0.8152, 0.7103, 0.7937, 0.8902, 0.4934, 0.4344, 0.1483, 0.2930,\n",
      "         0.5537, 0.8742, 0.9533, 0.9523, 0.2629, 0.3046, 0.5556, 0.4780],\n",
      "        [0.8367, 0.9746, 0.9835, 0.9215, 0.6607, 0.8777, 0.9671, 0.6673, 0.6946,\n",
      "         0.4640, 0.8593, 0.6009, 0.0352, 0.9267, 0.6154, 0.3045, 0.2122, 0.4337,\n",
      "         0.7900, 0.5677, 0.0783, 0.7349, 0.2609, 0.3094, 0.2661, 0.2887, 0.5347,\n",
      "         0.7596, 0.9202, 0.8699, 0.6796, 0.4730, 0.1501, 0.5428, 0.1259, 0.0544,\n",
      "         0.7305, 0.3998, 0.5201, 0.8822, 0.8377, 0.6290, 0.8387, 0.3226, 0.7696,\n",
      "         0.6736, 0.7975, 0.5936, 0.2332, 0.3009, 0.7467, 0.3255, 0.7801, 0.3737,\n",
      "         0.7757, 0.5207, 0.5426, 0.7564, 0.7468, 0.3909, 0.2042, 0.6068, 0.8958,\n",
      "         0.7170, 0.1549, 0.2792, 0.5477, 0.7508, 0.9404, 0.5131, 0.2775, 0.2780,\n",
      "         0.8903, 0.1536, 0.4895, 0.8187, 0.4895, 0.7344, 0.1727, 0.9625, 0.9414,\n",
      "         0.2046, 0.8666, 0.6145, 0.4450, 0.9408, 0.5488, 0.7207, 0.1702, 0.2706,\n",
      "         0.5362, 0.7228, 0.8439, 0.4197, 0.6725, 0.7619, 0.7002, 0.7279, 0.6112,\n",
      "         0.6458, 0.5137, 0.7987, 0.6849, 0.0829, 0.3970, 0.8515, 0.2648, 0.5936,\n",
      "         0.7305, 0.0913, 0.1787, 0.1759, 0.2920, 0.4665, 0.0753, 0.5208, 0.1574,\n",
      "         0.5950, 0.7601, 0.7014, 0.8131, 0.8538, 0.5406, 0.0715, 0.2739, 0.2298,\n",
      "         0.7933, 0.6803, 0.8369, 0.9661, 0.3812, 0.4266, 0.7638, 0.9178],\n",
      "        [0.8680, 0.9711, 0.9722, 0.9064, 0.3487, 0.8523, 0.9652, 0.3837, 0.5896,\n",
      "         0.5333, 0.7647, 0.6700, 0.0234, 0.8752, 0.8880, 0.4378, 0.1208, 0.3540,\n",
      "         0.5346, 0.6126, 0.0717, 0.8437, 0.2986, 0.2360, 0.1952, 0.2092, 0.5230,\n",
      "         0.5171, 0.7275, 0.8043, 0.6601, 0.6084, 0.2590, 0.4342, 0.1911, 0.0276,\n",
      "         0.5565, 0.6229, 0.3617, 0.6245, 0.4075, 0.6860, 0.9315, 0.1798, 0.6700,\n",
      "         0.4340, 0.6317, 0.8047, 0.4052, 0.1851, 0.7804, 0.0736, 0.6597, 0.6191,\n",
      "         0.7719, 0.6304, 0.7736, 0.5050, 0.8078, 0.3244, 0.2494, 0.2524, 0.8725,\n",
      "         0.5662, 0.1459, 0.3277, 0.3762, 0.7139, 0.8480, 0.6069, 0.1387, 0.2269,\n",
      "         0.7336, 0.0728, 0.2918, 0.8312, 0.1713, 0.5512, 0.0557, 0.5950, 0.4861,\n",
      "         0.2542, 0.8605, 0.3422, 0.2590, 0.8957, 0.4073, 0.4750, 0.1730, 0.2711,\n",
      "         0.2960, 0.7930, 0.6208, 0.3642, 0.3682, 0.7568, 0.3510, 0.5879, 0.7905,\n",
      "         0.7139, 0.3129, 0.7302, 0.6492, 0.0781, 0.1598, 0.5137, 0.0922, 0.6730,\n",
      "         0.7490, 0.0921, 0.2452, 0.1898, 0.2840, 0.5792, 0.0686, 0.6097, 0.2153,\n",
      "         0.4596, 0.8147, 0.4636, 0.9316, 0.8126, 0.2425, 0.1320, 0.2454, 0.2482,\n",
      "         0.7330, 0.8518, 0.3194, 0.9039, 0.6295, 0.6751, 0.7858, 0.8363]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[117536, 2048], edge_index=[2, 1057824], y=[117536, 2], pos=[117536, 2], censor=[4], duration=[4], batch=[117536], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -0.9675,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000, -0.4595,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.1806,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.9337,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  4\n",
      "Data[0]:  tensor([[63.3149,  1.2620,  0.0000,  2.4729,  0.0000,  1.1890,  0.0000,  1.2916,\n",
      "          1.7991,  0.6931, 16.2440,  0.0000, 10.4265,  1.3070,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [61.3703,  5.8863,  0.0000,  6.5615,  0.0000,  1.8614,  0.0000,  3.7958,\n",
      "          0.9421,  0.0000,  0.0000,  0.0000,  8.4631,  1.3064,  0.0000,  0.0000,\n",
      "          9.8133],\n",
      "        [57.3929,  9.0080,  3.0457,  5.4765,  0.0000,  5.9959,  0.0000,  1.8084,\n",
      "          3.1746,  0.0000,  5.5119,  0.0000,  3.1280,  2.4122,  2.9088,  0.0000,\n",
      "          0.1370],\n",
      "        [79.0000,  2.4122,  8.4532,  2.1002,  0.0000,  1.8120,  0.0000,  2.8639,\n",
      "          1.8733,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.4434,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6666, 0.9687, 0.9611, 0.4308, 0.9667, 0.9750, 0.5963, 0.4483, 0.9144,\n",
      "         0.4925, 0.9126, 0.9852, 0.0101, 0.8353, 0.9415, 0.6395, 0.0414, 0.3022,\n",
      "         0.5039, 0.6342, 0.1187, 0.8907, 0.3112, 0.1417, 0.0635, 0.2065, 0.6859,\n",
      "         0.6308, 0.8689, 0.8775, 0.5540, 0.3240, 0.1039, 0.2848, 0.0423, 0.0232,\n",
      "         0.5163, 0.7122, 0.1774, 0.7458, 0.7029, 0.5734, 0.9479, 0.1361, 0.5193,\n",
      "         0.3192, 0.8503, 0.8161, 0.2089, 0.1645, 0.6838, 0.0587, 0.7801, 0.7460,\n",
      "         0.6741, 0.7180, 0.6048, 0.5830, 0.5246, 0.2136, 0.0592, 0.7857, 0.9324,\n",
      "         0.7719, 0.1659, 0.1218, 0.7274, 0.9041, 0.9463, 0.5912, 0.0742, 0.2477,\n",
      "         0.9148, 0.0669, 0.1726, 0.9033, 0.0874, 0.8341, 0.2128, 0.9627, 0.6772,\n",
      "         0.1432, 0.6440, 0.3934, 0.2421, 0.9511, 0.2786, 0.4626, 0.0630, 0.1259,\n",
      "         0.3500, 0.8440, 0.7010, 0.1710, 0.4745, 0.8223, 0.5238, 0.3881, 0.3019,\n",
      "         0.9546, 0.3245, 0.8297, 0.8189, 0.0508, 0.1432, 0.8336, 0.0634, 0.3393,\n",
      "         0.3921, 0.0894, 0.1057, 0.2991, 0.6905, 0.5822, 0.0446, 0.4838, 0.0675,\n",
      "         0.6181, 0.3675, 0.6790, 0.9596, 0.9322, 0.2103, 0.0509, 0.2841, 0.0662,\n",
      "         0.3342, 0.4737, 0.5240, 0.9476, 0.3720, 0.4598, 0.6760, 0.8853],\n",
      "        [0.9192, 0.9795, 0.9893, 0.7697, 0.7116, 0.6449, 0.9833, 0.5967, 0.6925,\n",
      "         0.4932, 0.9637, 0.5212, 0.1563, 0.9119, 0.9133, 0.4353, 0.6191, 0.3274,\n",
      "         0.8851, 0.2284, 0.0688, 0.9031, 0.6043, 0.4930, 0.4960, 0.2532, 0.3962,\n",
      "         0.7930, 0.9293, 0.8693, 0.8133, 0.7549, 0.1185, 0.6666, 0.0713, 0.0411,\n",
      "         0.5954, 0.5162, 0.4634, 0.9427, 0.9595, 0.3962, 0.7412, 0.2309, 0.3343,\n",
      "         0.6385, 0.9305, 0.3965, 0.3531, 0.2736, 0.6801, 0.6279, 0.8942, 0.4163,\n",
      "         0.6328, 0.4104, 0.4058, 0.8450, 0.4860, 0.7118, 0.0630, 0.6321, 0.7068,\n",
      "         0.7212, 0.1738, 0.3963, 0.6540, 0.8792, 0.9147, 0.6050, 0.4887, 0.5181,\n",
      "         0.9452, 0.0775, 0.6041, 0.8510, 0.4928, 0.8782, 0.2653, 0.9616, 0.9357,\n",
      "         0.1266, 0.4716, 0.4226, 0.1402, 0.9646, 0.3561, 0.5282, 0.1219, 0.1581,\n",
      "         0.4270, 0.4961, 0.8341, 0.6226, 0.7659, 0.6070, 0.7478, 0.5678, 0.3839,\n",
      "         0.5897, 0.4630, 0.9330, 0.6189, 0.1407, 0.4317, 0.4508, 0.4107, 0.4076,\n",
      "         0.4517, 0.5805, 0.4789, 0.1386, 0.4912, 0.6466, 0.0365, 0.8059, 0.2190,\n",
      "         0.9488, 0.6890, 0.8028, 0.9437, 0.4637, 0.4443, 0.2571, 0.1418, 0.1778,\n",
      "         0.3352, 0.6003, 0.9564, 0.9677, 0.2293, 0.2248, 0.6757, 0.6829],\n",
      "        [0.6477, 0.9827, 0.9882, 0.4667, 0.8096, 0.9117, 0.9824, 0.7835, 0.3351,\n",
      "         0.7284, 0.8701, 0.6056, 0.0277, 0.9074, 0.8901, 0.4547, 0.1101, 0.5119,\n",
      "         0.6606, 0.6976, 0.0945, 0.8737, 0.2730, 0.2555, 0.1756, 0.2477, 0.6378,\n",
      "         0.8459, 0.5923, 0.9125, 0.4155, 0.7399, 0.2114, 0.5108, 0.1597, 0.0265,\n",
      "         0.6458, 0.5787, 0.6905, 0.7662, 0.4384, 0.7929, 0.9428, 0.2288, 0.7055,\n",
      "         0.4377, 0.6358, 0.8129, 0.5047, 0.2022, 0.5943, 0.0581, 0.7942, 0.6258,\n",
      "         0.9157, 0.5655, 0.5166, 0.6559, 0.8358, 0.5879, 0.1680, 0.4816, 0.5850,\n",
      "         0.7781, 0.3361, 0.2757, 0.5732, 0.7662, 0.9469, 0.6215, 0.1743, 0.5271,\n",
      "         0.8767, 0.1109, 0.2553, 0.8095, 0.3974, 0.6678, 0.2164, 0.8846, 0.5851,\n",
      "         0.2686, 0.9376, 0.3853, 0.2772, 0.8698, 0.3776, 0.4976, 0.1611, 0.2679,\n",
      "         0.6619, 0.6471, 0.8765, 0.3432, 0.5712, 0.7822, 0.7892, 0.7985, 0.5978,\n",
      "         0.8189, 0.3502, 0.8819, 0.6280, 0.0608, 0.1626, 0.5167, 0.1604, 0.6145,\n",
      "         0.7943, 0.0714, 0.2409, 0.1427, 0.6107, 0.6680, 0.0743, 0.7505, 0.2774,\n",
      "         0.5519, 0.7972, 0.7580, 0.6464, 0.9100, 0.6584, 0.0465, 0.1485, 0.2208,\n",
      "         0.8173, 0.9140, 0.4510, 0.9239, 0.6641, 0.7014, 0.5460, 0.8999],\n",
      "        [0.9367, 0.9834, 0.9883, 0.9509, 0.9253, 0.9569, 0.9858, 0.8671, 0.8115,\n",
      "         0.3258, 0.9233, 0.7832, 0.0129, 0.9584, 0.9395, 0.4446, 0.0652, 0.2684,\n",
      "         0.7314, 0.7736, 0.0640, 0.8869, 0.1443, 0.0806, 0.0803, 0.1861, 0.8251,\n",
      "         0.8413, 0.5013, 0.8785, 0.8129, 0.6324, 0.2362, 0.1452, 0.1062, 0.0343,\n",
      "         0.6430, 0.7200, 0.3172, 0.5216, 0.4098, 0.8651, 0.9052, 0.0929, 0.8550,\n",
      "         0.2362, 0.2470, 0.9048, 0.4473, 0.1435, 0.8684, 0.0446, 0.9060, 0.7345,\n",
      "         0.9172, 0.6739, 0.7471, 0.5233, 0.9045, 0.2860, 0.0838, 0.2603, 0.9390,\n",
      "         0.8311, 0.0450, 0.1511, 0.2490, 0.7654, 0.9473, 0.4535, 0.1545, 0.2465,\n",
      "         0.7796, 0.0499, 0.2035, 0.8893, 0.4577, 0.6854, 0.0512, 0.7851, 0.4808,\n",
      "         0.1077, 0.9030, 0.1925, 0.1576, 0.9044, 0.4831, 0.3381, 0.1045, 0.1368,\n",
      "         0.8141, 0.8456, 0.8546, 0.2010, 0.3607, 0.6388, 0.2803, 0.8719, 0.9004,\n",
      "         0.9025, 0.1482, 0.8892, 0.7600, 0.0531, 0.1383, 0.8319, 0.0701, 0.6607,\n",
      "         0.8733, 0.0712, 0.1154, 0.1045, 0.8317, 0.6226, 0.0422, 0.6945, 0.1002,\n",
      "         0.3770, 0.8536, 0.7289, 0.9608, 0.9315, 0.2352, 0.1005, 0.0833, 0.1182,\n",
      "         0.8830, 0.8888, 0.1567, 0.9357, 0.7828, 0.8641, 0.8879, 0.8026]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[114159, 2048], edge_index=[2, 1027431], y=[114159, 2], pos=[114159, 2], censor=[4], duration=[4], batch=[114159], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  0.5692,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -1.0688,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.8629,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000, -1.3812,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  5\n",
      "Data[0]:  tensor([[7.2960e+01, 4.8240e+00, 4.4691e+00, 4.1514e+00, 0.0000e+00, 4.0765e+00,\n",
      "         0.0000e+00, 3.8996e-01, 1.2175e+00, 0.0000e+00, 4.0348e+00, 0.0000e+00,\n",
      "         1.4684e+00, 1.6745e+00, 3.4245e-01, 3.9151e-01, 0.0000e+00],\n",
      "        [6.4046e+01, 6.9132e+00, 2.5507e+00, 5.5390e+00, 0.0000e+00, 2.9407e+00,\n",
      "         0.0000e+00, 7.3716e-01, 1.9194e+00, 9.0935e-01, 6.8012e+00, 0.0000e+00,\n",
      "         5.9398e+00, 1.2872e+00, 6.1904e-02, 1.5275e-01, 2.0167e-01],\n",
      "        [5.9638e+01, 6.9200e+00, 2.2580e+00, 6.8535e+00, 0.0000e+00, 4.4051e+00,\n",
      "         0.0000e+00, 2.5097e+00, 1.5174e+00, 0.0000e+00, 5.8925e+00, 0.0000e+00,\n",
      "         4.4268e+00, 3.4694e+00, 7.3524e-01, 7.5940e-01, 6.1483e-01],\n",
      "        [8.3661e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3108e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0865e+00, 6.3757e+00,\n",
      "         0.0000e+00, 7.7240e-01, 1.8844e-01, 0.0000e+00, 1.6054e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.8923, 0.9852, 0.9903, 0.9656, 0.9089, 0.9293, 0.9837, 0.8717, 0.7100,\n",
      "         0.3067, 0.8708, 0.8381, 0.0129, 0.9543, 0.9065, 0.4911, 0.0601, 0.3341,\n",
      "         0.3949, 0.7088, 0.0599, 0.7773, 0.2893, 0.1623, 0.1718, 0.1930, 0.6104,\n",
      "         0.8073, 0.3936, 0.9186, 0.7403, 0.4730, 0.1669, 0.2808, 0.1163, 0.0225,\n",
      "         0.6971, 0.6852, 0.3306, 0.3845, 0.2758, 0.7945, 0.9532, 0.1455, 0.7339,\n",
      "         0.2707, 0.3860, 0.8200, 0.5504, 0.1661, 0.6701, 0.0387, 0.8461, 0.7024,\n",
      "         0.9213, 0.7169, 0.7661, 0.5485, 0.8956, 0.2593, 0.1385, 0.3102, 0.9153,\n",
      "         0.7742, 0.0728, 0.3300, 0.3275, 0.7261, 0.9425, 0.6966, 0.1866, 0.1452,\n",
      "         0.8110, 0.0888, 0.1964, 0.8316, 0.3933, 0.4068, 0.0796, 0.5198, 0.4055,\n",
      "         0.1608, 0.9369, 0.2621, 0.1583, 0.6826, 0.4537, 0.4016, 0.1160, 0.1830,\n",
      "         0.7630, 0.9054, 0.7765, 0.3008, 0.3055, 0.8302, 0.2181, 0.8278, 0.7036,\n",
      "         0.8960, 0.2293, 0.8862, 0.7284, 0.0880, 0.1830, 0.7368, 0.1711, 0.6600,\n",
      "         0.8491, 0.0711, 0.1870, 0.1395, 0.7360, 0.6248, 0.0570, 0.7208, 0.2177,\n",
      "         0.4449, 0.8616, 0.4599, 0.9552, 0.9140, 0.1625, 0.0780, 0.1466, 0.1647,\n",
      "         0.8536, 0.8450, 0.2323, 0.8112, 0.8168, 0.8666, 0.7206, 0.8428],\n",
      "        [0.8248, 0.9026, 0.9710, 0.9270, 0.8969, 0.9488, 0.9627, 0.6488, 0.7585,\n",
      "         0.6211, 0.4721, 0.4363, 0.0097, 0.9479, 0.8256, 0.5333, 0.5732, 0.6108,\n",
      "         0.8249, 0.7315, 0.0655, 0.8408, 0.6193, 0.6163, 0.4341, 0.1394, 0.8764,\n",
      "         0.7883, 0.8052, 0.7994, 0.7121, 0.7343, 0.1329, 0.6266, 0.0489, 0.0264,\n",
      "         0.5916, 0.6624, 0.5903, 0.7514, 0.7752, 0.4978, 0.5901, 0.2655, 0.3349,\n",
      "         0.7026, 0.7888, 0.5126, 0.2502, 0.1171, 0.8057, 0.1022, 0.4408, 0.6937,\n",
      "         0.7141, 0.6686, 0.5309, 0.5782, 0.4624, 0.5576, 0.2116, 0.4174, 0.7447,\n",
      "         0.4392, 0.7490, 0.5423, 0.7442, 0.8502, 0.9466, 0.7231, 0.1294, 0.6259,\n",
      "         0.8444, 0.0978, 0.6675, 0.8147, 0.0447, 0.7453, 0.0486, 0.9281, 0.9308,\n",
      "         0.4223, 0.8817, 0.2979, 0.3483, 0.9486, 0.3948, 0.3711, 0.1185, 0.2758,\n",
      "         0.5735, 0.7504, 0.8297, 0.2806, 0.5647, 0.8200, 0.8186, 0.4455, 0.3326,\n",
      "         0.8948, 0.5015, 0.8331, 0.6867, 0.1270, 0.1915, 0.7458, 0.3928, 0.5465,\n",
      "         0.3981, 0.0890, 0.2061, 0.4857, 0.6844, 0.6448, 0.0409, 0.7591, 0.2911,\n",
      "         0.7197, 0.7436, 0.7569, 0.9408, 0.9291, 0.6917, 0.5762, 0.4661, 0.2184,\n",
      "         0.7775, 0.8466, 0.7849, 0.9505, 0.6945, 0.8224, 0.8005, 0.6385],\n",
      "        [0.8029, 0.9677, 0.9794, 0.9382, 0.9044, 0.7531, 0.9540, 0.7276, 0.6872,\n",
      "         0.4844, 0.7908, 0.9316, 0.0143, 0.9456, 0.8990, 0.4131, 0.1560, 0.3259,\n",
      "         0.7345, 0.6517, 0.0644, 0.8419, 0.3469, 0.1911, 0.1572, 0.1914, 0.7176,\n",
      "         0.5064, 0.5617, 0.8769, 0.6255, 0.4728, 0.2096, 0.2346, 0.1290, 0.0550,\n",
      "         0.6114, 0.5889, 0.3299, 0.5135, 0.4566, 0.7349, 0.9424, 0.1813, 0.6618,\n",
      "         0.3283, 0.5245, 0.7344, 0.5907, 0.1800, 0.7288, 0.1153, 0.8128, 0.6132,\n",
      "         0.9013, 0.7284, 0.7582, 0.6541, 0.8245, 0.4232, 0.2193, 0.4969, 0.9010,\n",
      "         0.7718, 0.1127, 0.2886, 0.5760, 0.7048, 0.9568, 0.6880, 0.1348, 0.3160,\n",
      "         0.8533, 0.0817, 0.3364, 0.8605, 0.4710, 0.5494, 0.2880, 0.9286, 0.5594,\n",
      "         0.2233, 0.9212, 0.3457, 0.2541, 0.8277, 0.4110, 0.5093, 0.1580, 0.2903,\n",
      "         0.7207, 0.7877, 0.8878, 0.4032, 0.5319, 0.7885, 0.3365, 0.7769, 0.7100,\n",
      "         0.6666, 0.3145, 0.8417, 0.6525, 0.0945, 0.2313, 0.6222, 0.0976, 0.6580,\n",
      "         0.7703, 0.0817, 0.2885, 0.1433, 0.6210, 0.6562, 0.0629, 0.6472, 0.2498,\n",
      "         0.4737, 0.8428, 0.7385, 0.9518, 0.8677, 0.3218, 0.0650, 0.1948, 0.3167,\n",
      "         0.7898, 0.8242, 0.6522, 0.9213, 0.6504, 0.7450, 0.7801, 0.8332],\n",
      "        [0.6527, 0.5410, 0.6307, 0.8532, 0.4505, 0.9791, 0.9793, 0.1929, 0.3940,\n",
      "         0.6183, 0.3005, 0.3656, 0.0123, 0.7928, 0.8871, 0.1783, 0.7767, 0.1710,\n",
      "         0.5420, 0.3313, 0.0658, 0.5608, 0.4236, 0.1893, 0.3428, 0.1827, 0.2326,\n",
      "         0.7623, 0.9022, 0.8129, 0.6783, 0.5342, 0.1213, 0.3359, 0.0499, 0.0238,\n",
      "         0.5290, 0.7782, 0.2483, 0.8141, 0.6380, 0.1841, 0.7818, 0.2402, 0.6210,\n",
      "         0.5012, 0.7895, 0.8063, 0.3511, 0.1410, 0.8400, 0.0698, 0.3072, 0.8262,\n",
      "         0.3143, 0.2671, 0.4539, 0.9042, 0.2662, 0.3964, 0.2002, 0.2784, 0.8796,\n",
      "         0.2738, 0.3692, 0.2007, 0.7901, 0.3765, 0.9641, 0.5477, 0.1179, 0.4695,\n",
      "         0.8958, 0.0524, 0.4860, 0.7376, 0.2212, 0.8280, 0.0980, 0.9224, 0.9346,\n",
      "         0.4500, 0.8080, 0.5499, 0.1168, 0.9525, 0.2612, 0.2997, 0.1258, 0.1848,\n",
      "         0.0884, 0.6446, 0.4288, 0.1837, 0.4621, 0.6313, 0.8805, 0.2037, 0.5341,\n",
      "         0.7919, 0.4021, 0.8165, 0.7522, 0.0725, 0.2988, 0.5233, 0.2537, 0.4136,\n",
      "         0.1440, 0.0824, 0.1600, 0.1301, 0.6554, 0.5659, 0.0538, 0.2670, 0.4426,\n",
      "         0.8922, 0.5510, 0.8152, 0.9561, 0.5494, 0.7991, 0.1122, 0.1230, 0.1574,\n",
      "         0.5026, 0.6366, 0.9452, 0.9457, 0.7164, 0.7025, 0.3245, 0.3933]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[58786, 2048], edge_index=[2, 529074], y=[58786, 2], pos=[58786, 2], censor=[4], duration=[4], batch=[58786], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -1.4279,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.8896,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.1145,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.3483,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  6\n",
      "Data[0]:  tensor([[8.5178e+01, 4.0856e+00, 3.4698e+00, 2.7223e+00, 0.0000e+00, 1.0746e+00,\n",
      "         0.0000e+00, 2.5407e+00, 5.5472e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.7418e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.6003e+01, 4.5928e+00, 1.3411e+00, 4.8233e+00, 9.0035e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.9874e+00, 0.0000e+00, 2.0575e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.1048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.8527e+01, 3.7762e+00, 2.7019e-01, 4.1546e+00, 5.4901e-01, 3.0753e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1534e+00, 0.0000e+00, 2.7624e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.3878e+00, 3.3441e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.1837e+01, 4.2030e-01, 4.9679e+00, 2.7753e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.3425, 0.5077, 0.6617, 0.4832, 0.3870, 0.8409, 0.7455, 0.1063, 0.3451,\n",
      "         0.4155, 0.5713, 0.2627, 0.0129, 0.4267, 0.6436, 0.2550, 0.3547, 0.1877,\n",
      "         0.7984, 0.3697, 0.0993, 0.7015, 0.7510, 0.1097, 0.6208, 0.2112, 0.1253,\n",
      "         0.5103, 0.6610, 0.8335, 0.1880, 0.6509, 0.1454, 0.5979, 0.0897, 0.0466,\n",
      "         0.1461, 0.7557, 0.3370, 0.7136, 0.9421, 0.1670, 0.8008, 0.2746, 0.1682,\n",
      "         0.2799, 0.8111, 0.2141, 0.7635, 0.1382, 0.6264, 0.2797, 0.3807, 0.7616,\n",
      "         0.7075, 0.3807, 0.1829, 0.9369, 0.2300, 0.7776, 0.0581, 0.4660, 0.4779,\n",
      "         0.5727, 0.0856, 0.4527, 0.7800, 0.7405, 0.2829, 0.1791, 0.4936, 0.4391,\n",
      "         0.8698, 0.1035, 0.7617, 0.6948, 0.7916, 0.9077, 0.3186, 0.9612, 0.9581,\n",
      "         0.0851, 0.4767, 0.6663, 0.2626, 0.9530, 0.1465, 0.4824, 0.1796, 0.1497,\n",
      "         0.1006, 0.3073, 0.6666, 0.2003, 0.6574, 0.1942, 0.9163, 0.1855, 0.1213,\n",
      "         0.3683, 0.3831, 0.4210, 0.3820, 0.0674, 0.6046, 0.3966, 0.0773, 0.1811,\n",
      "         0.1074, 0.0999, 0.1928, 0.1644, 0.1921, 0.2689, 0.0478, 0.2900, 0.5077,\n",
      "         0.7774, 0.2901, 0.8785, 0.6622, 0.1583, 0.8994, 0.0689, 0.1220, 0.1513,\n",
      "         0.3446, 0.4998, 0.9548, 0.9433, 0.1609, 0.1420, 0.2116, 0.5740],\n",
      "        [0.6268, 0.9817, 0.9875, 0.5028, 0.8284, 0.8222, 0.7968, 0.2667, 0.5820,\n",
      "         0.4747, 0.8920, 0.9516, 0.1730, 0.9270, 0.7813, 0.6242, 0.6318, 0.5819,\n",
      "         0.5680, 0.8139, 0.0716, 0.6865, 0.4240, 0.1896, 0.1281, 0.1884, 0.3606,\n",
      "         0.6068, 0.7851, 0.8719, 0.5692, 0.4824, 0.2574, 0.5074, 0.1182, 0.0228,\n",
      "         0.7903, 0.7093, 0.1765, 0.3788, 0.3902, 0.8781, 0.9677, 0.1411, 0.7708,\n",
      "         0.2550, 0.9122, 0.8304, 0.5127, 0.2001, 0.3422, 0.0696, 0.8390, 0.7149,\n",
      "         0.8830, 0.6181, 0.4794, 0.6975, 0.8385, 0.2883, 0.3952, 0.2738, 0.8941,\n",
      "         0.7818, 0.6561, 0.2486, 0.3272, 0.7816, 0.9541, 0.4791, 0.1197, 0.1932,\n",
      "         0.6193, 0.0674, 0.1677, 0.8906, 0.6182, 0.9040, 0.0859, 0.8809, 0.4000,\n",
      "         0.6999, 0.5530, 0.5176, 0.1921, 0.9110, 0.3879, 0.7249, 0.1111, 0.1617,\n",
      "         0.1631, 0.6409, 0.8484, 0.8220, 0.6515, 0.3794, 0.8012, 0.8570, 0.5527,\n",
      "         0.8803, 0.2379, 0.7321, 0.7787, 0.0634, 0.1730, 0.8270, 0.0933, 0.6624,\n",
      "         0.8460, 0.2694, 0.1695, 0.1296, 0.7480, 0.7169, 0.0518, 0.7912, 0.1756,\n",
      "         0.2847, 0.8507, 0.8173, 0.9336, 0.9034, 0.8338, 0.0583, 0.2444, 0.2031,\n",
      "         0.8523, 0.7152, 0.6006, 0.8463, 0.7451, 0.8203, 0.6902, 0.9079],\n",
      "        [0.5171, 0.9781, 0.9786, 0.2599, 0.9081, 0.9420, 0.9664, 0.8341, 0.1452,\n",
      "         0.8611, 0.9417, 0.6011, 0.0406, 0.9017, 0.9367, 0.1888, 0.1008, 0.3163,\n",
      "         0.7632, 0.7967, 0.0650, 0.3958, 0.2756, 0.1603, 0.1382, 0.2021, 0.2198,\n",
      "         0.5002, 0.9286, 0.9177, 0.4242, 0.3912, 0.2021, 0.3738, 0.1017, 0.0271,\n",
      "         0.6679, 0.6889, 0.2477, 0.3889, 0.2638, 0.7766, 0.9504, 0.1897, 0.7857,\n",
      "         0.3420, 0.8340, 0.8719, 0.7310, 0.1633, 0.2659, 0.0416, 0.8668, 0.7166,\n",
      "         0.9456, 0.7193, 0.6034, 0.8364, 0.8667, 0.2778, 0.3104, 0.4814, 0.3667,\n",
      "         0.8105, 0.8396, 0.2318, 0.8386, 0.7863, 0.9530, 0.6683, 0.1053, 0.3720,\n",
      "         0.8787, 0.0517, 0.2842, 0.6402, 0.6359, 0.8852, 0.3140, 0.9102, 0.7249,\n",
      "         0.6822, 0.5972, 0.2334, 0.4914, 0.9431, 0.2199, 0.3798, 0.1127, 0.1777,\n",
      "         0.8474, 0.6119, 0.8299, 0.2590, 0.7786, 0.5205, 0.7521, 0.8375, 0.2263,\n",
      "         0.7799, 0.2055, 0.8476, 0.6953, 0.0623, 0.1269, 0.4802, 0.0809, 0.3731,\n",
      "         0.8511, 0.0641, 0.1804, 0.1317, 0.6193, 0.7492, 0.0461, 0.7249, 0.1558,\n",
      "         0.5084, 0.8728, 0.8190, 0.9369, 0.9286, 0.7734, 0.4045, 0.3650, 0.2352,\n",
      "         0.6243, 0.7852, 0.9506, 0.9222, 0.5673, 0.4226, 0.3412, 0.8360],\n",
      "        [0.6996, 0.9765, 0.9833, 0.9492, 0.9379, 0.9629, 0.9301, 0.5292, 0.0721,\n",
      "         0.4896, 0.9679, 0.3255, 0.0109, 0.9409, 0.7898, 0.4392, 0.0767, 0.4902,\n",
      "         0.3534, 0.4217, 0.0687, 0.8763, 0.3236, 0.0756, 0.1261, 0.1731, 0.6119,\n",
      "         0.8759, 0.8904, 0.8982, 0.6090, 0.6351, 0.1877, 0.5179, 0.0492, 0.0348,\n",
      "         0.5110, 0.6114, 0.1471, 0.7797, 0.8483, 0.9119, 0.8561, 0.1002, 0.8944,\n",
      "         0.3160, 0.5216, 0.9311, 0.4000, 0.1163, 0.8254, 0.0419, 0.9547, 0.7405,\n",
      "         0.8881, 0.5566, 0.4010, 0.7563, 0.9401, 0.4607, 0.0636, 0.4304, 0.8989,\n",
      "         0.9123, 0.0537, 0.1664, 0.1310, 0.8105, 0.9370, 0.7656, 0.3847, 0.4505,\n",
      "         0.8780, 0.0427, 0.1498, 0.9459, 0.1045, 0.6706, 0.5400, 0.8726, 0.2308,\n",
      "         0.2346, 0.7966, 0.1927, 0.0580, 0.9485, 0.5537, 0.6112, 0.0925, 0.1248,\n",
      "         0.2793, 0.8875, 0.6325, 0.3488, 0.2668, 0.6810, 0.2761, 0.9141, 0.3812,\n",
      "         0.7074, 0.1171, 0.8561, 0.8041, 0.0934, 0.3364, 0.3236, 0.1164, 0.6727,\n",
      "         0.9215, 0.0811, 0.0769, 0.0982, 0.1629, 0.8051, 0.0373, 0.6242, 0.2504,\n",
      "         0.5582, 0.9000, 0.8377, 0.9425, 0.9259, 0.1199, 0.0607, 0.0783, 0.0947,\n",
      "         0.8685, 0.8635, 0.9484, 0.9213, 0.8210, 0.7567, 0.6448, 0.8491]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[82780, 2048], edge_index=[2, 745020], y=[82780, 2], pos=[82780, 2], censor=[4], duration=[4], batch=[82780], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.2043,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.0649,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.1333,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.9232,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  7\n",
      "Data[0]:  tensor([[4.9576e+01, 8.5896e+00, 0.0000e+00, 1.0243e+01, 4.2840e-01, 3.2322e+00,\n",
      "         0.0000e+00, 2.0228e+00, 2.1415e+00, 0.0000e+00, 6.0276e+00, 0.0000e+00,\n",
      "         1.3870e+01, 3.7987e+00, 1.4277e-02, 2.8102e-02, 2.8091e-02],\n",
      "        [6.1260e+01, 5.0236e+00, 5.6453e+00, 5.1555e-01, 0.0000e+00, 5.7899e+00,\n",
      "         0.0000e+00, 6.4138e+00, 3.2082e+00, 0.0000e+00, 5.9340e+00, 1.7721e+00,\n",
      "         2.6243e+00, 1.8132e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.4873e+01, 5.1556e+00, 5.3648e+00, 7.1203e+00, 0.0000e+00, 4.9100e+00,\n",
      "         0.0000e+00, 1.3530e+00, 1.1011e+00, 0.0000e+00, 3.0745e+00, 0.0000e+00,\n",
      "         3.7820e+00, 3.2658e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.5564e+01, 6.5352e+00, 3.3226e+00, 7.3225e+00, 0.0000e+00, 3.2446e-01,\n",
      "         0.0000e+00, 2.9081e+00, 1.8109e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.3455e+00, 9.1456e-01, 7.9830e-02, 0.0000e+00, 2.3872e+01]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7082, 0.9534, 0.9235, 0.8075, 0.7779, 0.7866, 0.7516, 0.5035, 0.6928,\n",
      "         0.8258, 0.7483, 0.9105, 0.1187, 0.8689, 0.8449, 0.3290, 0.4234, 0.4358,\n",
      "         0.8266, 0.2844, 0.0808, 0.7489, 0.4443, 0.4083, 0.2780, 0.2306, 0.5378,\n",
      "         0.7291, 0.9143, 0.8459, 0.5904, 0.6851, 0.3476, 0.3730, 0.2417, 0.0550,\n",
      "         0.4678, 0.3175, 0.3635, 0.9174, 0.6669, 0.6126, 0.9193, 0.2243, 0.6144,\n",
      "         0.7706, 0.8411, 0.6503, 0.4153, 0.2798, 0.6317, 0.0990, 0.6756, 0.2813,\n",
      "         0.8051, 0.5070, 0.6079, 0.8385, 0.5945, 0.4428, 0.3779, 0.6855, 0.6994,\n",
      "         0.6819, 0.3001, 0.3192, 0.7597, 0.7066, 0.9554, 0.4165, 0.2407, 0.3324,\n",
      "         0.9202, 0.0966, 0.3948, 0.8747, 0.2079, 0.8250, 0.0569, 0.9633, 0.9589,\n",
      "         0.2913, 0.5780, 0.5394, 0.3658, 0.9492, 0.3921, 0.5364, 0.2025, 0.3546,\n",
      "         0.3412, 0.6475, 0.8214, 0.4375, 0.8415, 0.6282, 0.7580, 0.5672, 0.5192,\n",
      "         0.4599, 0.5997, 0.7535, 0.5634, 0.1284, 0.2172, 0.7693, 0.2246, 0.4492,\n",
      "         0.4951, 0.0898, 0.2867, 0.2076, 0.2815, 0.3696, 0.0795, 0.6602, 0.3300,\n",
      "         0.8230, 0.6338, 0.6975, 0.9540, 0.6804, 0.5166, 0.3400, 0.2738, 0.3831,\n",
      "         0.5712, 0.6777, 0.9239, 0.9525, 0.3818, 0.4361, 0.6207, 0.8224],\n",
      "        [0.5998, 0.9843, 0.9875, 0.8594, 0.8668, 0.9634, 0.9802, 0.4705, 0.5333,\n",
      "         0.4150, 0.9790, 0.9853, 0.0130, 0.8705, 0.9377, 0.5628, 0.0432, 0.2935,\n",
      "         0.6131, 0.6224, 0.0525, 0.8987, 0.2428, 0.1720, 0.0943, 0.2079, 0.6847,\n",
      "         0.8740, 0.7249, 0.9026, 0.5481, 0.7588, 0.1342, 0.4846, 0.0662, 0.0258,\n",
      "         0.6656, 0.7119, 0.3348, 0.6011, 0.4821, 0.8616, 0.9411, 0.1577, 0.5549,\n",
      "         0.3764, 0.7326, 0.8494, 0.1023, 0.1825, 0.8093, 0.0572, 0.8061, 0.6774,\n",
      "         0.9104, 0.6916, 0.7913, 0.4948, 0.9171, 0.2713, 0.0761, 0.3266, 0.9068,\n",
      "         0.8953, 0.1213, 0.1757, 0.4460, 0.8223, 0.9619, 0.5305, 0.0726, 0.1525,\n",
      "         0.8853, 0.0869, 0.1508, 0.8232, 0.0365, 0.4639, 0.0520, 0.7039, 0.6306,\n",
      "         0.1198, 0.9256, 0.3281, 0.1292, 0.9132, 0.4319, 0.4028, 0.0608, 0.1498,\n",
      "         0.4592, 0.8126, 0.7507, 0.1827, 0.2602, 0.7176, 0.3254, 0.7660, 0.7445,\n",
      "         0.8938, 0.2475, 0.8662, 0.7689, 0.0657, 0.1554, 0.8703, 0.1239, 0.6381,\n",
      "         0.8761, 0.0645, 0.1134, 0.1221, 0.4283, 0.5257, 0.0468, 0.8111, 0.0876,\n",
      "         0.3496, 0.7752, 0.4062, 0.9550, 0.9135, 0.2032, 0.0471, 0.0930, 0.1493,\n",
      "         0.7933, 0.8584, 0.3741, 0.8453, 0.7960, 0.9099, 0.5054, 0.9119],\n",
      "        [0.7711, 0.9756, 0.9841, 0.8541, 0.8045, 0.8919, 0.9686, 0.3150, 0.3663,\n",
      "         0.7599, 0.9300, 0.4951, 0.0280, 0.9550, 0.8577, 0.4280, 0.1303, 0.4894,\n",
      "         0.7107, 0.7353, 0.0926, 0.8867, 0.4037, 0.2193, 0.3848, 0.2228, 0.4223,\n",
      "         0.7790, 0.8550, 0.8820, 0.6758, 0.7241, 0.5135, 0.7849, 0.1887, 0.0677,\n",
      "         0.6609, 0.6522, 0.7096, 0.8147, 0.7893, 0.8441, 0.9443, 0.2402, 0.7826,\n",
      "         0.5449, 0.8143, 0.7626, 0.5692, 0.2363, 0.6225, 0.0985, 0.8439, 0.6697,\n",
      "         0.8316, 0.6253, 0.7652, 0.8238, 0.8557, 0.4435, 0.2646, 0.6842, 0.9170,\n",
      "         0.8168, 0.7967, 0.2920, 0.8194, 0.5417, 0.9569, 0.4944, 0.1483, 0.4891,\n",
      "         0.8660, 0.0616, 0.4756, 0.8441, 0.7604, 0.8763, 0.3118, 0.9465, 0.5659,\n",
      "         0.4125, 0.8673, 0.4204, 0.5891, 0.9518, 0.4063, 0.5420, 0.3748, 0.3369,\n",
      "         0.3711, 0.7789, 0.8445, 0.6020, 0.6525, 0.7580, 0.8241, 0.7940, 0.5384,\n",
      "         0.7324, 0.2745, 0.8773, 0.6408, 0.1226, 0.2554, 0.7052, 0.1304, 0.7460,\n",
      "         0.8199, 0.0905, 0.2237, 0.1616, 0.6395, 0.5926, 0.0665, 0.7196, 0.6700,\n",
      "         0.8218, 0.7797, 0.7513, 0.9305, 0.7870, 0.7693, 0.2393, 0.1690, 0.4231,\n",
      "         0.8250, 0.6208, 0.8646, 0.9557, 0.7217, 0.8342, 0.6748, 0.8875],\n",
      "        [0.8291, 0.9820, 0.9904, 0.8576, 0.7714, 0.9084, 0.9803, 0.5211, 0.7419,\n",
      "         0.7114, 0.5985, 0.6525, 0.0262, 0.9326, 0.9030, 0.2779, 0.0590, 0.4683,\n",
      "         0.8716, 0.1950, 0.0656, 0.8940, 0.4589, 0.4835, 0.2840, 0.3351, 0.5672,\n",
      "         0.8097, 0.8786, 0.8766, 0.6713, 0.8727, 0.1685, 0.6336, 0.0832, 0.0405,\n",
      "         0.5584, 0.5029, 0.6971, 0.8903, 0.7805, 0.6404, 0.8767, 0.1258, 0.4841,\n",
      "         0.6422, 0.9411, 0.5827, 0.5096, 0.3683, 0.5653, 0.1079, 0.6754, 0.4539,\n",
      "         0.7411, 0.5226, 0.6245, 0.8204, 0.6858, 0.6479, 0.1158, 0.7145, 0.8637,\n",
      "         0.6349, 0.1545, 0.2375, 0.5772, 0.8145, 0.9653, 0.6268, 0.1305, 0.3146,\n",
      "         0.9078, 0.0951, 0.3917, 0.6820, 0.4955, 0.7645, 0.0891, 0.9206, 0.9426,\n",
      "         0.1707, 0.9066, 0.6581, 0.1884, 0.9540, 0.5633, 0.5370, 0.1201, 0.2056,\n",
      "         0.2150, 0.7922, 0.8240, 0.3061, 0.7942, 0.6611, 0.7044, 0.7469, 0.6040,\n",
      "         0.6610, 0.6107, 0.7602, 0.6598, 0.2345, 0.5354, 0.8155, 0.3801, 0.6870,\n",
      "         0.6804, 0.0653, 0.2846, 0.2062, 0.2665, 0.4949, 0.0357, 0.6513, 0.1727,\n",
      "         0.9393, 0.6577, 0.7991, 0.8429, 0.8405, 0.5008, 0.0889, 0.1101, 0.2779,\n",
      "         0.8444, 0.8727, 0.9457, 0.9651, 0.1666, 0.2128, 0.6181, 0.7616]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[86640, 2048], edge_index=[2, 779760], y=[86640, 2], pos=[86640, 2], censor=[4], duration=[4], batch=[86640], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.7339,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.4144,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.5410,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.0782,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  8\n",
      "Data[0]:  tensor([[59.9923, 12.5207,  0.0000, 14.2503,  0.0000,  3.8342,  0.0000,  0.0000,\n",
      "          1.8004,  0.0000,  0.5202,  0.0000,  4.6349,  2.4469,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [90.0281,  0.0000,  0.0000,  0.0000,  0.0000,  0.8224,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.7836,  0.0000,  1.5013,  3.8807,  1.0817,  0.5750,\n",
      "          0.3271],\n",
      "        [63.9619,  4.9900,  4.5394,  4.3125,  0.0000,  5.9057,  0.0000,  3.7180,\n",
      "          4.1476,  0.0000,  3.3580,  0.0000,  2.7748,  0.9446,  0.8193,  0.5284,\n",
      "          0.0000],\n",
      "        [64.8124,  0.3756,  0.0000,  0.7863,  2.8817,  6.8719,  0.0000,  5.4805,\n",
      "          7.0199,  0.0000,  0.0000,  0.0000,  7.3485,  3.7664,  0.0000,  0.5561,\n",
      "          0.1007]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7039, 0.9667, 0.9838, 0.5313, 0.8405, 0.6153, 0.9745, 0.7524, 0.3480,\n",
      "         0.5112, 0.6219, 0.6054, 0.0765, 0.9472, 0.8116, 0.3380, 0.2943, 0.3411,\n",
      "         0.7194, 0.5132, 0.0730, 0.7295, 0.5075, 0.3022, 0.2543, 0.2217, 0.4882,\n",
      "         0.7530, 0.7679, 0.8746, 0.5432, 0.7274, 0.5212, 0.4248, 0.2480, 0.0307,\n",
      "         0.6289, 0.4476, 0.3547, 0.8742, 0.5034, 0.6400, 0.8262, 0.2094, 0.5380,\n",
      "         0.4207, 0.6001, 0.5825, 0.7175, 0.1856, 0.6840, 0.1374, 0.7282, 0.4835,\n",
      "         0.8804, 0.5541, 0.7659, 0.8112, 0.7315, 0.4196, 0.3435, 0.6218, 0.7990,\n",
      "         0.6064, 0.2144, 0.3212, 0.4892, 0.7459, 0.9355, 0.5794, 0.2410, 0.3596,\n",
      "         0.8858, 0.1293, 0.4048, 0.8589, 0.5493, 0.6010, 0.2282, 0.9242, 0.6554,\n",
      "         0.3178, 0.8092, 0.3522, 0.3438, 0.9285, 0.4706, 0.4845, 0.1984, 0.3200,\n",
      "         0.6985, 0.7775, 0.8607, 0.4740, 0.6505, 0.7538, 0.4938, 0.8053, 0.7924,\n",
      "         0.7463, 0.3534, 0.8624, 0.5065, 0.1270, 0.2248, 0.4885, 0.1349, 0.7043,\n",
      "         0.7086, 0.0805, 0.2971, 0.2064, 0.1772, 0.5934, 0.1056, 0.5319, 0.3439,\n",
      "         0.5955, 0.9141, 0.7403, 0.9195, 0.8149, 0.4638, 0.1585, 0.2645, 0.2944,\n",
      "         0.8304, 0.7497, 0.9188, 0.9247, 0.5680, 0.5284, 0.6149, 0.7339],\n",
      "        [0.2433, 0.9801, 0.9841, 0.9608, 0.9738, 0.9750, 0.9811, 0.9447, 0.8550,\n",
      "         0.0337, 0.9467, 0.9829, 0.0116, 0.9394, 0.1352, 0.4130, 0.7808, 0.5378,\n",
      "         0.4827, 0.7519, 0.0754, 0.6047, 0.2020, 0.1104, 0.1598, 0.1169, 0.7995,\n",
      "         0.8552, 0.3422, 0.8693, 0.1798, 0.6406, 0.4931, 0.7188, 0.0703, 0.0290,\n",
      "         0.8919, 0.8044, 0.2057, 0.7100, 0.0998, 0.9180, 0.9462, 0.3646, 0.8654,\n",
      "         0.3853, 0.6420, 0.9314, 0.8350, 0.1177, 0.8498, 0.2440, 0.9298, 0.8729,\n",
      "         0.9606, 0.8573, 0.8532, 0.6565, 0.9380, 0.2467, 0.0419, 0.3540, 0.9548,\n",
      "         0.9108, 0.0529, 0.7438, 0.2641, 0.8456, 0.9486, 0.8116, 0.1049, 0.1206,\n",
      "         0.8105, 0.0370, 0.4597, 0.9267, 0.6195, 0.5523, 0.0476, 0.3464, 0.0724,\n",
      "         0.0917, 0.9215, 0.1984, 0.1272, 0.6679, 0.6395, 0.1804, 0.2585, 0.0903,\n",
      "         0.9271, 0.8604, 0.8169, 0.2207, 0.5437, 0.8730, 0.1029, 0.8531, 0.7815,\n",
      "         0.9405, 0.1088, 0.9439, 0.8259, 0.0660, 0.2089, 0.5948, 0.0529, 0.8110,\n",
      "         0.9340, 0.0809, 0.2909, 0.1059, 0.7614, 0.8493, 0.0638, 0.8476, 0.4361,\n",
      "         0.4175, 0.9503, 0.5062, 0.9635, 0.9566, 0.1462, 0.0497, 0.2527, 0.0903,\n",
      "         0.9211, 0.8801, 0.1281, 0.7941, 0.8207, 0.8686, 0.1704, 0.8302],\n",
      "        [0.8074, 0.9690, 0.9794, 0.9223, 0.8675, 0.2524, 0.9796, 0.7259, 0.7741,\n",
      "         0.4255, 0.8609, 0.7484, 0.0251, 0.8919, 0.9149, 0.4854, 0.4478, 0.3553,\n",
      "         0.3979, 0.7359, 0.0696, 0.7712, 0.2955, 0.1954, 0.1438, 0.2166, 0.6682,\n",
      "         0.8231, 0.6819, 0.9157, 0.6826, 0.7190, 0.1743, 0.4589, 0.1452, 0.0393,\n",
      "         0.6885, 0.7098, 0.3199, 0.8635, 0.3914, 0.7873, 0.8939, 0.2318, 0.7965,\n",
      "         0.4082, 0.7982, 0.8549, 0.5353, 0.1817, 0.8426, 0.1477, 0.8643, 0.7378,\n",
      "         0.9154, 0.7555, 0.8459, 0.4463, 0.8052, 0.4017, 0.2122, 0.2759, 0.9215,\n",
      "         0.8177, 0.1646, 0.2010, 0.4475, 0.7381, 0.9371, 0.5152, 0.1225, 0.2144,\n",
      "         0.8547, 0.0731, 0.2859, 0.8663, 0.1472, 0.7906, 0.0540, 0.8654, 0.6277,\n",
      "         0.1897, 0.8698, 0.3756, 0.1876, 0.8603, 0.4581, 0.4583, 0.1352, 0.2665,\n",
      "         0.6083, 0.8441, 0.7700, 0.2261, 0.3477, 0.8368, 0.2780, 0.7885, 0.3358,\n",
      "         0.8818, 0.2671, 0.4944, 0.6943, 0.0616, 0.2463, 0.8543, 0.1544, 0.7483,\n",
      "         0.6776, 0.0689, 0.1701, 0.1783, 0.6816, 0.7206, 0.0743, 0.8324, 0.2290,\n",
      "         0.5066, 0.8263, 0.6233, 0.9572, 0.9253, 0.2228, 0.0614, 0.1493, 0.1684,\n",
      "         0.8056, 0.8939, 0.4131, 0.8806, 0.8125, 0.8766, 0.7985, 0.9223],\n",
      "        [0.5817, 0.4091, 0.4998, 0.9144, 0.7566, 0.5153, 0.6578, 0.2587, 0.5630,\n",
      "         0.7503, 0.4141, 0.3329, 0.0219, 0.9295, 0.8675, 0.4225, 0.3249, 0.3431,\n",
      "         0.8829, 0.7722, 0.0611, 0.4714, 0.3950, 0.1923, 0.2780, 0.1991, 0.4251,\n",
      "         0.4744, 0.9066, 0.8505, 0.4637, 0.3278, 0.2012, 0.4225, 0.0817, 0.0369,\n",
      "         0.3821, 0.6733, 0.2988, 0.9151, 0.8625, 0.2993, 0.9432, 0.1629, 0.7868,\n",
      "         0.8480, 0.9026, 0.8256, 0.1796, 0.2215, 0.8181, 0.2397, 0.4570, 0.6731,\n",
      "         0.4162, 0.4299, 0.3998, 0.8336, 0.3879, 0.4558, 0.5221, 0.7107, 0.4498,\n",
      "         0.4903, 0.0756, 0.3184, 0.6995, 0.7545, 0.9120, 0.3860, 0.1733, 0.4518,\n",
      "         0.7488, 0.0565, 0.3481, 0.8739, 0.6464, 0.8420, 0.4846, 0.9718, 0.9534,\n",
      "         0.2071, 0.2825, 0.6559, 0.4682, 0.9552, 0.2764, 0.4748, 0.1280, 0.3096,\n",
      "         0.1837, 0.4305, 0.5785, 0.3656, 0.8481, 0.4150, 0.8448, 0.3679, 0.3184,\n",
      "         0.6967, 0.6953, 0.3865, 0.7010, 0.0873, 0.3788, 0.8631, 0.2631, 0.3048,\n",
      "         0.2856, 0.0508, 0.1693, 0.1355, 0.2237, 0.3412, 0.0590, 0.4064, 0.2550,\n",
      "         0.8769, 0.4458, 0.7534, 0.4259, 0.7580, 0.7129, 0.0970, 0.1435, 0.2002,\n",
      "         0.3042, 0.4695, 0.9429, 0.9680, 0.3198, 0.3609, 0.4656, 0.6138]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[77431, 2048], edge_index=[2, 696879], y=[77431, 2], pos=[77431, 2], censor=[4], duration=[4], batch=[77431], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000,  0.8582,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.2135,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.1967,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.7026,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  9\n",
      "Data[0]:  tensor([[5.0614e+01, 1.1151e+01, 0.0000e+00, 4.1896e+00, 0.0000e+00, 2.5580e+00,\n",
      "         0.0000e+00, 1.6751e+00, 1.7371e+00, 0.0000e+00, 6.4095e+00, 0.0000e+00,\n",
      "         1.9060e+01, 2.6059e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.9894e+01, 2.8197e+00, 9.2453e-01, 3.3905e+00, 3.2408e-01, 1.2951e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3519e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.4315e+01, 2.5004e+00, 7.9476e+00, 1.5355e+00, 0.0000e+00, 3.5377e-01,\n",
      "         0.0000e+00, 1.1928e-01, 4.3532e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7921e+00, 0.0000e+00, 1.2514e-03, 0.0000e+00, 0.0000e+00],\n",
      "        [5.7732e+01, 4.2428e+00, 3.9475e+00, 4.2951e+00, 0.0000e+00, 4.8261e+00,\n",
      "         0.0000e+00, 8.4308e+00, 2.9776e+00, 3.1302e-03, 6.6188e+00, 0.0000e+00,\n",
      "         5.1181e+00, 1.8081e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6616, 0.9207, 0.9790, 0.8450, 0.8371, 0.5924, 0.7272, 0.4334, 0.6723,\n",
      "         0.7470, 0.4875, 0.7719, 0.1502, 0.9089, 0.7284, 0.3265, 0.1040, 0.5433,\n",
      "         0.8044, 0.5562, 0.0793, 0.7520, 0.4608, 0.6844, 0.2152, 0.2880, 0.6978,\n",
      "         0.5450, 0.9502, 0.8619, 0.5326, 0.5219, 0.4052, 0.5445, 0.1145, 0.0492,\n",
      "         0.5747, 0.5164, 0.3528, 0.9271, 0.9340, 0.5116, 0.6320, 0.3389, 0.4056,\n",
      "         0.8366, 0.9068, 0.4865, 0.1988, 0.3395, 0.7477, 0.1028, 0.5961, 0.4613,\n",
      "         0.6985, 0.6542, 0.8515, 0.8670, 0.6005, 0.6312, 0.1883, 0.8652, 0.8091,\n",
      "         0.5195, 0.0860, 0.3641, 0.7359, 0.6870, 0.9531, 0.6492, 0.5114, 0.3310,\n",
      "         0.9088, 0.3392, 0.5116, 0.7588, 0.7252, 0.7729, 0.0693, 0.9649, 0.9406,\n",
      "         0.4552, 0.9212, 0.5813, 0.4478, 0.9503, 0.4693, 0.7249, 0.1421, 0.5519,\n",
      "         0.2249, 0.8615, 0.8438, 0.5719, 0.8614, 0.7648, 0.6950, 0.5512, 0.4600,\n",
      "         0.8764, 0.6233, 0.7603, 0.5480, 0.4288, 0.4821, 0.7031, 0.4735, 0.5999,\n",
      "         0.5653, 0.3582, 0.3839, 0.2262, 0.4144, 0.4749, 0.1671, 0.6437, 0.1997,\n",
      "         0.7651, 0.5426, 0.5420, 0.8628, 0.5309, 0.5057, 0.2678, 0.1528, 0.4991,\n",
      "         0.5279, 0.6634, 0.9324, 0.9634, 0.5208, 0.6418, 0.6353, 0.8733],\n",
      "        [0.9697, 0.9741, 0.4200, 0.9100, 0.5732, 0.1617, 0.8252, 0.2489, 0.8758,\n",
      "         0.5627, 0.3787, 0.9748, 0.0112, 0.9089, 0.9267, 0.2332, 0.9169, 0.6675,\n",
      "         0.9222, 0.9012, 0.0958, 0.6420, 0.8517, 0.8558, 0.8766, 0.2279, 0.7757,\n",
      "         0.4796, 0.9313, 0.8666, 0.9137, 0.5591, 0.1416, 0.8218, 0.9280, 0.0392,\n",
      "         0.1250, 0.8409, 0.7873, 0.8765, 0.3521, 0.3401, 0.6378, 0.2501, 0.3871,\n",
      "         0.6993, 0.9328, 0.6894, 0.9226, 0.2116, 0.3698, 0.4931, 0.5013, 0.8742,\n",
      "         0.8639, 0.8614, 0.7025, 0.9687, 0.5684, 0.8897, 0.9184, 0.3643, 0.9507,\n",
      "         0.4143, 0.9212, 0.8916, 0.9277, 0.4788, 0.9466, 0.0455, 0.1500, 0.4093,\n",
      "         0.9521, 0.0355, 0.8336, 0.7184, 0.9500, 0.9560, 0.8451, 0.9584, 0.9120,\n",
      "         0.8402, 0.9256, 0.8606, 0.4593, 0.9557, 0.4132, 0.7568, 0.5164, 0.2281,\n",
      "         0.4652, 0.6929, 0.8328, 0.1390, 0.8229, 0.0754, 0.8862, 0.2671, 0.1400,\n",
      "         0.9506, 0.7356, 0.3449, 0.7310, 0.0740, 0.7197, 0.5606, 0.8957, 0.2859,\n",
      "         0.5611, 0.1210, 0.6120, 0.3800, 0.7667, 0.0647, 0.1307, 0.8188, 0.6027,\n",
      "         0.7397, 0.8905, 0.9397, 0.9546, 0.9545, 0.9453, 0.1449, 0.3372, 0.5176,\n",
      "         0.9481, 0.5157, 0.9694, 0.9481, 0.6988, 0.5850, 0.9391, 0.0565],\n",
      "        [0.9738, 0.9748, 0.9884, 0.9620, 0.9418, 0.9545, 0.9779, 0.8647, 0.5527,\n",
      "         0.0866, 0.8902, 0.5196, 0.0171, 0.8709, 0.9187, 0.2777, 0.0352, 0.2622,\n",
      "         0.3349, 0.7176, 0.0592, 0.5513, 0.1200, 0.1151, 0.1010, 0.1519, 0.5088,\n",
      "         0.7753, 0.3660, 0.9346, 0.8984, 0.8364, 0.1029, 0.1149, 0.0656, 0.0291,\n",
      "         0.5559, 0.7600, 0.0646, 0.4376, 0.2044, 0.8984, 0.9394, 0.0542, 0.8739,\n",
      "         0.1744, 0.2120, 0.9153, 0.1968, 0.1137, 0.8658, 0.0685, 0.7201, 0.7931,\n",
      "         0.8010, 0.5798, 0.6097, 0.2842, 0.9154, 0.1555, 0.0513, 0.1268, 0.9548,\n",
      "         0.8046, 0.0610, 0.1791, 0.0929, 0.6551, 0.9324, 0.6451, 0.1280, 0.0696,\n",
      "         0.6836, 0.0767, 0.1127, 0.9252, 0.3334, 0.2720, 0.0511, 0.6409, 0.1568,\n",
      "         0.1118, 0.9295, 0.1817, 0.0576, 0.6417, 0.7200, 0.2413, 0.1141, 0.1365,\n",
      "         0.8633, 0.8401, 0.8540, 0.1687, 0.1442, 0.8609, 0.3380, 0.8097, 0.8241,\n",
      "         0.9506, 0.1619, 0.9346, 0.7715, 0.0566, 0.1349, 0.8956, 0.1117, 0.7530,\n",
      "         0.8805, 0.0702, 0.0868, 0.0679, 0.8390, 0.2816, 0.0531, 0.7347, 0.0810,\n",
      "         0.3198, 0.8342, 0.3862, 0.9506, 0.9351, 0.1832, 0.0479, 0.1223, 0.1222,\n",
      "         0.9064, 0.6282, 0.2177, 0.7432, 0.8630, 0.9368, 0.8956, 0.9441],\n",
      "        [0.8035, 0.9818, 0.9844, 0.9412, 0.9218, 0.9660, 0.9759, 0.7275, 0.7558,\n",
      "         0.5020, 0.9456, 0.9668, 0.0140, 0.9061, 0.9383, 0.4696, 0.3247, 0.3722,\n",
      "         0.8926, 0.6780, 0.0677, 0.8984, 0.3026, 0.1509, 0.1730, 0.1767, 0.7486,\n",
      "         0.7985, 0.8202, 0.8554, 0.7008, 0.6227, 0.4224, 0.6073, 0.0632, 0.0252,\n",
      "         0.8359, 0.6996, 0.4401, 0.5812, 0.6440, 0.8224, 0.9488, 0.2122, 0.8353,\n",
      "         0.6371, 0.5716, 0.8978, 0.1996, 0.1619, 0.8532, 0.2021, 0.8819, 0.6959,\n",
      "         0.9049, 0.6495, 0.7705, 0.6334, 0.8925, 0.4393, 0.2175, 0.3039, 0.9095,\n",
      "         0.8414, 0.2119, 0.2758, 0.4354, 0.9014, 0.9523, 0.7433, 0.1072, 0.4212,\n",
      "         0.8882, 0.0770, 0.3335, 0.8751, 0.4179, 0.5768, 0.0442, 0.7969, 0.7275,\n",
      "         0.3668, 0.8906, 0.3225, 0.2474, 0.8994, 0.4800, 0.4739, 0.1249, 0.1998,\n",
      "         0.6802, 0.7612, 0.8589, 0.2588, 0.6177, 0.8638, 0.4520, 0.7239, 0.6750,\n",
      "         0.8806, 0.3564, 0.9199, 0.7127, 0.0662, 0.1412, 0.8860, 0.0787, 0.6056,\n",
      "         0.8097, 0.0784, 0.1648, 0.1284, 0.3767, 0.6985, 0.0651, 0.8373, 0.1804,\n",
      "         0.5060, 0.8316, 0.4261, 0.9455, 0.9238, 0.3363, 0.1007, 0.1441, 0.1214,\n",
      "         0.8625, 0.8707, 0.3589, 0.8842, 0.8146, 0.8978, 0.8331, 0.8980]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[74422, 2048], edge_index=[2, 669798], y=[74422, 2], pos=[74422, 2], censor=[4], duration=[4], batch=[74422], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -1.0105,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0557,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.7213,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.5495,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Data[0]:  tensor([[8.5154e+01, 1.4899e+00, 8.9853e+00, 1.7151e+00, 0.0000e+00, 2.9513e-01,\n",
      "         0.0000e+00, 3.3794e-02, 8.6546e-02, 0.0000e+00, 2.8515e-01, 0.0000e+00,\n",
      "         1.4628e+00, 2.1396e-01, 1.4182e-01, 6.0730e-02, 7.5681e-02],\n",
      "        [5.8844e+01, 3.7401e+00, 0.0000e+00, 3.1700e+00, 0.0000e+00, 9.9024e+00,\n",
      "         0.0000e+00, 2.4605e+00, 2.1465e+00, 0.0000e+00, 5.6693e+00, 0.0000e+00,\n",
      "         8.9965e+00, 3.3693e+00, 3.9498e-01, 4.1574e-01, 8.9082e-01],\n",
      "        [5.1349e+01, 6.6520e+00, 3.7913e+00, 3.9070e+00, 0.0000e+00, 1.2613e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.2623e+00, 7.2794e-01, 5.5044e+00, 0.0000e+00,\n",
      "         1.3742e+01, 2.4631e-01, 0.0000e+00, 0.0000e+00, 8.5557e+00],\n",
      "        [7.1162e+01, 6.1982e+00, 0.0000e+00, 6.2350e+00, 0.0000e+00, 3.2783e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4140e+00, 0.0000e+00,\n",
      "         3.3587e+00, 5.3537e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9759, 0.9710, 0.9873, 0.9371, 0.9578, 0.9125, 0.9777, 0.9163, 0.8852,\n",
      "         0.1800, 0.9154, 0.9851, 0.0156, 0.9419, 0.9044, 0.5931, 0.1354, 0.1841,\n",
      "         0.8983, 0.8635, 0.0497, 0.8765, 0.2367, 0.1409, 0.1246, 0.1745, 0.7222,\n",
      "         0.8878, 0.6941, 0.8865, 0.8963, 0.8995, 0.1234, 0.0385, 0.0797, 0.0245,\n",
      "         0.7871, 0.7847, 0.0919, 0.9406, 0.9312, 0.9338, 0.9490, 0.1079, 0.8955,\n",
      "         0.1362, 0.3917, 0.9225, 0.2689, 0.1245, 0.8720, 0.7702, 0.9345, 0.8664,\n",
      "         0.9385, 0.7049, 0.9270, 0.7234, 0.9310, 0.3968, 0.0625, 0.1799, 0.9341,\n",
      "         0.9259, 0.0827, 0.5990, 0.1540, 0.8718, 0.9512, 0.8164, 0.1471, 0.3135,\n",
      "         0.9018, 0.0698, 0.8035, 0.9118, 0.1267, 0.2221, 0.0603, 0.8829, 0.6829,\n",
      "         0.0961, 0.9317, 0.3041, 0.0825, 0.9445, 0.8129, 0.1693, 0.1211, 0.1195,\n",
      "         0.9345, 0.8596, 0.8584, 0.2150, 0.1557, 0.8580, 0.3691, 0.8859, 0.9228,\n",
      "         0.9381, 0.1170, 0.9306, 0.8200, 0.0775, 0.1395, 0.8797, 0.0881, 0.8499,\n",
      "         0.9087, 0.0519, 0.1375, 0.1314, 0.8782, 0.7968, 0.0544, 0.8972, 0.1272,\n",
      "         0.4165, 0.9319, 0.8384, 0.9558, 0.9278, 0.1754, 0.1077, 0.0819, 0.0975,\n",
      "         0.9012, 0.8872, 0.1399, 0.9079, 0.8713, 0.8865, 0.9244, 0.9309],\n",
      "        [0.7670, 0.9067, 0.7268, 0.5471, 0.8267, 0.9524, 0.9214, 0.4476, 0.4764,\n",
      "         0.5569, 0.9190, 0.5926, 0.3588, 0.9284, 0.6046, 0.2538, 0.5171, 0.3251,\n",
      "         0.8473, 0.2889, 0.0491, 0.8657, 0.3606, 0.1530, 0.2060, 0.1784, 0.5318,\n",
      "         0.6548, 0.8567, 0.8892, 0.6027, 0.5436, 0.1272, 0.4688, 0.0789, 0.0198,\n",
      "         0.4849, 0.5535, 0.5106, 0.8379, 0.7210, 0.5422, 0.9103, 0.2335, 0.8836,\n",
      "         0.4943, 0.8184, 0.8924, 0.1807, 0.1947, 0.8313, 0.1538, 0.7533, 0.4160,\n",
      "         0.8048, 0.5692, 0.4723, 0.8262, 0.6109, 0.2821, 0.1919, 0.6401, 0.9350,\n",
      "         0.7358, 0.2123, 0.2858, 0.8074, 0.8337, 0.9466, 0.5848, 0.6361, 0.1755,\n",
      "         0.8920, 0.0560, 0.1959, 0.8085, 0.6244, 0.8208, 0.0989, 0.9559, 0.9245,\n",
      "         0.3051, 0.4900, 0.3967, 0.2109, 0.9555, 0.3977, 0.4378, 0.0975, 0.1674,\n",
      "         0.3407, 0.6804, 0.9031, 0.3035, 0.4822, 0.5571, 0.8006, 0.4993, 0.4045,\n",
      "         0.8863, 0.3397, 0.8803, 0.7139, 0.0872, 0.2104, 0.8562, 0.3346, 0.3680,\n",
      "         0.5066, 0.0640, 0.1517, 0.1598, 0.5277, 0.6346, 0.0551, 0.7116, 0.1155,\n",
      "         0.7560, 0.6902, 0.7269, 0.9357, 0.8919, 0.6895, 0.5497, 0.1619, 0.2055,\n",
      "         0.5771, 0.7293, 0.8850, 0.9655, 0.4357, 0.5025, 0.6122, 0.8110],\n",
      "        [0.7163, 0.7363, 0.9611, 0.5188, 0.6315, 0.9343, 0.8297, 0.3917, 0.6485,\n",
      "         0.6472, 0.4933, 0.5724, 0.5466, 0.9276, 0.6543, 0.2661, 0.0944, 0.4379,\n",
      "         0.7016, 0.2511, 0.0595, 0.5058, 0.3333, 0.3619, 0.2890, 0.2909, 0.5694,\n",
      "         0.5179, 0.9513, 0.8201, 0.5976, 0.6364, 0.1529, 0.5289, 0.0981, 0.0270,\n",
      "         0.7729, 0.5602, 0.4891, 0.8516, 0.8957, 0.4536, 0.9319, 0.1326, 0.4571,\n",
      "         0.7255, 0.9097, 0.5395, 0.2343, 0.3251, 0.5849, 0.0866, 0.5510, 0.4692,\n",
      "         0.5469, 0.5716, 0.5108, 0.7619, 0.5901, 0.6616, 0.1406, 0.6067, 0.9322,\n",
      "         0.7655, 0.1602, 0.2197, 0.3597, 0.4564, 0.9382, 0.4813, 0.1293, 0.2442,\n",
      "         0.9260, 0.1210, 0.1493, 0.8698, 0.1625, 0.7870, 0.0579, 0.9572, 0.8841,\n",
      "         0.1560, 0.9447, 0.4760, 0.1827, 0.9605, 0.4780, 0.5064, 0.0995, 0.2684,\n",
      "         0.2029, 0.6637, 0.8154, 0.2323, 0.5310, 0.7571, 0.7286, 0.5021, 0.5569,\n",
      "         0.6168, 0.4568, 0.8523, 0.5769, 0.0924, 0.3627, 0.8338, 0.2744, 0.4384,\n",
      "         0.4855, 0.0876, 0.1369, 0.1207, 0.5003, 0.4018, 0.0600, 0.5545, 0.3393,\n",
      "         0.9013, 0.8941, 0.7390, 0.8171, 0.9384, 0.5481, 0.0667, 0.1099, 0.2084,\n",
      "         0.4931, 0.5959, 0.9548, 0.9615, 0.2787, 0.3338, 0.7183, 0.6163],\n",
      "        [0.7079, 0.9766, 0.9798, 0.2827, 0.7059, 0.2585, 0.5245, 0.6298, 0.2081,\n",
      "         0.7578, 0.8086, 0.4235, 0.0111, 0.9184, 0.5189, 0.1801, 0.3525, 0.7559,\n",
      "         0.8036, 0.6963, 0.0869, 0.8034, 0.5795, 0.5513, 0.4161, 0.2635, 0.7172,\n",
      "         0.4407, 0.9199, 0.8608, 0.4190, 0.4421, 0.5164, 0.7939, 0.2802, 0.0396,\n",
      "         0.2269, 0.2637, 0.4181, 0.9140, 0.8963, 0.8069, 0.5794, 0.5190, 0.6631,\n",
      "         0.7720, 0.9329, 0.7865, 0.6700, 0.4191, 0.3498, 0.0674, 0.8039, 0.2949,\n",
      "         0.9237, 0.2302, 0.3527, 0.8848, 0.9132, 0.6011, 0.1711, 0.8077, 0.7516,\n",
      "         0.6997, 0.8391, 0.5312, 0.7484, 0.6728, 0.5660, 0.3060, 0.1732, 0.6231,\n",
      "         0.9172, 0.1369, 0.5115, 0.7661, 0.7543, 0.8907, 0.1635, 0.9433, 0.9343,\n",
      "         0.7708, 0.6374, 0.6619, 0.5893, 0.9514, 0.2536, 0.6124, 0.1969, 0.4810,\n",
      "         0.4268, 0.7479, 0.8316, 0.7309, 0.8369, 0.3843, 0.8951, 0.8712, 0.5337,\n",
      "         0.5827, 0.3897, 0.7301, 0.6969, 0.1192, 0.3548, 0.3770, 0.7310, 0.2779,\n",
      "         0.8393, 0.0721, 0.3706, 0.4258, 0.1175, 0.5303, 0.1096, 0.7752, 0.4155,\n",
      "         0.7915, 0.8493, 0.8018, 0.9097, 0.8624, 0.8021, 0.4177, 0.4261, 0.2844,\n",
      "         0.4129, 0.6754, 0.9472, 0.9542, 0.7109, 0.8225, 0.4746, 0.8199]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[72621, 2048], edge_index=[2, 653589], y=[72621, 2], pos=[72621, 2], censor=[4], duration=[4], batch=[72621], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.0868,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.9427,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.3886,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0675,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  11\n",
      "Data[0]:  tensor([[79.0097,  1.2196,  2.3352,  7.6616,  0.0000,  0.4296,  0.0000,  0.6600,\n",
      "          1.3467,  0.0000,  0.0000,  0.0000,  5.0740,  0.7763,  0.9898,  0.4975,\n",
      "          0.0000],\n",
      "        [81.1958,  1.2315,  2.1779,  2.9652,  0.0000,  2.9296,  0.0000,  0.2977,\n",
      "          1.2347,  0.0000,  5.1300,  0.0000,  0.0000,  0.0000,  2.8376,  0.0000,\n",
      "          0.0000],\n",
      "        [63.9980,  5.4235,  5.0711,  7.6021,  0.0000,  2.4926,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  4.8887,  0.0000,  6.6038,  2.2246,  0.2282,  0.5525,\n",
      "          0.9150],\n",
      "        [56.7332, 11.7644,  0.0000, 15.7628,  0.0000,  1.6793,  0.0000,  0.5936,\n",
      "          0.7337,  0.0000,  0.0000,  0.0000,  8.2780,  3.9356,  0.1979,  0.1123,\n",
      "          0.2094]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.8507, 0.9787, 0.9906, 0.9721, 0.9226, 0.8861, 0.9802, 0.8384, 0.6485,\n",
      "         0.6486, 0.8363, 0.9546, 0.0176, 0.9559, 0.7014, 0.3485, 0.4404, 0.2835,\n",
      "         0.2337, 0.6623, 0.0787, 0.9126, 0.3076, 0.1620, 0.1763, 0.1741, 0.3546,\n",
      "         0.8230, 0.5596, 0.8700, 0.7103, 0.7497, 0.4985, 0.4354, 0.1371, 0.0423,\n",
      "         0.4802, 0.6595, 0.1469, 0.7033, 0.2525, 0.7984, 0.9249, 0.2145, 0.6772,\n",
      "         0.2090, 0.6581, 0.7658, 0.6400, 0.1298, 0.6272, 0.0906, 0.8172, 0.7157,\n",
      "         0.9123, 0.7441, 0.8354, 0.6523, 0.8749, 0.2397, 0.1280, 0.2416, 0.9464,\n",
      "         0.7688, 0.0897, 0.1587, 0.2701, 0.8436, 0.9616, 0.6346, 0.3546, 0.1745,\n",
      "         0.9175, 0.3645, 0.2763, 0.7167, 0.1491, 0.6879, 0.2062, 0.6474, 0.3495,\n",
      "         0.1429, 0.8052, 0.2976, 0.1820, 0.6934, 0.5699, 0.2543, 0.1486, 0.2038,\n",
      "         0.5987, 0.8292, 0.8523, 0.2178, 0.3479, 0.8288, 0.3002, 0.8250, 0.7133,\n",
      "         0.8445, 0.2420, 0.8505, 0.6709, 0.0787, 0.1271, 0.6776, 0.0733, 0.7545,\n",
      "         0.7990, 0.0527, 0.4013, 0.1142, 0.7846, 0.7500, 0.0519, 0.7425, 0.2977,\n",
      "         0.4427, 0.7173, 0.5224, 0.9552, 0.7538, 0.3017, 0.1451, 0.1506, 0.1783,\n",
      "         0.8334, 0.8011, 0.9282, 0.8520, 0.6950, 0.7172, 0.7678, 0.8158],\n",
      "        [0.9110, 0.9745, 0.9845, 0.9361, 0.9255, 0.9423, 0.9742, 0.8048, 0.2602,\n",
      "         0.2815, 0.8923, 0.8888, 0.0139, 0.9395, 0.9409, 0.5942, 0.0531, 0.2028,\n",
      "         0.1634, 0.8035, 0.0706, 0.8392, 0.1376, 0.1135, 0.0896, 0.1679, 0.4262,\n",
      "         0.9018, 0.4205, 0.8786, 0.7195, 0.5666, 0.1446, 0.2943, 0.0624, 0.0370,\n",
      "         0.6240, 0.7258, 0.2221, 0.3583, 0.1913, 0.7860, 0.8066, 0.1922, 0.8428,\n",
      "         0.1494, 0.2654, 0.8878, 0.3899, 0.1097, 0.7905, 0.0473, 0.7991, 0.8071,\n",
      "         0.8979, 0.7034, 0.4835, 0.4999, 0.7068, 0.1689, 0.0710, 0.4251, 0.9346,\n",
      "         0.6985, 0.0644, 0.1277, 0.2366, 0.8429, 0.9217, 0.6799, 0.1785, 0.1282,\n",
      "         0.8877, 0.0483, 0.2359, 0.9095, 0.0633, 0.3710, 0.0514, 0.5967, 0.3738,\n",
      "         0.1308, 0.9072, 0.2080, 0.1108, 0.6765, 0.4711, 0.2654, 0.0954, 0.1227,\n",
      "         0.7481, 0.8200, 0.7913, 0.5004, 0.2073, 0.8150, 0.1899, 0.7654, 0.2663,\n",
      "         0.9453, 0.1379, 0.7382, 0.7379, 0.0831, 0.1345, 0.3981, 0.0841, 0.7404,\n",
      "         0.6654, 0.0679, 0.1196, 0.2361, 0.7948, 0.7736, 0.0451, 0.8782, 0.0920,\n",
      "         0.2355, 0.8430, 0.6533, 0.9432, 0.8562, 0.1380, 0.0457, 0.0789, 0.0893,\n",
      "         0.8238, 0.7367, 0.2804, 0.6558, 0.8005, 0.8547, 0.8022, 0.8845],\n",
      "        [0.9026, 0.9443, 0.9892, 0.9548, 0.4689, 0.9187, 0.9785, 0.8177, 0.8806,\n",
      "         0.9013, 0.6340, 0.9702, 0.0110, 0.9221, 0.9406, 0.6153, 0.6357, 0.5569,\n",
      "         0.8648, 0.4454, 0.0632, 0.8769, 0.2429, 0.1752, 0.6618, 0.2087, 0.9122,\n",
      "         0.8538, 0.9580, 0.8823, 0.8108, 0.8003, 0.1776, 0.6188, 0.0899, 0.0263,\n",
      "         0.7943, 0.6554, 0.6372, 0.8214, 0.9148, 0.4396, 0.8497, 0.1045, 0.6938,\n",
      "         0.8200, 0.8859, 0.8414, 0.6306, 0.1954, 0.8904, 0.5391, 0.6072, 0.6799,\n",
      "         0.4339, 0.6568, 0.6273, 0.8520, 0.4905, 0.5744, 0.6798, 0.8217, 0.9094,\n",
      "         0.6627, 0.7272, 0.5654, 0.8220, 0.7420, 0.9245, 0.6598, 0.0872, 0.1525,\n",
      "         0.8962, 0.1048, 0.3448, 0.8402, 0.2155, 0.8223, 0.3420, 0.9488, 0.9261,\n",
      "         0.1842, 0.9117, 0.2674, 0.1365, 0.9403, 0.4283, 0.3922, 0.4321, 0.3911,\n",
      "         0.6545, 0.8154, 0.8621, 0.3104, 0.5201, 0.8507, 0.6702, 0.4287, 0.8641,\n",
      "         0.9091, 0.2973, 0.8270, 0.7586, 0.0659, 0.6188, 0.8223, 0.6310, 0.6921,\n",
      "         0.2850, 0.0657, 0.1631, 0.1668, 0.7456, 0.3608, 0.0462, 0.8087, 0.7099,\n",
      "         0.8501, 0.8348, 0.8606, 0.9440, 0.9402, 0.5079, 0.0558, 0.1337, 0.1636,\n",
      "         0.8792, 0.8092, 0.8779, 0.9357, 0.5503, 0.5794, 0.9181, 0.8625],\n",
      "        [0.8125, 0.9806, 0.9878, 0.8539, 0.6480, 0.6129, 0.9811, 0.6217, 0.5269,\n",
      "         0.8140, 0.6785, 0.7534, 0.0480, 0.9380, 0.7825, 0.2970, 0.3585, 0.4208,\n",
      "         0.7315, 0.4700, 0.0780, 0.8628, 0.4722, 0.3093, 0.3246, 0.2094, 0.4267,\n",
      "         0.7497, 0.8525, 0.8812, 0.6004, 0.7519, 0.4373, 0.5516, 0.2632, 0.0328,\n",
      "         0.6229, 0.4275, 0.2219, 0.8771, 0.6942, 0.5698, 0.8880, 0.4335, 0.4687,\n",
      "         0.5362, 0.7155, 0.5245, 0.7348, 0.2023, 0.5905, 0.1878, 0.6253, 0.4107,\n",
      "         0.8752, 0.4015, 0.7283, 0.7144, 0.6934, 0.5164, 0.3874, 0.6787, 0.8362,\n",
      "         0.5807, 0.1343, 0.3241, 0.7267, 0.7097, 0.9496, 0.5893, 0.2105, 0.4340,\n",
      "         0.8911, 0.3003, 0.5539, 0.8400, 0.3126, 0.8670, 0.3467, 0.9371, 0.8870,\n",
      "         0.3488, 0.8656, 0.4526, 0.3301, 0.9279, 0.6136, 0.6041, 0.2436, 0.4054,\n",
      "         0.3864, 0.7640, 0.8899, 0.6885, 0.5768, 0.8060, 0.8141, 0.7750, 0.7943,\n",
      "         0.2939, 0.4676, 0.7511, 0.5344, 0.1539, 0.2411, 0.5193, 0.0998, 0.6362,\n",
      "         0.6174, 0.0746, 0.2479, 0.1566, 0.5116, 0.5608, 0.1059, 0.6699, 0.3404,\n",
      "         0.6406, 0.8952, 0.7959, 0.9568, 0.8344, 0.6539, 0.1270, 0.2606, 0.4437,\n",
      "         0.8565, 0.8071, 0.8456, 0.9495, 0.4727, 0.5756, 0.7857, 0.7915]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[97472, 2048], edge_index=[2, 877248], y=[97472, 2], pos=[97472, 2], censor=[4], duration=[4], batch=[97472], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  1.3062,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.1288,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.0245,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.8147,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  12\n",
      "Data[0]:  tensor([[57.1579,  7.5409,  5.0934,  6.8296,  0.0000,  3.8242,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  8.7007,  0.0000,  7.7790,  3.0743,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [86.6496,  4.7123,  2.5474,  2.3411,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.7998,  0.9498,\n",
      "          0.0000],\n",
      "        [67.9631,  9.0024,  8.3237,  3.3637,  0.0000,  3.1841,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  8.1630,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [55.7166,  0.9742,  0.0000,  1.8856,  1.0716, 13.7688,  0.0000,  7.4385,\n",
      "          5.7605,  0.8750,  6.0304,  0.0000,  4.8687,  1.6101,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7414, 0.9775, 0.9857, 0.8650, 0.8917, 0.9030, 0.9675, 0.5369, 0.7626,\n",
      "         0.6739, 0.9051, 0.5407, 0.1418, 0.9428, 0.5829, 0.5534, 0.3603, 0.3958,\n",
      "         0.8172, 0.4158, 0.0787, 0.8652, 0.3515, 0.2222, 0.3791, 0.2660, 0.8162,\n",
      "         0.7927, 0.9442, 0.8476, 0.6578, 0.5818, 0.3504, 0.7251, 0.1203, 0.0270,\n",
      "         0.7524, 0.6268, 0.5731, 0.8890, 0.7506, 0.8013, 0.9256, 0.2298, 0.4789,\n",
      "         0.3673, 0.8984, 0.4907, 0.2275, 0.1720, 0.8361, 0.3003, 0.7954, 0.6263,\n",
      "         0.8749, 0.5395, 0.7108, 0.7465, 0.8975, 0.5475, 0.2144, 0.5432, 0.9319,\n",
      "         0.8222, 0.3757, 0.3433, 0.7916, 0.8738, 0.9534, 0.6068, 0.2616, 0.2722,\n",
      "         0.9248, 0.1387, 0.4366, 0.8669, 0.2720, 0.7749, 0.0704, 0.9368, 0.7382,\n",
      "         0.2539, 0.6861, 0.3817, 0.2896, 0.9400, 0.5502, 0.4252, 0.2526, 0.2861,\n",
      "         0.5496, 0.8048, 0.8357, 0.3876, 0.3921, 0.7540, 0.7117, 0.7780, 0.7439,\n",
      "         0.6815, 0.3837, 0.8065, 0.6542, 0.0889, 0.2799, 0.8127, 0.0742, 0.4745,\n",
      "         0.7420, 0.0786, 0.2335, 0.1400, 0.3427, 0.6137, 0.0828, 0.5605, 0.3842,\n",
      "         0.5593, 0.8906, 0.7342, 0.9410, 0.9198, 0.6544, 0.3012, 0.1910, 0.2190,\n",
      "         0.6211, 0.8338, 0.8001, 0.9204, 0.7747, 0.8194, 0.7400, 0.8940],\n",
      "        [0.9601, 0.9814, 0.9907, 0.9643, 0.9099, 0.9754, 0.9842, 0.9052, 0.7267,\n",
      "         0.3531, 0.9628, 0.9714, 0.7956, 0.9622, 0.9511, 0.6989, 0.1368, 0.5261,\n",
      "         0.4202, 0.7926, 0.0567, 0.6580, 0.1343, 0.1399, 0.1629, 0.1286, 0.7874,\n",
      "         0.8835, 0.3114, 0.9016, 0.7638, 0.5186, 0.1189, 0.1907, 0.0717, 0.0205,\n",
      "         0.7044, 0.7878, 0.0990, 0.1300, 0.1378, 0.9022, 0.9323, 0.0591, 0.6751,\n",
      "         0.2265, 0.5247, 0.8529, 0.2558, 0.1075, 0.8726, 0.0658, 0.8867, 0.8438,\n",
      "         0.8604, 0.8067, 0.9320, 0.2693, 0.9175, 0.2438, 0.0841, 0.3102, 0.9515,\n",
      "         0.8262, 0.0492, 0.6059, 0.1276, 0.6902, 0.8178, 0.8277, 0.0770, 0.0865,\n",
      "         0.9302, 0.0760, 0.3254, 0.5262, 0.0499, 0.3817, 0.0515, 0.3321, 0.1938,\n",
      "         0.1182, 0.9414, 0.1782, 0.0801, 0.5988, 0.7669, 0.1609, 0.0997, 0.1304,\n",
      "         0.9378, 0.7915, 0.8855, 0.1533, 0.2345, 0.8861, 0.1931, 0.8272, 0.9031,\n",
      "         0.9081, 0.1980, 0.9395, 0.8286, 0.0870, 0.1840, 0.7573, 0.0797, 0.5760,\n",
      "         0.9261, 0.0651, 0.0997, 0.1054, 0.8628, 0.7499, 0.0516, 0.8145, 0.3200,\n",
      "         0.3932, 0.9569, 0.5515, 0.9634, 0.9426, 0.1695, 0.0591, 0.1216, 0.1408,\n",
      "         0.9236, 0.9007, 0.3774, 0.7878, 0.5507, 0.5431, 0.9213, 0.9403],\n",
      "        [0.8260, 0.9732, 0.9831, 0.8779, 0.8175, 0.9124, 0.9754, 0.8319, 0.7144,\n",
      "         0.6059, 0.7858, 0.8762, 0.0204, 0.9248, 0.9320, 0.2483, 0.1525, 0.2998,\n",
      "         0.5325, 0.6918, 0.0787, 0.9059, 0.3011, 0.2022, 0.1559, 0.2255, 0.6443,\n",
      "         0.8072, 0.5025, 0.8819, 0.7293, 0.5813, 0.2522, 0.3893, 0.1138, 0.0304,\n",
      "         0.7634, 0.6297, 0.5600, 0.5009, 0.2668, 0.7284, 0.7411, 0.1498, 0.6806,\n",
      "         0.3581, 0.6390, 0.8167, 0.5404, 0.1863, 0.6728, 0.0581, 0.7299, 0.6678,\n",
      "         0.8880, 0.7385, 0.6658, 0.4447, 0.7829, 0.3674, 0.1941, 0.3291, 0.8610,\n",
      "         0.5958, 0.1721, 0.1909, 0.3901, 0.7341, 0.9555, 0.6345, 0.1607, 0.2549,\n",
      "         0.7234, 0.0757, 0.2278, 0.8320, 0.2285, 0.4941, 0.0591, 0.7758, 0.3930,\n",
      "         0.1976, 0.8649, 0.2906, 0.2343, 0.8332, 0.3504, 0.3645, 0.1590, 0.2338,\n",
      "         0.5650, 0.7084, 0.6772, 0.3141, 0.5728, 0.7649, 0.2728, 0.7161, 0.7270,\n",
      "         0.6637, 0.3041, 0.8555, 0.6509, 0.0652, 0.1479, 0.7312, 0.0621, 0.6281,\n",
      "         0.7630, 0.1191, 0.2431, 0.1377, 0.1841, 0.6369, 0.0685, 0.8031, 0.1590,\n",
      "         0.4547, 0.8353, 0.4009, 0.9589, 0.8157, 0.2245, 0.0987, 0.1846, 0.2339,\n",
      "         0.8129, 0.8546, 0.8687, 0.7557, 0.7752, 0.8626, 0.5948, 0.7234],\n",
      "        [0.6664, 0.9734, 0.9759, 0.8027, 0.9216, 0.9573, 0.9040, 0.6590, 0.6718,\n",
      "         0.4257, 0.9716, 0.9493, 0.0176, 0.9140, 0.9165, 0.5238, 0.3261, 0.3411,\n",
      "         0.8525, 0.8687, 0.1276, 0.7011, 0.3357, 0.1395, 0.1774, 0.2335, 0.9040,\n",
      "         0.8096, 0.6500, 0.9004, 0.4982, 0.6924, 0.1484, 0.4283, 0.0696, 0.0948,\n",
      "         0.8434, 0.6743, 0.3646, 0.6369, 0.4932, 0.8799, 0.9428, 0.1759, 0.8599,\n",
      "         0.4763, 0.6762, 0.8986, 0.1786, 0.1705, 0.7448, 0.0702, 0.9129, 0.6571,\n",
      "         0.9403, 0.6914, 0.8206, 0.4714, 0.9127, 0.3245, 0.3398, 0.4962, 0.9032,\n",
      "         0.8994, 0.2469, 0.4643, 0.6503, 0.8948, 0.9510, 0.6841, 0.1543, 0.2380,\n",
      "         0.9016, 0.0967, 0.1982, 0.7238, 0.4717, 0.6525, 0.0745, 0.8785, 0.5895,\n",
      "         0.2112, 0.9370, 0.4440, 0.2390, 0.9198, 0.4696, 0.4229, 0.1637, 0.2328,\n",
      "         0.6588, 0.7588, 0.8603, 0.2105, 0.4030, 0.8607, 0.3577, 0.8538, 0.7987,\n",
      "         0.9418, 0.2799, 0.9222, 0.7463, 0.0871, 0.2405, 0.8454, 0.0767, 0.5972,\n",
      "         0.8395, 0.0992, 0.1377, 0.1197, 0.6905, 0.6422, 0.0598, 0.8033, 0.4118,\n",
      "         0.6193, 0.7918, 0.5529, 0.9193, 0.9408, 0.2157, 0.0623, 0.0980, 0.1176,\n",
      "         0.8210, 0.8610, 0.2934, 0.9567, 0.8486, 0.9224, 0.5522, 0.8950]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[81699, 2048], edge_index=[2, 735291], y=[81699, 2], pos=[81699, 2], censor=[4], duration=[4], batch=[81699], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  1.3302,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.0912,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.4321,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.7302,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  13\n",
      "Data[0]:  tensor([[58.2150,  5.6533,  0.0000,  6.8247,  0.0000,  0.8437,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  3.2758,  3.0804,  6.8379,  3.2836,  1.2415,  0.0000,\n",
      "         10.7440],\n",
      "        [66.0627,  6.7767,  3.3182,  5.2416,  0.0000,  3.7266,  0.0000,  1.1819,\n",
      "          3.0066,  0.0000,  0.0000,  0.0000,  5.8026,  2.5412,  0.6817,  0.8658,\n",
      "          0.7944],\n",
      "        [31.8503, 12.0391,  4.1874,  7.3851,  1.4255, 14.1031,  0.0000,  4.6514,\n",
      "          2.4721,  1.9278, 12.3966,  0.0000,  6.2029,  1.3586,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [45.2517, 11.1107,  2.4914,  8.5422,  0.0778, 11.3863,  0.0000,  3.7471,\n",
      "          2.8645,  0.0679,  5.3153,  0.0000,  5.4429,  3.7021,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9668, 0.9780, 0.9877, 0.5717, 0.5602, 0.2791, 0.9779, 0.3565, 0.5941,\n",
      "         0.8599, 0.4992, 0.5304, 0.0150, 0.8174, 0.7909, 0.2952, 0.5785, 0.4016,\n",
      "         0.7953, 0.2043, 0.0572, 0.6906, 0.5350, 0.3094, 0.1403, 0.2770, 0.3713,\n",
      "         0.8323, 0.9462, 0.8535, 0.7879, 0.7349, 0.2152, 0.6418, 0.0605, 0.0268,\n",
      "         0.5318, 0.5895, 0.4132, 0.7903, 0.8267, 0.4055, 0.9273, 0.3069, 0.7233,\n",
      "         0.5337, 0.8845, 0.8425, 0.6829, 0.2676, 0.7144, 0.1187, 0.5454, 0.5520,\n",
      "         0.6271, 0.6837, 0.6756, 0.7857, 0.6744, 0.5316, 0.1775, 0.8349, 0.8984,\n",
      "         0.5351, 0.0943, 0.2510, 0.6590, 0.7807, 0.9592, 0.6091, 0.1313, 0.2709,\n",
      "         0.9283, 0.2498, 0.3598, 0.8606, 0.0498, 0.8171, 0.3307, 0.9366, 0.8979,\n",
      "         0.2545, 0.9007, 0.5782, 0.2242, 0.9451, 0.4262, 0.7000, 0.1697, 0.2748,\n",
      "         0.1629, 0.7994, 0.7014, 0.5441, 0.5083, 0.7299, 0.5182, 0.3630, 0.4420,\n",
      "         0.6458, 0.4702, 0.5915, 0.7071, 0.0814, 0.4830, 0.5002, 0.2408, 0.5250,\n",
      "         0.4792, 0.0731, 0.4445, 0.1658, 0.3603, 0.5649, 0.0624, 0.7198, 0.2861,\n",
      "         0.7269, 0.7081, 0.7602, 0.9003, 0.7313, 0.2497, 0.0660, 0.1842, 0.2773,\n",
      "         0.6069, 0.8041, 0.9295, 0.9474, 0.5238, 0.5513, 0.7746, 0.8937],\n",
      "        [0.6854, 0.9695, 0.8376, 0.9622, 0.9133, 0.9224, 0.9837, 0.7610, 0.7780,\n",
      "         0.7110, 0.9675, 0.4234, 0.0589, 0.8712, 0.6050, 0.3064, 0.5448, 0.2474,\n",
      "         0.8659, 0.2567, 0.0686, 0.8724, 0.5547, 0.1800, 0.2682, 0.2215, 0.3581,\n",
      "         0.4537, 0.8635, 0.8802, 0.4733, 0.5561, 0.6283, 0.6670, 0.1085, 0.0595,\n",
      "         0.3911, 0.6819, 0.3456, 0.8171, 0.8255, 0.7779, 0.6984, 0.1587, 0.9056,\n",
      "         0.3467, 0.8471, 0.8943, 0.7446, 0.1772, 0.6762, 0.1646, 0.7500, 0.6898,\n",
      "         0.9411, 0.7277, 0.5597, 0.8501, 0.7510, 0.6967, 0.0675, 0.5678, 0.6941,\n",
      "         0.8592, 0.5885, 0.2236, 0.8213, 0.7954, 0.9598, 0.6154, 0.4185, 0.3554,\n",
      "         0.9208, 0.3497, 0.4738, 0.8641, 0.5842, 0.7848, 0.5595, 0.9584, 0.9185,\n",
      "         0.6337, 0.4966, 0.2668, 0.1695, 0.9476, 0.2499, 0.4457, 0.1110, 0.2057,\n",
      "         0.6843, 0.8412, 0.8338, 0.4301, 0.4806, 0.7080, 0.8002, 0.6586, 0.7806,\n",
      "         0.8432, 0.2648, 0.9104, 0.7598, 0.0618, 0.2600, 0.5420, 0.1222, 0.4995,\n",
      "         0.6739, 0.1023, 0.5561, 0.4359, 0.5958, 0.7394, 0.0643, 0.8589, 0.1119,\n",
      "         0.7227, 0.8122, 0.7878, 0.9392, 0.2623, 0.7473, 0.5867, 0.2449, 0.1893,\n",
      "         0.9008, 0.6809, 0.8517, 0.9473, 0.7366, 0.8950, 0.5901, 0.7311],\n",
      "        [0.7908, 0.9747, 0.9872, 0.9120, 0.7547, 0.8741, 0.9784, 0.6702, 0.8079,\n",
      "         0.5578, 0.8490, 0.9133, 0.0552, 0.9292, 0.8532, 0.4849, 0.1096, 0.4817,\n",
      "         0.6739, 0.6644, 0.1070, 0.8695, 0.4637, 0.3201, 0.2655, 0.2747, 0.7977,\n",
      "         0.7523, 0.7786, 0.8150, 0.6518, 0.6816, 0.2985, 0.6892, 0.2527, 0.0406,\n",
      "         0.7157, 0.5577, 0.4957, 0.7645, 0.6352, 0.7280, 0.7656, 0.2151, 0.7335,\n",
      "         0.5754, 0.4360, 0.7497, 0.2897, 0.2428, 0.7882, 0.2406, 0.8023, 0.5260,\n",
      "         0.8984, 0.6012, 0.7298, 0.6129, 0.8125, 0.4109, 0.4230, 0.3443, 0.8684,\n",
      "         0.7860, 0.2666, 0.3828, 0.7074, 0.7320, 0.9394, 0.5701, 0.2460, 0.3208,\n",
      "         0.8759, 0.1588, 0.3517, 0.7395, 0.4103, 0.6241, 0.0513, 0.8878, 0.8824,\n",
      "         0.3399, 0.8494, 0.3833, 0.2929, 0.9255, 0.5357, 0.6199, 0.1527, 0.3648,\n",
      "         0.6057, 0.8282, 0.8544, 0.3800, 0.5677, 0.7725, 0.5965, 0.7998, 0.6353,\n",
      "         0.7898, 0.4120, 0.8792, 0.6523, 0.0871, 0.3253, 0.8308, 0.2431, 0.5603,\n",
      "         0.7020, 0.0598, 0.2580, 0.1852, 0.5109, 0.5367, 0.0943, 0.7963, 0.2440,\n",
      "         0.6247, 0.7217, 0.5772, 0.9245, 0.9034, 0.3978, 0.1733, 0.2156, 0.2999,\n",
      "         0.8193, 0.8680, 0.5564, 0.9426, 0.6609, 0.7555, 0.8216, 0.8325],\n",
      "        [0.7132, 0.9448, 0.9710, 0.5964, 0.5823, 0.8978, 0.9857, 0.6431, 0.5720,\n",
      "         0.5542, 0.5721, 0.6681, 0.3876, 0.9549, 0.8881, 0.4131, 0.2481, 0.5175,\n",
      "         0.7259, 0.4427, 0.0759, 0.8473, 0.4405, 0.3386, 0.2869, 0.3819, 0.6597,\n",
      "         0.6998, 0.8414, 0.8585, 0.6082, 0.7376, 0.3851, 0.5938, 0.1798, 0.0230,\n",
      "         0.6141, 0.3911, 0.4201, 0.6787, 0.6989, 0.6656, 0.9399, 0.1855, 0.6248,\n",
      "         0.7331, 0.6416, 0.7285, 0.4055, 0.2607, 0.8267, 0.2253, 0.6494, 0.3512,\n",
      "         0.7414, 0.4863, 0.7037, 0.6619, 0.6870, 0.3855, 0.4873, 0.3048, 0.4614,\n",
      "         0.5825, 0.1632, 0.4455, 0.6832, 0.7143, 0.8460, 0.5366, 0.3461, 0.4251,\n",
      "         0.8692, 0.2272, 0.4229, 0.7881, 0.2061, 0.7637, 0.1436, 0.7115, 0.7907,\n",
      "         0.3948, 0.7733, 0.3490, 0.2645, 0.8452, 0.5190, 0.5674, 0.2148, 0.3409,\n",
      "         0.5615, 0.6755, 0.8282, 0.3655, 0.5523, 0.6391, 0.5585, 0.5889, 0.5790,\n",
      "         0.7337, 0.5631, 0.8626, 0.6198, 0.1879, 0.2567, 0.6718, 0.3406, 0.5435,\n",
      "         0.6735, 0.0551, 0.1387, 0.1750, 0.5310, 0.6150, 0.1093, 0.8362, 0.3267,\n",
      "         0.6499, 0.7991, 0.6776, 0.9368, 0.8711, 0.4933, 0.1790, 0.2717, 0.3054,\n",
      "         0.8380, 0.8173, 0.7043, 0.9210, 0.6316, 0.6379, 0.5963, 0.8661]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[149871, 2048], edge_index=[2, 1348839], y=[149871, 2], pos=[149871, 2], censor=[4], duration=[4], batch=[149871], ptr=[5])\n",
      "Data[3]:  tensor([[1.0000, 1.3692, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0662, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2511, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.7678, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  14\n",
      "Data[0]:  tensor([[85.1781,  4.0856,  3.4698,  2.7223,  0.0000,  1.0746,  0.0000,  2.5407,\n",
      "          0.5547,  0.0000,  0.0000,  0.0000,  0.0000,  0.3742,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [52.3376,  2.5504,  0.0000,  4.8087,  2.1526,  5.0104,  0.0000,  0.0000,\n",
      "          2.2168,  0.5991, 14.3895,  0.0000, 10.7577,  3.8394,  0.2564,  0.3957,\n",
      "          0.6856],\n",
      "        [75.4889,  2.9179,  1.1104,  5.6934,  0.0000,  4.0326,  0.0000,  2.3385,\n",
      "          1.4715,  0.0000,  2.9670,  0.0000,  1.0661,  1.5615,  0.2370,  0.9126,\n",
      "          0.2026],\n",
      "        [84.3999,  1.1966,  2.1455,  3.3701,  0.0000,  4.0460,  0.0000,  1.6131,\n",
      "          2.9924,  0.0000,  0.0000,  0.0000,  0.0000,  0.2364,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.3425, 0.5077, 0.6617, 0.4832, 0.3870, 0.8409, 0.7455, 0.1063, 0.3451,\n",
      "         0.4155, 0.5713, 0.2627, 0.0129, 0.4267, 0.6436, 0.2550, 0.3547, 0.1877,\n",
      "         0.7984, 0.3697, 0.0993, 0.7015, 0.7510, 0.1097, 0.6208, 0.2112, 0.1253,\n",
      "         0.5103, 0.6610, 0.8335, 0.1880, 0.6509, 0.1454, 0.5979, 0.0897, 0.0466,\n",
      "         0.1461, 0.7557, 0.3370, 0.7136, 0.9421, 0.1670, 0.8008, 0.2746, 0.1682,\n",
      "         0.2799, 0.8111, 0.2141, 0.7635, 0.1382, 0.6264, 0.2797, 0.3807, 0.7616,\n",
      "         0.7075, 0.3807, 0.1829, 0.9369, 0.2300, 0.7776, 0.0581, 0.4660, 0.4779,\n",
      "         0.5727, 0.0856, 0.4527, 0.7800, 0.7405, 0.2829, 0.1791, 0.4936, 0.4391,\n",
      "         0.8698, 0.1035, 0.7617, 0.6948, 0.7916, 0.9077, 0.3186, 0.9612, 0.9581,\n",
      "         0.0851, 0.4767, 0.6663, 0.2626, 0.9530, 0.1465, 0.4824, 0.1796, 0.1497,\n",
      "         0.1006, 0.3073, 0.6666, 0.2003, 0.6574, 0.1942, 0.9163, 0.1855, 0.1213,\n",
      "         0.3683, 0.3831, 0.4210, 0.3820, 0.0674, 0.6046, 0.3966, 0.0773, 0.1811,\n",
      "         0.1074, 0.0999, 0.1928, 0.1644, 0.1921, 0.2689, 0.0478, 0.2900, 0.5077,\n",
      "         0.7774, 0.2901, 0.8785, 0.6622, 0.1583, 0.8994, 0.0689, 0.1220, 0.1513,\n",
      "         0.3446, 0.4998, 0.9548, 0.9433, 0.1609, 0.1420, 0.2116, 0.5740],\n",
      "        [0.7412, 0.8082, 0.8942, 0.9000, 0.8493, 0.8470, 0.9427, 0.4463, 0.7960,\n",
      "         0.8369, 0.5053, 0.8743, 0.0107, 0.9509, 0.9308, 0.2594, 0.4969, 0.3774,\n",
      "         0.9009, 0.6905, 0.0631, 0.7358, 0.4432, 0.2329, 0.4547, 0.2532, 0.6011,\n",
      "         0.6863, 0.9456, 0.8865, 0.4978, 0.5230, 0.2585, 0.7735, 0.1625, 0.0471,\n",
      "         0.5925, 0.4836, 0.4784, 0.8310, 0.7818, 0.3925, 0.9085, 0.1696, 0.6480,\n",
      "         0.7132, 0.8035, 0.7309, 0.1860, 0.2378, 0.6368, 0.0728, 0.5217, 0.4625,\n",
      "         0.6122, 0.6384, 0.5055, 0.8054, 0.4678, 0.5758, 0.4217, 0.6244, 0.6828,\n",
      "         0.5062, 0.4498, 0.4313, 0.8002, 0.8282, 0.9610, 0.5961, 0.1814, 0.3077,\n",
      "         0.8733, 0.0906, 0.5897, 0.8311, 0.6204, 0.7932, 0.3839, 0.9434, 0.9378,\n",
      "         0.2434, 0.7043, 0.5770, 0.4287, 0.9429, 0.3625, 0.7826, 0.2725, 0.4424,\n",
      "         0.2903, 0.6973, 0.8958, 0.3255, 0.6984, 0.7368, 0.7310, 0.4073, 0.5580,\n",
      "         0.8213, 0.5474, 0.7987, 0.6443, 0.0718, 0.2650, 0.8663, 0.3728, 0.4365,\n",
      "         0.3379, 0.0833, 0.2322, 0.1729, 0.2009, 0.4941, 0.0446, 0.5979, 0.3933,\n",
      "         0.8041, 0.6911, 0.7523, 0.9323, 0.9212, 0.6388, 0.2155, 0.3770, 0.4726,\n",
      "         0.5320, 0.6988, 0.9123, 0.9562, 0.3472, 0.4015, 0.5829, 0.6527],\n",
      "        [0.9146, 0.9778, 0.9887, 0.9389, 0.7325, 0.9574, 0.9854, 0.8633, 0.6067,\n",
      "         0.3711, 0.9535, 0.4454, 0.0144, 0.9039, 0.9313, 0.2680, 0.4400, 0.3097,\n",
      "         0.5833, 0.8604, 0.0735, 0.8853, 0.2427, 0.1702, 0.2571, 0.1275, 0.6931,\n",
      "         0.7432, 0.8250, 0.8538, 0.8356, 0.3108, 0.1139, 0.4734, 0.0967, 0.0246,\n",
      "         0.6027, 0.7605, 0.7470, 0.1665, 0.3491, 0.9120, 0.9520, 0.2412, 0.8218,\n",
      "         0.2049, 0.7139, 0.8894, 0.3115, 0.1378, 0.6489, 0.0829, 0.8762, 0.7656,\n",
      "         0.8996, 0.6321, 0.7652, 0.6460, 0.9080, 0.3081, 0.1229, 0.5325, 0.9452,\n",
      "         0.8801, 0.1720, 0.2152, 0.6698, 0.7182, 0.9346, 0.7870, 0.0897, 0.2173,\n",
      "         0.9112, 0.0502, 0.2578, 0.8869, 0.1114, 0.7743, 0.2126, 0.9306, 0.6615,\n",
      "         0.2121, 0.8805, 0.2576, 0.2744, 0.9481, 0.6100, 0.3915, 0.0812, 0.1661,\n",
      "         0.8208, 0.8325, 0.8486, 0.2778, 0.4652, 0.8595, 0.7653, 0.8546, 0.8644,\n",
      "         0.9129, 0.1775, 0.9356, 0.7790, 0.2399, 0.0957, 0.8505, 0.0972, 0.3759,\n",
      "         0.8169, 0.0692, 0.4000, 0.1279, 0.8170, 0.6348, 0.0408, 0.6509, 0.1268,\n",
      "         0.4361, 0.8414, 0.8087, 0.9545, 0.8824, 0.6910, 0.5450, 0.2120, 0.1493,\n",
      "         0.9065, 0.7534, 0.8462, 0.9254, 0.8173, 0.9036, 0.8706, 0.9271],\n",
      "        [0.7982, 0.9785, 0.8181, 0.9293, 0.6740, 0.9433, 0.9799, 0.4761, 0.8947,\n",
      "         0.3114, 0.9455, 0.9102, 0.0443, 0.9675, 0.9743, 0.8032, 0.0483, 0.1733,\n",
      "         0.2643, 0.8325, 0.0889, 0.8737, 0.1667, 0.0618, 0.1128, 0.1606, 0.2454,\n",
      "         0.8889, 0.8851, 0.8645, 0.6721, 0.4359, 0.1603, 0.1914, 0.0734, 0.0358,\n",
      "         0.5514, 0.7717, 0.2533, 0.6937, 0.3176, 0.8253, 0.2403, 0.0897, 0.8070,\n",
      "         0.3388, 0.8738, 0.8642, 0.3354, 0.0666, 0.2010, 0.2526, 0.8454, 0.8007,\n",
      "         0.8660, 0.7838, 0.3385, 0.6735, 0.8653, 0.1790, 0.0991, 0.4637, 0.7670,\n",
      "         0.8613, 0.0860, 0.1693, 0.3066, 0.6422, 0.9505, 0.4581, 0.0729, 0.1479,\n",
      "         0.3987, 0.7183, 0.0992, 0.6056, 0.6692, 0.2645, 0.0485, 0.9084, 0.1553,\n",
      "         0.1234, 0.4255, 0.1691, 0.1293, 0.9439, 0.1713, 0.2535, 0.1227, 0.1365,\n",
      "         0.5365, 0.8529, 0.8094, 0.1800, 0.7239, 0.6896, 0.1208, 0.7701, 0.7892,\n",
      "         0.8563, 0.0761, 0.7270, 0.7787, 0.0482, 0.0633, 0.8761, 0.0567, 0.1875,\n",
      "         0.6951, 0.0522, 0.1282, 0.0924, 0.4612, 0.8073, 0.0306, 0.8272, 0.1025,\n",
      "         0.2141, 0.2207, 0.1463, 0.9517, 0.3063, 0.0916, 0.0653, 0.1181, 0.1328,\n",
      "         0.7531, 0.9050, 0.4112, 0.9511, 0.8055, 0.8545, 0.6902, 0.8589]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[90704, 2048], edge_index=[2, 816336], y=[90704, 2], pos=[90704, 2], censor=[4], duration=[4], batch=[90704], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.2043,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.7514,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.1811,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.8608,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  15\n",
      "Data[0]:  tensor([[6.1370e+01, 5.8863e+00, 0.0000e+00, 6.5615e+00, 0.0000e+00, 1.8614e+00,\n",
      "         0.0000e+00, 3.7958e+00, 9.4206e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.4631e+00, 1.3064e+00, 0.0000e+00, 0.0000e+00, 9.8133e+00],\n",
      "        [7.6709e+01, 4.4488e+00, 1.2553e+01, 8.9379e-01, 0.0000e+00, 6.6987e-01,\n",
      "         0.0000e+00, 4.6772e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.8112e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.5667e+01, 1.1591e+01, 0.0000e+00, 1.3008e+01, 3.6527e-01, 2.4933e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3866e+00, 1.0204e+00, 0.0000e+00,\n",
      "         6.0718e+00, 5.4305e+00, 5.9276e-01, 3.9409e-01, 9.8005e-01],\n",
      "        [7.1204e+01, 3.9254e+00, 8.9324e+00, 4.2050e+00, 0.0000e+00, 1.2499e+00,\n",
      "         0.0000e+00, 2.4637e+00, 7.3142e-01, 0.0000e+00, 5.1225e-01, 0.0000e+00,\n",
      "         5.4925e+00, 1.2837e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9192, 0.9795, 0.9893, 0.7697, 0.7116, 0.6449, 0.9833, 0.5967, 0.6925,\n",
      "         0.4932, 0.9637, 0.5212, 0.1563, 0.9119, 0.9133, 0.4353, 0.6191, 0.3274,\n",
      "         0.8851, 0.2284, 0.0688, 0.9031, 0.6043, 0.4930, 0.4960, 0.2532, 0.3962,\n",
      "         0.7930, 0.9293, 0.8693, 0.8133, 0.7549, 0.1185, 0.6666, 0.0713, 0.0411,\n",
      "         0.5954, 0.5162, 0.4634, 0.9427, 0.9595, 0.3962, 0.7412, 0.2309, 0.3343,\n",
      "         0.6385, 0.9305, 0.3965, 0.3531, 0.2736, 0.6801, 0.6279, 0.8942, 0.4163,\n",
      "         0.6328, 0.4104, 0.4058, 0.8450, 0.4860, 0.7118, 0.0630, 0.6321, 0.7068,\n",
      "         0.7212, 0.1738, 0.3963, 0.6540, 0.8792, 0.9147, 0.6050, 0.4887, 0.5181,\n",
      "         0.9452, 0.0775, 0.6041, 0.8510, 0.4928, 0.8782, 0.2653, 0.9616, 0.9357,\n",
      "         0.1266, 0.4716, 0.4226, 0.1402, 0.9646, 0.3561, 0.5282, 0.1219, 0.1581,\n",
      "         0.4270, 0.4961, 0.8341, 0.6226, 0.7659, 0.6070, 0.7478, 0.5678, 0.3839,\n",
      "         0.5897, 0.4630, 0.9330, 0.6189, 0.1407, 0.4317, 0.4508, 0.4107, 0.4076,\n",
      "         0.4517, 0.5805, 0.4789, 0.1386, 0.4912, 0.6466, 0.0365, 0.8059, 0.2190,\n",
      "         0.9488, 0.6890, 0.8028, 0.9437, 0.4637, 0.4443, 0.2571, 0.1418, 0.1778,\n",
      "         0.3352, 0.6003, 0.9564, 0.9677, 0.2293, 0.2248, 0.6757, 0.6829],\n",
      "        [0.9769, 0.9625, 0.9889, 0.9497, 0.5994, 0.7096, 0.9830, 0.7024, 0.5845,\n",
      "         0.2202, 0.7302, 0.9190, 0.0141, 0.9125, 0.7764, 0.7554, 0.0843, 0.2942,\n",
      "         0.2425, 0.8418, 0.0766, 0.8851, 0.1612, 0.1588, 0.1701, 0.1827, 0.5831,\n",
      "         0.8025, 0.5012, 0.8444, 0.8929, 0.7243, 0.1747, 0.1212, 0.0926, 0.0492,\n",
      "         0.8396, 0.7200, 0.2560, 0.7222, 0.2899, 0.6471, 0.9494, 0.3191, 0.7483,\n",
      "         0.2365, 0.4014, 0.8033, 0.3766, 0.1661, 0.8148, 0.1305, 0.6041, 0.7572,\n",
      "         0.7904, 0.7394, 0.6053, 0.2489, 0.5656, 0.3664, 0.1056, 0.2694, 0.9527,\n",
      "         0.8310, 0.1003, 0.3393, 0.2103, 0.6704, 0.9440, 0.5773, 0.1384, 0.1366,\n",
      "         0.6519, 0.0855, 0.1462, 0.9024, 0.1555, 0.2876, 0.0693, 0.5209, 0.2754,\n",
      "         0.1473, 0.9393, 0.2490, 0.0983, 0.6316, 0.4806, 0.2540, 0.1310, 0.2048,\n",
      "         0.7562, 0.8016, 0.7350, 0.3449, 0.2605, 0.7583, 0.2599, 0.6214, 0.9133,\n",
      "         0.9216, 0.2136, 0.5200, 0.7334, 0.0871, 0.1087, 0.4138, 0.1249, 0.6433,\n",
      "         0.3943, 0.0769, 0.1499, 0.1160, 0.8325, 0.6826, 0.0912, 0.7040, 0.1338,\n",
      "         0.2746, 0.9032, 0.7006, 0.9584, 0.9609, 0.1850, 0.0477, 0.1366, 0.1627,\n",
      "         0.9398, 0.9023, 0.2460, 0.4668, 0.8224, 0.8398, 0.8673, 0.8899],\n",
      "        [0.6913, 0.6637, 0.9789, 0.8739, 0.4274, 0.3576, 0.6889, 0.3562, 0.5396,\n",
      "         0.6810, 0.4409, 0.6942, 0.5927, 0.8635, 0.8365, 0.3861, 0.5170, 0.6081,\n",
      "         0.8459, 0.5832, 0.1386, 0.6567, 0.6291, 0.7668, 0.4956, 0.4465, 0.4775,\n",
      "         0.5917, 0.9011, 0.8935, 0.4891, 0.5860, 0.5564, 0.5997, 0.5471, 0.0302,\n",
      "         0.5513, 0.4825, 0.4181, 0.8238, 0.7333, 0.4244, 0.6260, 0.3422, 0.5383,\n",
      "         0.6839, 0.8944, 0.7274, 0.7412, 0.2950, 0.7424, 0.0643, 0.5271, 0.5017,\n",
      "         0.6303, 0.4357, 0.6053, 0.8719, 0.5480, 0.6049, 0.5362, 0.6058, 0.7310,\n",
      "         0.5101, 0.6216, 0.4306, 0.8241, 0.6561, 0.9535, 0.3417, 0.4602, 0.4882,\n",
      "         0.8803, 0.2104, 0.5533, 0.8364, 0.5116, 0.8495, 0.3165, 0.9332, 0.9562,\n",
      "         0.5206, 0.6663, 0.4909, 0.5655, 0.9599, 0.3508, 0.5771, 0.2011, 0.3558,\n",
      "         0.3210, 0.7180, 0.8289, 0.5655, 0.7992, 0.6422, 0.7914, 0.4926, 0.3929,\n",
      "         0.7530, 0.5930, 0.8580, 0.6354, 0.1181, 0.5437, 0.5820, 0.5887, 0.4795,\n",
      "         0.4793, 0.4267, 0.5374, 0.2615, 0.3459, 0.5765, 0.1937, 0.7248, 0.4420,\n",
      "         0.8959, 0.7799, 0.7628, 0.9233, 0.8185, 0.6375, 0.5581, 0.3255, 0.6343,\n",
      "         0.4442, 0.5970, 0.9508, 0.9443, 0.4064, 0.4115, 0.5963, 0.6195],\n",
      "        [0.8168, 0.9789, 0.9883, 0.9482, 0.9256, 0.9561, 0.9708, 0.6338, 0.7065,\n",
      "         0.5066, 0.8506, 0.3703, 0.0132, 0.9412, 0.9147, 0.5773, 0.1221, 0.3029,\n",
      "         0.7425, 0.8031, 0.0855, 0.7110, 0.3278, 0.1831, 0.3507, 0.1958, 0.4194,\n",
      "         0.7588, 0.8750, 0.8530, 0.8351, 0.8316, 0.1724, 0.2126, 0.0922, 0.0463,\n",
      "         0.4944, 0.7328, 0.6530, 0.9389, 0.9249, 0.7402, 0.9465, 0.1124, 0.8817,\n",
      "         0.4994, 0.7998, 0.8836, 0.1273, 0.1851, 0.8275, 0.7109, 0.8325, 0.6757,\n",
      "         0.8494, 0.4074, 0.3343, 0.8856, 0.7350, 0.7774, 0.1091, 0.6107, 0.8266,\n",
      "         0.8510, 0.0774, 0.5462, 0.7341, 0.7154, 0.9679, 0.7772, 0.3538, 0.2788,\n",
      "         0.9260, 0.0862, 0.4675, 0.8695, 0.5355, 0.7768, 0.0669, 0.9528, 0.8591,\n",
      "         0.1268, 0.9507, 0.2695, 0.1694, 0.9530, 0.7024, 0.3153, 0.1141, 0.2167,\n",
      "         0.4407, 0.7634, 0.8740, 0.2524, 0.4507, 0.8783, 0.8552, 0.7192, 0.6176,\n",
      "         0.6474, 0.2626, 0.9322, 0.7549, 0.0837, 0.1312, 0.8568, 0.1980, 0.5315,\n",
      "         0.5053, 0.0820, 0.1708, 0.1404, 0.6570, 0.5842, 0.0636, 0.8471, 0.1543,\n",
      "         0.7512, 0.5742, 0.8130, 0.9490, 0.7789, 0.7916, 0.0959, 0.1363, 0.1653,\n",
      "         0.9055, 0.9049, 0.8664, 0.9647, 0.6770, 0.6336, 0.7758, 0.9375]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[46806, 2048], edge_index=[2, 421254], y=[46806, 2], pos=[46806, 2], censor=[4], duration=[4], batch=[46806], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -1.0688,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.0026,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  1.0548,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -2.0925,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  16\n",
      "Data[0]:  tensor([[7.1181e+01, 3.6415e+00, 6.3628e+00, 6.8771e+00, 0.0000e+00, 7.6573e-01,\n",
      "         0.0000e+00, 4.6498e-01, 1.3508e+00, 0.0000e+00, 0.0000e+00, 5.0906e-01,\n",
      "         6.2403e+00, 1.6860e+00, 4.2027e-01, 3.8542e-02, 4.6139e-01],\n",
      "        [5.5082e+01, 6.2807e+00, 1.2346e+01, 6.2954e+00, 2.3796e-01, 2.9585e+00,\n",
      "         0.0000e+00, 1.6279e+00, 3.5870e+00, 0.0000e+00, 1.2272e+00, 0.0000e+00,\n",
      "         4.0660e+00, 2.3347e+00, 1.4492e+00, 8.8983e-01, 1.6179e+00],\n",
      "        [5.8273e+01, 4.0941e+00, 0.0000e+00, 3.1365e+00, 0.0000e+00, 2.0229e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4863e+00, 1.8640e+01, 0.0000e+00,\n",
      "         9.5202e+00, 1.8265e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.4335e+01, 4.7803e+00, 5.4207e+00, 4.1595e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4619e-01, 7.6026e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.5073e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.8720, 0.9812, 0.9874, 0.9052, 0.2420, 0.8485, 0.9786, 0.3785, 0.7663,\n",
      "         0.5104, 0.8841, 0.6703, 0.0182, 0.9438, 0.9112, 0.3421, 0.3730, 0.3179,\n",
      "         0.8784, 0.7480, 0.0706, 0.4314, 0.3489, 0.2299, 0.4193, 0.2201, 0.3966,\n",
      "         0.7567, 0.9247, 0.8713, 0.7245, 0.7953, 0.2395, 0.3139, 0.1303, 0.0284,\n",
      "         0.2456, 0.2052, 0.3866, 0.9175, 0.8792, 0.6938, 0.7740, 0.1139, 0.6683,\n",
      "         0.3941, 0.8424, 0.7449, 0.3872, 0.1710, 0.7381, 0.2323, 0.8318, 0.1882,\n",
      "         0.8387, 0.5309, 0.3493, 0.8710, 0.8802, 0.5298, 0.2257, 0.5266, 0.8894,\n",
      "         0.8078, 0.1140, 0.2860, 0.4712, 0.5651, 0.9486, 0.4751, 0.1584, 0.2296,\n",
      "         0.8986, 0.0482, 0.3284, 0.7711, 0.7214, 0.8053, 0.1770, 0.9473, 0.9115,\n",
      "         0.2113, 0.9042, 0.4081, 0.1922, 0.9499, 0.4675, 0.3863, 0.1650, 0.2837,\n",
      "         0.2634, 0.8125, 0.8409, 0.2946, 0.3267, 0.7624, 0.7420, 0.7989, 0.8269,\n",
      "         0.6237, 0.3619, 0.8461, 0.6441, 0.0985, 0.2049, 0.8524, 0.1066, 0.3596,\n",
      "         0.7799, 0.0771, 0.1740, 0.1250, 0.4275, 0.2446, 0.0755, 0.5730, 0.2386,\n",
      "         0.8501, 0.8698, 0.8085, 0.9034, 0.7581, 0.7794, 0.1008, 0.1633, 0.2124,\n",
      "         0.7560, 0.8561, 0.9149, 0.9466, 0.1923, 0.2179, 0.7974, 0.8486],\n",
      "        [0.9043, 0.9809, 0.9879, 0.9411, 0.8856, 0.9348, 0.9774, 0.7719, 0.8051,\n",
      "         0.7014, 0.9506, 0.9785, 0.0105, 0.9612, 0.8190, 0.3801, 0.0376, 0.3840,\n",
      "         0.8651, 0.7668, 0.0647, 0.9137, 0.2163, 0.2284, 0.1579, 0.2162, 0.8532,\n",
      "         0.8739, 0.9264, 0.9140, 0.6825, 0.8294, 0.5330, 0.4746, 0.0955, 0.0236,\n",
      "         0.7412, 0.6930, 0.7111, 0.8864, 0.8263, 0.9016, 0.9298, 0.2703, 0.8349,\n",
      "         0.4114, 0.8567, 0.9001, 0.3801, 0.2018, 0.8746, 0.2675, 0.9321, 0.7286,\n",
      "         0.9343, 0.7399, 0.8628, 0.7279, 0.9038, 0.5319, 0.1541, 0.5660, 0.9554,\n",
      "         0.8434, 0.0986, 0.5211, 0.5793, 0.6789, 0.9391, 0.6431, 0.4223, 0.2378,\n",
      "         0.9178, 0.1921, 0.4061, 0.9004, 0.7192, 0.5922, 0.1523, 0.8845, 0.9444,\n",
      "         0.3671, 0.8796, 0.4899, 0.1654, 0.9520, 0.6467, 0.3905, 0.2844, 0.2096,\n",
      "         0.8735, 0.8753, 0.8816, 0.2740, 0.4872, 0.8743, 0.8390, 0.8346, 0.8680,\n",
      "         0.9061, 0.2768, 0.9252, 0.7106, 0.0835, 0.2118, 0.7206, 0.1556, 0.8659,\n",
      "         0.8708, 0.0658, 0.1346, 0.3855, 0.5452, 0.7462, 0.0495, 0.8482, 0.3799,\n",
      "         0.7019, 0.9284, 0.8306, 0.9430, 0.9261, 0.7480, 0.4879, 0.0830, 0.2197,\n",
      "         0.8590, 0.8815, 0.6299, 0.9364, 0.7854, 0.9083, 0.8902, 0.9187],\n",
      "        [0.9432, 0.9815, 0.9874, 0.9578, 0.9471, 0.9671, 0.9801, 0.7970, 0.3753,\n",
      "         0.4874, 0.4823, 0.9859, 0.0087, 0.9413, 0.9131, 0.4560, 0.4288, 0.3712,\n",
      "         0.7368, 0.3809, 0.0515, 0.5737, 0.3717, 0.2338, 0.1967, 0.2141, 0.6706,\n",
      "         0.7850, 0.9107, 0.8898, 0.8067, 0.7021, 0.1386, 0.7860, 0.0886, 0.0362,\n",
      "         0.7793, 0.4620, 0.3669, 0.8679, 0.8821, 0.5148, 0.9521, 0.1279, 0.5588,\n",
      "         0.5743, 0.7865, 0.6193, 0.1002, 0.2129, 0.7912, 0.4387, 0.5832, 0.4618,\n",
      "         0.9153, 0.5949, 0.5684, 0.8100, 0.6885, 0.4354, 0.1714, 0.6275, 0.9460,\n",
      "         0.5467, 0.2761, 0.2234, 0.7946, 0.8779, 0.9641, 0.5689, 0.1387, 0.3075,\n",
      "         0.9105, 0.0916, 0.4430, 0.8947, 0.0969, 0.8390, 0.0647, 0.9499, 0.9644,\n",
      "         0.2048, 0.9089, 0.5403, 0.3346, 0.9538, 0.5289, 0.5492, 0.2111, 0.2726,\n",
      "         0.7458, 0.7425, 0.8934, 0.2932, 0.7053, 0.7589, 0.5529, 0.7795, 0.5224,\n",
      "         0.8735, 0.3493, 0.9359, 0.5852, 0.0842, 0.1805, 0.8655, 0.3620, 0.6172,\n",
      "         0.5867, 0.0869, 0.1761, 0.2474, 0.5167, 0.5195, 0.0704, 0.8054, 0.3466,\n",
      "         0.4515, 0.8242, 0.5882, 0.9629, 0.7755, 0.3363, 0.1519, 0.1688, 0.4274,\n",
      "         0.7398, 0.9008, 0.8030, 0.9600, 0.5139, 0.5782, 0.8929, 0.8417],\n",
      "        [0.2790, 0.9792, 0.8866, 0.1416, 0.3733, 0.1576, 0.4394, 0.1034, 0.6849,\n",
      "         0.9157, 0.9701, 0.8410, 0.0391, 0.8226, 0.5957, 0.3826, 0.7889, 0.3751,\n",
      "         0.8455, 0.3961, 0.0778, 0.3158, 0.6035, 0.3298, 0.7299, 0.1472, 0.6018,\n",
      "         0.7628, 0.9278, 0.8474, 0.2265, 0.2128, 0.7135, 0.8808, 0.2474, 0.0528,\n",
      "         0.3183, 0.1171, 0.7028, 0.8990, 0.8926, 0.7938, 0.9309, 0.1350, 0.1412,\n",
      "         0.8142, 0.9486, 0.2375, 0.7122, 0.3163, 0.7734, 0.5441, 0.8327, 0.2243,\n",
      "         0.9027, 0.3059, 0.6334, 0.8450, 0.8916, 0.7733, 0.5904, 0.4237, 0.8783,\n",
      "         0.7774, 0.1584, 0.6061, 0.8561, 0.3007, 0.9376, 0.2774, 0.1904, 0.2487,\n",
      "         0.7923, 0.0617, 0.8961, 0.7988, 0.4427, 0.9003, 0.6869, 0.8703, 0.8754,\n",
      "         0.7457, 0.8415, 0.4091, 0.3942, 0.9519, 0.6071, 0.7677, 0.3718, 0.4128,\n",
      "         0.0893, 0.4488, 0.8113, 0.2878, 0.5371, 0.5734, 0.8158, 0.8587, 0.1470,\n",
      "         0.6093, 0.2952, 0.7041, 0.3867, 0.0755, 0.6964, 0.3318, 0.8859, 0.7687,\n",
      "         0.9037, 0.1206, 0.1263, 0.2101, 0.1683, 0.4405, 0.1684, 0.7161, 0.7379,\n",
      "         0.4177, 0.8404, 0.8497, 0.9586, 0.9134, 0.8568, 0.1513, 0.5758, 0.3581,\n",
      "         0.2408, 0.7531, 0.9720, 0.9658, 0.2256, 0.1845, 0.2652, 0.1937]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[80246, 2048], edge_index=[2, 722214], y=[80246, 2], pos=[80246, 2], censor=[4], duration=[4], batch=[80246], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -0.4684,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.6845,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0812,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.1289,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  17\n",
      "Data[0]:  tensor([[8.4659e+01, 6.3029e+00, 5.3749e+00, 7.5454e-01, 0.0000e+00, 1.1273e-01,\n",
      "         1.2751e-01, 0.0000e+00, 3.5022e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.1147e-01, 1.1698e+00, 0.0000e+00, 4.3706e-01],\n",
      "        [5.2332e+01, 1.0473e+01, 1.1385e+00, 1.2196e+01, 3.1489e+00, 4.6510e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0608e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.4285e+00, 0.0000e+00, 9.7714e-03, 1.4628e-02],\n",
      "        [4.5383e+01, 7.7689e+00, 3.3901e-02, 5.7906e+00, 4.1091e+00, 9.2364e+00,\n",
      "         0.0000e+00, 2.6189e-01, 2.7322e-01, 2.1769e+00, 1.4399e+01, 0.0000e+00,\n",
      "         7.9803e+00, 2.4976e+00, 1.3630e-02, 3.9977e-02, 3.5304e-02],\n",
      "        [4.5078e+01, 9.0521e+00, 2.7170e+00, 3.9621e+00, 0.0000e+00, 5.1889e+00,\n",
      "         0.0000e+00, 1.8673e+00, 2.7545e+00, 0.0000e+00, 1.3733e+01, 0.0000e+00,\n",
      "         1.0374e+01, 5.2567e-01, 0.0000e+00, 1.9490e+00, 2.7980e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9498, 0.9818, 0.9891, 0.9536, 0.8276, 0.9675, 0.9782, 0.8718, 0.7560,\n",
      "         0.5884, 0.8873, 0.9780, 0.0095, 0.9075, 0.8433, 0.7433, 0.0554, 0.6417,\n",
      "         0.6955, 0.8722, 0.0666, 0.7157, 0.1601, 0.2248, 0.2401, 0.1769, 0.9397,\n",
      "         0.8817, 0.6221, 0.9137, 0.8333, 0.6871, 0.6414, 0.2953, 0.0594, 0.0320,\n",
      "         0.7601, 0.7596, 0.3822, 0.3034, 0.4620, 0.8906, 0.9538, 0.0652, 0.8594,\n",
      "         0.2651, 0.7546, 0.9018, 0.5461, 0.1433, 0.8473, 0.0479, 0.8925, 0.7882,\n",
      "         0.9377, 0.7949, 0.9154, 0.6794, 0.8868, 0.3875, 0.0750, 0.3386, 0.9607,\n",
      "         0.8554, 0.0696, 0.5118, 0.5984, 0.8272, 0.9265, 0.7683, 0.1016, 0.2794,\n",
      "         0.8827, 0.0855, 0.1373, 0.8942, 0.7694, 0.3703, 0.1210, 0.9359, 0.2360,\n",
      "         0.1358, 0.9376, 0.2424, 0.0818, 0.9375, 0.6201, 0.2171, 0.2394, 0.1633,\n",
      "         0.9100, 0.8748, 0.8991, 0.2083, 0.3510, 0.8847, 0.7337, 0.8733, 0.9120,\n",
      "         0.9151, 0.2037, 0.9397, 0.8127, 0.1471, 0.2274, 0.7836, 0.1004, 0.6365,\n",
      "         0.9087, 0.0601, 0.1057, 0.1976, 0.8483, 0.7614, 0.0550, 0.8727, 0.6273,\n",
      "         0.4572, 0.9101, 0.8882, 0.9640, 0.9580, 0.6797, 0.1689, 0.1377, 0.1504,\n",
      "         0.9586, 0.8714, 0.5999, 0.9298, 0.8048, 0.9130, 0.9443, 0.9178],\n",
      "        [0.6958, 0.5595, 0.5314, 0.4043, 0.7573, 0.5920, 0.7583, 0.6634, 0.5127,\n",
      "         0.6105, 0.4641, 0.5372, 0.0209, 0.8817, 0.7668, 0.4557, 0.5623, 0.3483,\n",
      "         0.6518, 0.4107, 0.0578, 0.5546, 0.2884, 0.2681, 0.2785, 0.2636, 0.5277,\n",
      "         0.5128, 0.8822, 0.8497, 0.5276, 0.4614, 0.5856, 0.3119, 0.1917, 0.0376,\n",
      "         0.6074, 0.6482, 0.2188, 0.8401, 0.7860, 0.3848, 0.9221, 0.1462, 0.6765,\n",
      "         0.6163, 0.8001, 0.7415, 0.2904, 0.2102, 0.7920, 0.2623, 0.5442, 0.6588,\n",
      "         0.4760, 0.5005, 0.5567, 0.7260, 0.4646, 0.3928, 0.2304, 0.6185, 0.7359,\n",
      "         0.6088, 0.2282, 0.4530, 0.7245, 0.6559, 0.9419, 0.5655, 0.6257, 0.2971,\n",
      "         0.9172, 0.3694, 0.5202, 0.8086, 0.5149, 0.6648, 0.1298, 0.9468, 0.8363,\n",
      "         0.2739, 0.7589, 0.3037, 0.2110, 0.9425, 0.4033, 0.3955, 0.1666, 0.2866,\n",
      "         0.5802, 0.5545, 0.8404, 0.3895, 0.4665, 0.5590, 0.5830, 0.4431, 0.6216,\n",
      "         0.6692, 0.3907, 0.6765, 0.6559, 0.1112, 0.1842, 0.5784, 0.1652, 0.3928,\n",
      "         0.4216, 0.0861, 0.3721, 0.4644, 0.3915, 0.5596, 0.0941, 0.4515, 0.2356,\n",
      "         0.6334, 0.6377, 0.8008, 0.6854, 0.7233, 0.4664, 0.1366, 0.2159, 0.2762,\n",
      "         0.4385, 0.5830, 0.9275, 0.9355, 0.6359, 0.7726, 0.6826, 0.7717],\n",
      "        [0.7985, 0.9731, 0.9779, 0.8854, 0.7405, 0.8771, 0.9602, 0.6199, 0.5038,\n",
      "         0.4824, 0.8886, 0.9173, 0.4174, 0.9167, 0.8054, 0.4583, 0.4085, 0.5325,\n",
      "         0.7911, 0.6591, 0.1007, 0.6801, 0.4834, 0.3632, 0.4047, 0.2909, 0.8139,\n",
      "         0.6313, 0.9038, 0.8508, 0.6445, 0.6550, 0.4121, 0.8027, 0.2236, 0.0252,\n",
      "         0.7480, 0.5512, 0.5104, 0.7971, 0.8179, 0.7390, 0.9090, 0.2440, 0.7014,\n",
      "         0.6947, 0.6258, 0.7510, 0.4477, 0.3829, 0.8033, 0.1193, 0.8399, 0.5655,\n",
      "         0.8935, 0.6500, 0.6559, 0.7521, 0.8425, 0.5343, 0.4927, 0.4909, 0.7936,\n",
      "         0.8134, 0.4251, 0.3013, 0.7828, 0.7981, 0.9423, 0.5693, 0.1835, 0.4551,\n",
      "         0.8897, 0.2107, 0.4377, 0.6733, 0.4650, 0.7757, 0.2182, 0.8669, 0.9079,\n",
      "         0.4237, 0.8730, 0.4869, 0.3618, 0.9421, 0.4993, 0.7334, 0.1325, 0.3887,\n",
      "         0.4970, 0.8028, 0.8399, 0.3525, 0.6325, 0.6387, 0.6613, 0.8221, 0.6765,\n",
      "         0.8000, 0.5383, 0.8223, 0.6662, 0.1849, 0.3629, 0.8298, 0.4642, 0.4915,\n",
      "         0.7651, 0.0999, 0.4527, 0.3002, 0.5353, 0.5442, 0.0714, 0.5993, 0.2034,\n",
      "         0.7312, 0.7781, 0.6127, 0.9394, 0.9093, 0.5552, 0.3477, 0.2198, 0.4017,\n",
      "         0.7361, 0.7828, 0.7845, 0.9370, 0.7214, 0.7817, 0.7702, 0.8335],\n",
      "        [0.7221, 0.8537, 0.9330, 0.8937, 0.7184, 0.8615, 0.9580, 0.6134, 0.6059,\n",
      "         0.4695, 0.8299, 0.8189, 0.0270, 0.7969, 0.7754, 0.3823, 0.2924, 0.4111,\n",
      "         0.6834, 0.5916, 0.0739, 0.8708, 0.2899, 0.3394, 0.2994, 0.2281, 0.5768,\n",
      "         0.7518, 0.9258, 0.8891, 0.6658, 0.5792, 0.1703, 0.6511, 0.1150, 0.0326,\n",
      "         0.6519, 0.5312, 0.4482, 0.7405, 0.7654, 0.5166, 0.8050, 0.2054, 0.4694,\n",
      "         0.4612, 0.8033, 0.6387, 0.2475, 0.2682, 0.7735, 0.1555, 0.8191, 0.4973,\n",
      "         0.7356, 0.4964, 0.5962, 0.6558, 0.5921, 0.4656, 0.1605, 0.4502, 0.9032,\n",
      "         0.6593, 0.1231, 0.1853, 0.4613, 0.7771, 0.9269, 0.5740, 0.1708, 0.2667,\n",
      "         0.8582, 0.1114, 0.4157, 0.8016, 0.1024, 0.6714, 0.0693, 0.9044, 0.9042,\n",
      "         0.2259, 0.8231, 0.5160, 0.2046, 0.9389, 0.4536, 0.5790, 0.0863, 0.2557,\n",
      "         0.5810, 0.6231, 0.8240, 0.2495, 0.5165, 0.7653, 0.7480, 0.5361, 0.5166,\n",
      "         0.8696, 0.5068, 0.6660, 0.6575, 0.0687, 0.2547, 0.8439, 0.2515, 0.4755,\n",
      "         0.5400, 0.0917, 0.2954, 0.1108, 0.3624, 0.5221, 0.0742, 0.7710, 0.1851,\n",
      "         0.6674, 0.8010, 0.6211, 0.9163, 0.8504, 0.3004, 0.0618, 0.1432, 0.2163,\n",
      "         0.6924, 0.7389, 0.8396, 0.9278, 0.4439, 0.4760, 0.5716, 0.8617]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[72667, 2048], edge_index=[2, 654003], y=[72667, 2], pos=[72667, 2], censor=[4], duration=[4], batch=[72667], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  0.6060,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.0693,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.2865,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.9244,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  18\n",
      "Data[0]:  tensor([[6.1823e+01, 5.3264e+00, 4.2147e+00, 7.5518e+00, 0.0000e+00, 2.0586e+00,\n",
      "         0.0000e+00, 3.7247e+00, 1.0865e+00, 0.0000e+00, 1.5524e+00, 0.0000e+00,\n",
      "         5.0045e+00, 1.8527e+00, 1.1269e+00, 3.7700e-01, 4.3012e+00],\n",
      "        [5.0829e+01, 1.4269e+01, 3.1171e+00, 1.2992e+01, 5.3152e-01, 3.4088e+00,\n",
      "         0.0000e+00, 6.1782e-02, 3.2050e-01, 4.2690e-01, 3.0846e+00, 0.0000e+00,\n",
      "         7.0296e+00, 2.8185e+00, 4.5350e-01, 3.7197e-01, 2.8490e-01],\n",
      "        [5.9496e+01, 3.0612e+00, 0.0000e+00, 4.5022e+00, 0.0000e+00, 8.4049e+00,\n",
      "         0.0000e+00, 1.8384e+00, 1.5088e+00, 2.2044e-01, 1.4009e+01, 0.0000e+00,\n",
      "         5.0857e+00, 1.8726e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0568e+01, 0.0000e+00, 9.4315e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6701, 0.9690, 0.9014, 0.8489, 0.8706, 0.8117, 0.9747, 0.4385, 0.6654,\n",
      "         0.4461, 0.8562, 0.9346, 0.2253, 0.9321, 0.8938, 0.3564, 0.0943, 0.4178,\n",
      "         0.4361, 0.7833, 0.0765, 0.8599, 0.3603, 0.2810, 0.5614, 0.2272, 0.3726,\n",
      "         0.7952, 0.9466, 0.8709, 0.4928, 0.5537, 0.1787, 0.3413, 0.0850, 0.0485,\n",
      "         0.7314, 0.5892, 0.5302, 0.9188, 0.6467, 0.7696, 0.6462, 0.4430, 0.7643,\n",
      "         0.6437, 0.7821, 0.7840, 0.2258, 0.2237, 0.7280, 0.0771, 0.8318, 0.6279,\n",
      "         0.8974, 0.5002, 0.4293, 0.6568, 0.8739, 0.7014, 0.1761, 0.5677, 0.7064,\n",
      "         0.7960, 0.1638, 0.2401, 0.6777, 0.6796, 0.7431, 0.5300, 0.1747, 0.2447,\n",
      "         0.9249, 0.1505, 0.1423, 0.8706, 0.4742, 0.8432, 0.1298, 0.9763, 0.8558,\n",
      "         0.1464, 0.8570, 0.3949, 0.1843, 0.9547, 0.3269, 0.4982, 0.1142, 0.2925,\n",
      "         0.2380, 0.7274, 0.8397, 0.4060, 0.5958, 0.7101, 0.8945, 0.5763, 0.3482,\n",
      "         0.8394, 0.4793, 0.6804, 0.5262, 0.2392, 0.2186, 0.7441, 0.1690, 0.2898,\n",
      "         0.4205, 0.0712, 0.5871, 0.1159, 0.6458, 0.4782, 0.0796, 0.5183, 0.2406,\n",
      "         0.8698, 0.5665, 0.7963, 0.9163, 0.4895, 0.5807, 0.0671, 0.1544, 0.2607,\n",
      "         0.6743, 0.7968, 0.8474, 0.9621, 0.6712, 0.6316, 0.6146, 0.8052],\n",
      "        [0.7877, 0.9715, 0.9489, 0.8560, 0.7655, 0.7741, 0.9789, 0.7601, 0.6026,\n",
      "         0.7135, 0.8150, 0.8015, 0.1063, 0.9623, 0.8510, 0.5921, 0.5229, 0.4956,\n",
      "         0.8072, 0.2097, 0.0840, 0.8653, 0.5471, 0.4222, 0.4113, 0.2958, 0.7453,\n",
      "         0.6799, 0.9130, 0.8724, 0.6243, 0.6275, 0.3804, 0.7705, 0.3228, 0.0475,\n",
      "         0.4233, 0.4857, 0.2947, 0.9178, 0.7900, 0.7289, 0.6504, 0.1898, 0.4853,\n",
      "         0.7435, 0.8964, 0.5554, 0.7297, 0.2605, 0.6409, 0.1099, 0.7304, 0.4198,\n",
      "         0.9002, 0.4072, 0.6452, 0.8141, 0.8045, 0.5716, 0.5457, 0.6084, 0.9014,\n",
      "         0.6858, 0.7260, 0.5334, 0.8486, 0.7344, 0.9221, 0.4493, 0.2530, 0.7050,\n",
      "         0.9326, 0.1304, 0.4959, 0.8138, 0.3387, 0.9009, 0.3997, 0.9490, 0.9276,\n",
      "         0.3813, 0.5810, 0.3794, 0.2674, 0.9517, 0.3989, 0.5225, 0.5527, 0.3766,\n",
      "         0.5903, 0.7695, 0.8596, 0.4924, 0.8454, 0.5340, 0.6011, 0.7875, 0.7404,\n",
      "         0.7036, 0.5507, 0.8094, 0.5839, 0.1543, 0.2974, 0.7447, 0.2031, 0.3380,\n",
      "         0.7367, 0.0772, 0.2990, 0.3223, 0.5323, 0.4233, 0.0981, 0.6866, 0.5978,\n",
      "         0.8821, 0.9016, 0.7174, 0.9522, 0.9346, 0.4506, 0.2862, 0.2706, 0.3601,\n",
      "         0.7646, 0.8643, 0.8934, 0.9502, 0.5905, 0.6627, 0.7594, 0.6037],\n",
      "        [0.8378, 0.9810, 0.9511, 0.9376, 0.7496, 0.9448, 0.9321, 0.6033, 0.7415,\n",
      "         0.4749, 0.9434, 0.9157, 0.0300, 0.9314, 0.9392, 0.4930, 0.2057, 0.3952,\n",
      "         0.6498, 0.6838, 0.0857, 0.7998, 0.4263, 0.2170, 0.2130, 0.2226, 0.7348,\n",
      "         0.7753, 0.7954, 0.9071, 0.7110, 0.5946, 0.1811, 0.4457, 0.0874, 0.0405,\n",
      "         0.5625, 0.6365, 0.3944, 0.6910, 0.5087, 0.7639, 0.9264, 0.2021, 0.6908,\n",
      "         0.4624, 0.4732, 0.7928, 0.1998, 0.1577, 0.8191, 0.1522, 0.8236, 0.6505,\n",
      "         0.8878, 0.6152, 0.6244, 0.6813, 0.8508, 0.4191, 0.2342, 0.3354, 0.8807,\n",
      "         0.7850, 0.1905, 0.3199, 0.5251, 0.8526, 0.9487, 0.6736, 0.2327, 0.2666,\n",
      "         0.8672, 0.1242, 0.4022, 0.7542, 0.2272, 0.6412, 0.0698, 0.8983, 0.6216,\n",
      "         0.1977, 0.8868, 0.4056, 0.2817, 0.8737, 0.5296, 0.5641, 0.1132, 0.2157,\n",
      "         0.5206, 0.8034, 0.8772, 0.2701, 0.4747, 0.7657, 0.7379, 0.7548, 0.6437,\n",
      "         0.8056, 0.3364, 0.8911, 0.6510, 0.0539, 0.2266, 0.8745, 0.0871, 0.6240,\n",
      "         0.7424, 0.0965, 0.1644, 0.2227, 0.5018, 0.5655, 0.0506, 0.7458, 0.1892,\n",
      "         0.4349, 0.7561, 0.7540, 0.9322, 0.9187, 0.6224, 0.1363, 0.1517, 0.2777,\n",
      "         0.7504, 0.8822, 0.6001, 0.9181, 0.6645, 0.7731, 0.8417, 0.8909],\n",
      "        [0.9798, 0.9757, 0.9898, 0.9496, 0.9227, 0.9591, 0.9811, 0.9432, 0.5724,\n",
      "         0.0408, 0.9822, 0.2091, 0.0118, 0.9628, 0.8339, 0.7396, 0.0651, 0.1154,\n",
      "         0.1344, 0.8249, 0.0839, 0.9248, 0.1041, 0.0729, 0.0631, 0.1427, 0.7299,\n",
      "         0.7779, 0.3212, 0.9400, 0.9257, 0.8167, 0.1310, 0.0664, 0.0634, 0.0380,\n",
      "         0.8416, 0.6992, 0.1057, 0.4782, 0.2325, 0.8484, 0.9425, 0.0918, 0.7985,\n",
      "         0.0672, 0.1135, 0.9227, 0.1272, 0.0941, 0.8491, 0.0534, 0.9601, 0.8274,\n",
      "         0.9202, 0.6856, 0.8620, 0.2786, 0.9286, 0.1098, 0.0449, 0.0972, 0.9283,\n",
      "         0.9018, 0.0625, 0.1162, 0.1087, 0.8689, 0.9447, 0.5335, 0.1038, 0.1496,\n",
      "         0.6754, 0.0464, 0.0824, 0.9113, 0.1015, 0.2509, 0.0547, 0.5601, 0.2247,\n",
      "         0.0680, 0.8754, 0.2368, 0.1071, 0.3812, 0.6289, 0.1143, 0.0484, 0.0809,\n",
      "         0.7860, 0.8788, 0.8719, 0.2077, 0.0940, 0.7500, 0.1659, 0.7180, 0.9433,\n",
      "         0.9198, 0.0634, 0.7883, 0.6778, 0.0819, 0.1579, 0.7933, 0.0563, 0.6148,\n",
      "         0.8737, 0.0874, 0.0632, 0.0985, 0.7876, 0.4319, 0.0393, 0.8579, 0.0488,\n",
      "         0.1125, 0.9244, 0.8291, 0.9368, 0.9454, 0.1009, 0.0448, 0.0724, 0.0817,\n",
      "         0.8841, 0.8955, 0.1595, 0.6320, 0.9063, 0.9182, 0.9019, 0.9216]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[89972, 2048], edge_index=[2, 809748], y=[89972, 2], pos=[89972, 2], censor=[4], duration=[4], batch=[89972], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  1.5601,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  1.0721,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.4083,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.3830,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  19\n",
      "Data[0]:  tensor([[4.7577e+01, 5.8448e+00, 0.0000e+00, 7.1704e+00, 0.0000e+00, 2.5927e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7649e-01, 6.0905e-01, 8.3272e+00, 0.0000e+00,\n",
      "         9.9083e+00, 2.0450e+00, 5.7723e-01, 1.6342e+00, 1.3437e+01],\n",
      "        [7.8281e+01, 2.0429e+00, 9.8297e+00, 7.4368e-01, 0.0000e+00, 1.4025e+00,\n",
      "         0.0000e+00, 1.4419e+00, 9.4702e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1178e+00, 0.0000e+00, 3.1938e+00],\n",
      "        [8.1338e+01, 2.9522e+00, 4.4264e+00, 3.3031e+00, 0.0000e+00, 1.2143e+00,\n",
      "         0.0000e+00, 2.7159e-01, 9.4009e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3476e+00, 2.2866e+00, 5.9168e-01, 2.9477e-01, 3.3434e-02],\n",
      "        [4.4799e+01, 1.6995e+01, 0.0000e+00, 1.7402e+01, 0.0000e+00, 6.3415e+00,\n",
      "         0.0000e+00, 3.6896e-01, 1.6499e+00, 0.0000e+00, 2.9992e+00, 0.0000e+00,\n",
      "         6.5338e+00, 2.5889e+00, 1.5362e-01, 1.1121e-01, 5.6995e-02]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.8322, 0.9444, 0.9283, 0.8965, 0.7326, 0.8032, 0.9500, 0.5056, 0.6008,\n",
      "         0.4892, 0.6568, 0.7260, 0.0338, 0.9234, 0.8570, 0.2380, 0.0995, 0.4536,\n",
      "         0.8821, 0.4678, 0.0776, 0.7622, 0.3918, 0.4876, 0.1564, 0.2722, 0.7122,\n",
      "         0.7657, 0.9569, 0.8876, 0.6932, 0.5982, 0.2186, 0.6428, 0.1761, 0.0282,\n",
      "         0.5947, 0.3948, 0.4444, 0.9064, 0.8537, 0.5541, 0.9121, 0.1830, 0.4604,\n",
      "         0.5800, 0.9030, 0.4960, 0.3935, 0.3226, 0.8303, 0.1051, 0.5741, 0.3044,\n",
      "         0.7498, 0.5112, 0.5924, 0.8565, 0.8030, 0.4096, 0.1367, 0.7150, 0.9080,\n",
      "         0.6399, 0.3351, 0.1655, 0.7349, 0.7979, 0.9336, 0.5129, 0.2871, 0.2949,\n",
      "         0.9341, 0.0902, 0.4109, 0.8226, 0.1696, 0.7852, 0.0684, 0.9323, 0.9329,\n",
      "         0.2543, 0.8748, 0.5558, 0.3858, 0.9384, 0.5288, 0.5317, 0.1764, 0.2349,\n",
      "         0.2709, 0.6236, 0.7996, 0.3067, 0.6043, 0.7717, 0.7567, 0.5966, 0.5326,\n",
      "         0.8816, 0.5873, 0.7691, 0.5947, 0.1027, 0.3078, 0.8704, 0.2991, 0.7268,\n",
      "         0.6363, 0.0941, 0.3014, 0.1666, 0.2822, 0.4743, 0.0863, 0.5877, 0.2257,\n",
      "         0.8647, 0.7995, 0.7519, 0.8933, 0.8983, 0.5155, 0.3053, 0.2663, 0.3517,\n",
      "         0.5812, 0.6896, 0.9321, 0.9477, 0.3263, 0.3596, 0.7509, 0.7796],\n",
      "        [0.9564, 0.9764, 0.9884, 0.9677, 0.9243, 0.9622, 0.9815, 0.7817, 0.7246,\n",
      "         0.1942, 0.9645, 0.8496, 0.0144, 0.9603, 0.9365, 0.5638, 0.0525, 0.2018,\n",
      "         0.4242, 0.7644, 0.0645, 0.9212, 0.1571, 0.1423, 0.0797, 0.2135, 0.8753,\n",
      "         0.8354, 0.6320, 0.8625, 0.8704, 0.7462, 0.1226, 0.1731, 0.0406, 0.0219,\n",
      "         0.8309, 0.6967, 0.2446, 0.7567, 0.2688, 0.8225, 0.9395, 0.0952, 0.5756,\n",
      "         0.1788, 0.4352, 0.8178, 0.2144, 0.1554, 0.9104, 0.0555, 0.8909, 0.7693,\n",
      "         0.9226, 0.5832, 0.8409, 0.4401, 0.9435, 0.2187, 0.0498, 0.3420, 0.9462,\n",
      "         0.8463, 0.0528, 0.1294, 0.1193, 0.8523, 0.9476, 0.6472, 0.1214, 0.0971,\n",
      "         0.7991, 0.0322, 0.2687, 0.9226, 0.0591, 0.3220, 0.0417, 0.5953, 0.3610,\n",
      "         0.0729, 0.9418, 0.3430, 0.0796, 0.7673, 0.6338, 0.2654, 0.0709, 0.0922,\n",
      "         0.6721, 0.8425, 0.8144, 0.1404, 0.1999, 0.8578, 0.2092, 0.7376, 0.8703,\n",
      "         0.9553, 0.1964, 0.8771, 0.7760, 0.0939, 0.1980, 0.7143, 0.0751, 0.6688,\n",
      "         0.8913, 0.0805, 0.1316, 0.1166, 0.8647, 0.6757, 0.0437, 0.6056, 0.0745,\n",
      "         0.3406, 0.9157, 0.5994, 0.9389, 0.9473, 0.0966, 0.0389, 0.0599, 0.0934,\n",
      "         0.8913, 0.8061, 0.3099, 0.7777, 0.7515, 0.8567, 0.9255, 0.8508],\n",
      "        [0.9526, 0.9794, 0.9902, 0.9367, 0.9556, 0.9487, 0.9790, 0.8871, 0.7835,\n",
      "         0.7144, 0.9377, 0.9738, 0.0125, 0.9620, 0.9211, 0.4577, 0.4373, 0.2692,\n",
      "         0.7918, 0.7865, 0.0471, 0.9265, 0.2114, 0.2385, 0.2581, 0.1703, 0.8159,\n",
      "         0.8548, 0.6316, 0.8738, 0.7983, 0.7190, 0.4777, 0.6473, 0.0935, 0.0206,\n",
      "         0.7795, 0.6824, 0.5785, 0.6810, 0.2543, 0.8886, 0.9055, 0.1808, 0.7224,\n",
      "         0.3528, 0.7741, 0.8595, 0.6904, 0.1312, 0.8268, 0.0335, 0.8048, 0.7372,\n",
      "         0.9003, 0.6759, 0.6743, 0.5849, 0.8781, 0.6129, 0.0759, 0.6292, 0.9023,\n",
      "         0.7360, 0.1940, 0.1891, 0.5779, 0.7662, 0.9476, 0.7889, 0.1308, 0.1989,\n",
      "         0.8577, 0.0459, 0.3250, 0.9072, 0.5292, 0.5516, 0.1104, 0.8641, 0.4524,\n",
      "         0.3744, 0.9315, 0.3191, 0.1173, 0.9197, 0.4733, 0.4101, 0.2150, 0.1181,\n",
      "         0.8252, 0.8376, 0.8420, 0.2764, 0.6688, 0.8298, 0.5111, 0.8353, 0.8896,\n",
      "         0.8433, 0.1446, 0.9291, 0.7288, 0.0598, 0.1165, 0.4630, 0.0685, 0.2972,\n",
      "         0.8537, 0.0675, 0.1736, 0.1546, 0.4635, 0.7815, 0.0562, 0.8369, 0.4813,\n",
      "         0.5733, 0.9100, 0.8843, 0.9386, 0.9072, 0.6633, 0.0843, 0.1600, 0.1407,\n",
      "         0.8641, 0.9059, 0.3290, 0.8604, 0.7114, 0.8529, 0.8773, 0.8458],\n",
      "        [0.7834, 0.9794, 0.9885, 0.8233, 0.5962, 0.6682, 0.9749, 0.7148, 0.5189,\n",
      "         0.7145, 0.8284, 0.7155, 0.0802, 0.9435, 0.7753, 0.3811, 0.3378, 0.5525,\n",
      "         0.7289, 0.3990, 0.0674, 0.7929, 0.4204, 0.4015, 0.4010, 0.3153, 0.7269,\n",
      "         0.7913, 0.7962, 0.8494, 0.5499, 0.6155, 0.4933, 0.6276, 0.4458, 0.0352,\n",
      "         0.6649, 0.4201, 0.3121, 0.7525, 0.4646, 0.6840, 0.9497, 0.2244, 0.4085,\n",
      "         0.5999, 0.8500, 0.5199, 0.6176, 0.2963, 0.6139, 0.1037, 0.6947, 0.3626,\n",
      "         0.8600, 0.4586, 0.5982, 0.7398, 0.8087, 0.5283, 0.4399, 0.3792, 0.7926,\n",
      "         0.6533, 0.5096, 0.4320, 0.6645, 0.6724, 0.9331, 0.4686, 0.2526, 0.4531,\n",
      "         0.8795, 0.1372, 0.4315, 0.6591, 0.5744, 0.7916, 0.1843, 0.8454, 0.7560,\n",
      "         0.4416, 0.7013, 0.3557, 0.2617, 0.9231, 0.4439, 0.6732, 0.2466, 0.4120,\n",
      "         0.4885, 0.7324, 0.7099, 0.5638, 0.7677, 0.5618, 0.5582, 0.7285, 0.5942,\n",
      "         0.6013, 0.4735, 0.7862, 0.4633, 0.1575, 0.2487, 0.6243, 0.3190, 0.6788,\n",
      "         0.6581, 0.0736, 0.3562, 0.2331, 0.3178, 0.4331, 0.1144, 0.6960, 0.3979,\n",
      "         0.6128, 0.8540, 0.7155, 0.9417, 0.9259, 0.5741, 0.3393, 0.2957, 0.4208,\n",
      "         0.7733, 0.4902, 0.8347, 0.8819, 0.4570, 0.5348, 0.7140, 0.7628]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[110774, 2048], edge_index=[2, 996966], y=[110774, 2], pos=[110774, 2], censor=[4], duration=[4], batch=[110774], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.7265,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.6682,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.8597,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  1.2914,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  20\n",
      "Data[0]:  tensor([[4.8600e+01, 1.2306e+01, 3.0563e+00, 9.0720e+00, 0.0000e+00, 2.9678e+00,\n",
      "         0.0000e+00, 1.0981e-01, 2.4431e+00, 7.7479e-01, 8.3954e+00, 0.0000e+00,\n",
      "         8.3580e+00, 2.8122e+00, 4.7501e-01, 4.4332e-01, 1.8665e-01],\n",
      "        [8.1338e+01, 2.9522e+00, 4.4264e+00, 3.3031e+00, 0.0000e+00, 1.2143e+00,\n",
      "         0.0000e+00, 2.7159e-01, 9.4009e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3476e+00, 2.2866e+00, 5.9168e-01, 2.9477e-01, 3.3434e-02],\n",
      "        [5.0138e+01, 1.2223e+01, 2.4176e+00, 1.3929e+01, 0.0000e+00, 4.0609e+00,\n",
      "         0.0000e+00, 1.4004e+00, 1.1551e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.7976e+00, 1.6480e+00, 1.8638e+00, 1.2308e+00, 1.1357e+00],\n",
      "        [8.0093e+01, 2.5838e+00, 2.6103e+00, 5.2601e+00, 0.0000e+00, 6.8993e-01,\n",
      "         0.0000e+00, 1.5740e-01, 3.0218e-01, 4.3219e-02, 2.6768e+00, 0.0000e+00,\n",
      "         2.5926e+00, 1.2834e+00, 8.2601e-01, 7.2652e-01, 1.5525e-01]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7792, 0.9770, 0.9886, 0.7997, 0.4487, 0.5031, 0.9562, 0.6063, 0.6999,\n",
      "         0.8320, 0.5661, 0.6182, 0.0493, 0.9029, 0.8868, 0.3417, 0.5810, 0.4910,\n",
      "         0.8656, 0.6561, 0.0585, 0.4734, 0.5303, 0.3545, 0.5154, 0.2735, 0.6757,\n",
      "         0.7628, 0.9196, 0.8407, 0.6259, 0.8284, 0.4338, 0.7388, 0.2547, 0.0181,\n",
      "         0.6697, 0.5338, 0.4339, 0.9379, 0.8404, 0.6250, 0.7930, 0.3904, 0.7315,\n",
      "         0.7772, 0.8848, 0.7696, 0.5908, 0.3528, 0.7205, 0.0641, 0.6132, 0.5652,\n",
      "         0.7992, 0.6726, 0.7165, 0.7686, 0.7130, 0.7289, 0.4430, 0.8202, 0.5476,\n",
      "         0.6406, 0.7459, 0.4734, 0.8324, 0.5164, 0.9562, 0.5648, 0.3444, 0.3636,\n",
      "         0.9295, 0.3125, 0.3987, 0.8647, 0.6289, 0.8717, 0.1344, 0.9585, 0.9476,\n",
      "         0.6478, 0.9065, 0.5791, 0.3591, 0.9532, 0.5040, 0.6422, 0.2903, 0.4052,\n",
      "         0.4462, 0.8041, 0.8632, 0.4228, 0.6055, 0.7590, 0.8020, 0.6132, 0.7692,\n",
      "         0.7523, 0.5443, 0.8830, 0.6490, 0.4201, 0.2807, 0.6365, 0.1778, 0.4851,\n",
      "         0.5699, 0.0685, 0.5455, 0.1689, 0.3223, 0.6270, 0.1297, 0.7356, 0.4614,\n",
      "         0.8740, 0.8784, 0.7707, 0.9326, 0.8122, 0.7157, 0.4500, 0.2223, 0.3450,\n",
      "         0.8762, 0.8370, 0.9397, 0.9698, 0.7109, 0.7766, 0.6948, 0.8527],\n",
      "        [0.9526, 0.9794, 0.9902, 0.9367, 0.9556, 0.9487, 0.9790, 0.8871, 0.7835,\n",
      "         0.7144, 0.9377, 0.9738, 0.0125, 0.9620, 0.9211, 0.4577, 0.4373, 0.2692,\n",
      "         0.7918, 0.7865, 0.0471, 0.9265, 0.2114, 0.2385, 0.2581, 0.1703, 0.8159,\n",
      "         0.8548, 0.6316, 0.8738, 0.7983, 0.7190, 0.4777, 0.6473, 0.0935, 0.0206,\n",
      "         0.7795, 0.6824, 0.5785, 0.6810, 0.2543, 0.8886, 0.9055, 0.1808, 0.7224,\n",
      "         0.3528, 0.7741, 0.8595, 0.6904, 0.1312, 0.8268, 0.0335, 0.8048, 0.7372,\n",
      "         0.9003, 0.6759, 0.6743, 0.5849, 0.8781, 0.6129, 0.0759, 0.6292, 0.9023,\n",
      "         0.7360, 0.1940, 0.1891, 0.5779, 0.7662, 0.9476, 0.7889, 0.1308, 0.1989,\n",
      "         0.8577, 0.0459, 0.3250, 0.9072, 0.5292, 0.5516, 0.1104, 0.8641, 0.4524,\n",
      "         0.3744, 0.9315, 0.3191, 0.1173, 0.9197, 0.4733, 0.4101, 0.2150, 0.1181,\n",
      "         0.8252, 0.8376, 0.8420, 0.2764, 0.6688, 0.8298, 0.5111, 0.8353, 0.8896,\n",
      "         0.8433, 0.1446, 0.9291, 0.7288, 0.0598, 0.1165, 0.4630, 0.0685, 0.2972,\n",
      "         0.8537, 0.0675, 0.1736, 0.1546, 0.4635, 0.7815, 0.0562, 0.8369, 0.4813,\n",
      "         0.5733, 0.9100, 0.8843, 0.9386, 0.9072, 0.6633, 0.0843, 0.1600, 0.1407,\n",
      "         0.8641, 0.9059, 0.3290, 0.8604, 0.7114, 0.8529, 0.8773, 0.8458],\n",
      "        [0.7996, 0.9649, 0.9739, 0.8728, 0.4302, 0.6394, 0.9656, 0.6030, 0.5986,\n",
      "         0.7262, 0.7110, 0.5592, 0.0338, 0.9540, 0.8642, 0.4319, 0.2553, 0.4388,\n",
      "         0.7787, 0.5357, 0.0679, 0.8467, 0.3872, 0.3310, 0.3111, 0.1990, 0.4804,\n",
      "         0.6869, 0.6351, 0.8376, 0.6138, 0.5579, 0.3550, 0.4169, 0.2535, 0.0752,\n",
      "         0.5065, 0.4031, 0.2424, 0.6153, 0.5649, 0.6349, 0.6548, 0.1944, 0.5210,\n",
      "         0.5516, 0.4238, 0.5816, 0.3516, 0.2285, 0.4828, 0.1102, 0.6838, 0.3536,\n",
      "         0.8356, 0.5692, 0.5349, 0.7585, 0.6850, 0.4182, 0.4057, 0.4916, 0.7295,\n",
      "         0.6157, 0.1668, 0.2686, 0.6723, 0.6843, 0.9413, 0.4160, 0.1975, 0.3521,\n",
      "         0.6572, 0.1084, 0.4079, 0.7212, 0.4237, 0.7991, 0.0476, 0.8779, 0.6165,\n",
      "         0.3290, 0.8812, 0.3669, 0.4687, 0.9451, 0.4891, 0.4855, 0.1623, 0.4071,\n",
      "         0.6598, 0.7629, 0.7409, 0.4231, 0.6611, 0.7773, 0.5193, 0.8038, 0.7908,\n",
      "         0.5282, 0.5517, 0.6777, 0.5204, 0.0881, 0.1993, 0.7665, 0.1316, 0.6257,\n",
      "         0.5642, 0.0719, 0.3384, 0.1473, 0.3919, 0.4952, 0.0680, 0.6177, 0.3201,\n",
      "         0.5643, 0.7980, 0.7967, 0.8581, 0.8466, 0.6618, 0.1051, 0.2751, 0.3743,\n",
      "         0.7944, 0.7761, 0.7643, 0.9337, 0.4711, 0.5150, 0.7545, 0.7839],\n",
      "        [0.9576, 0.9775, 0.9881, 0.9498, 0.9121, 0.9437, 0.9773, 0.8558, 0.8261,\n",
      "         0.5471, 0.8868, 0.8820, 0.6969, 0.9148, 0.8663, 0.5704, 0.2936, 0.3597,\n",
      "         0.5047, 0.3246, 0.0777, 0.8421, 0.3758, 0.1268, 0.1727, 0.1944, 0.6349,\n",
      "         0.8036, 0.7362, 0.8714, 0.8469, 0.8316, 0.6646, 0.6450, 0.2060, 0.0525,\n",
      "         0.8570, 0.7373, 0.2090, 0.7305, 0.2380, 0.7979, 0.9413, 0.2870, 0.8281,\n",
      "         0.3018, 0.7431, 0.8275, 0.7863, 0.1419, 0.8064, 0.2048, 0.8617, 0.7862,\n",
      "         0.9002, 0.7458, 0.7441, 0.7571, 0.8564, 0.5522, 0.1806, 0.6599, 0.9346,\n",
      "         0.8269, 0.2011, 0.3264, 0.5786, 0.8351, 0.8925, 0.7250, 0.5345, 0.3168,\n",
      "         0.9362, 0.0615, 0.3449, 0.9010, 0.5132, 0.8209, 0.0811, 0.8644, 0.4708,\n",
      "         0.3915, 0.9267, 0.4900, 0.2315, 0.8909, 0.5481, 0.6154, 0.1798, 0.1749,\n",
      "         0.7231, 0.8222, 0.8593, 0.8171, 0.4480, 0.7954, 0.4504, 0.8718, 0.9176,\n",
      "         0.9005, 0.1733, 0.4945, 0.7488, 0.0972, 0.3397, 0.3765, 0.1139, 0.7739,\n",
      "         0.8759, 0.0712, 0.3540, 0.4806, 0.8030, 0.7753, 0.0611, 0.8214, 0.1984,\n",
      "         0.4115, 0.9017, 0.7624, 0.9017, 0.9332, 0.4939, 0.1417, 0.2428, 0.2285,\n",
      "         0.8979, 0.8506, 0.3863, 0.8642, 0.7912, 0.8471, 0.9105, 0.8533]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[104921, 2048], edge_index=[2, 944289], y=[104921, 2], pos=[104921, 2], censor=[4], duration=[4], batch=[104921], ptr=[5])\n",
      "Data[3]:  tensor([[1.0000, 0.7080, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.8597, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.2128, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0264, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  21\n",
      "Data[0]:  tensor([[8.8570e+01, 1.5884e+00, 4.2469e+00, 1.0609e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.5333e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.6032e+01, 4.2551e+00, 2.9331e-02, 5.5394e+00, 0.0000e+00, 2.6969e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4285e+00, 1.4163e+00, 8.7572e-01,\n",
      "         2.2346e+00, 4.4921e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.9929e+01, 7.1370e-01, 8.6359e+00, 1.4973e-01, 0.0000e+00, 5.3524e-02,\n",
      "         0.0000e+00, 1.0752e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 4.1102e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.8406e+01, 6.8717e+00, 4.5880e+00, 9.3096e+00, 0.0000e+00, 3.3393e+00,\n",
      "         0.0000e+00, 4.6870e-01, 1.0459e+00, 0.0000e+00, 3.1070e+00, 0.0000e+00,\n",
      "         5.8434e+00, 2.2830e+00, 4.2115e-02, 1.0500e+00, 3.6449e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9827, 0.9796, 0.9889, 0.9617, 0.9475, 0.9485, 0.9849, 0.9134, 0.6323,\n",
      "         0.3569, 0.8910, 0.8659, 0.0102, 0.9544, 0.9424, 0.5862, 0.0607, 0.1827,\n",
      "         0.2845, 0.6791, 0.0689, 0.8913, 0.2468, 0.0693, 0.1080, 0.1771, 0.7625,\n",
      "         0.8156, 0.4153, 0.9053, 0.9248, 0.6979, 0.1253, 0.0920, 0.0803, 0.0438,\n",
      "         0.4975, 0.7527, 0.0685, 0.2163, 0.1343, 0.7502, 0.9598, 0.0611, 0.7563,\n",
      "         0.1164, 0.4048, 0.9109, 0.1717, 0.1118, 0.8889, 0.0328, 0.7795, 0.7888,\n",
      "         0.9207, 0.6358, 0.6856, 0.3691, 0.7658, 0.2466, 0.0355, 0.2502, 0.9439,\n",
      "         0.7188, 0.0419, 0.1441, 0.1458, 0.7447, 0.9138, 0.5656, 0.1697, 0.1214,\n",
      "         0.8570, 0.0557, 0.1362, 0.8874, 0.0923, 0.3558, 0.0644, 0.4972, 0.2093,\n",
      "         0.0955, 0.9437, 0.1668, 0.0828, 0.7506, 0.5608, 0.1819, 0.1409, 0.1062,\n",
      "         0.8649, 0.7838, 0.8816, 0.1536, 0.1845, 0.8693, 0.1498, 0.7299, 0.9181,\n",
      "         0.9254, 0.1064, 0.8063, 0.7857, 0.0574, 0.1506, 0.6928, 0.0600, 0.9054,\n",
      "         0.8188, 0.0723, 0.1038, 0.1239, 0.8369, 0.7449, 0.0694, 0.8406, 0.1824,\n",
      "         0.3942, 0.9060, 0.7328, 0.9511, 0.8967, 0.1203, 0.0567, 0.0794, 0.1469,\n",
      "         0.8861, 0.8337, 0.4048, 0.7123, 0.8142, 0.8525, 0.8767, 0.9046],\n",
      "        [0.8492, 0.9590, 0.5512, 0.8944, 0.3804, 0.0540, 0.8517, 0.2659, 0.2656,\n",
      "         0.8261, 0.3733, 0.9116, 0.0109, 0.9168, 0.8644, 0.6571, 0.8287, 0.6206,\n",
      "         0.9116, 0.4778, 0.0698, 0.2137, 0.6979, 0.9066, 0.6458, 0.2504, 0.3595,\n",
      "         0.7159, 0.9177, 0.8964, 0.6392, 0.6274, 0.1070, 0.3731, 0.7699, 0.0754,\n",
      "         0.2876, 0.1621, 0.4368, 0.9248, 0.9294, 0.2246, 0.8616, 0.4165, 0.5827,\n",
      "         0.9137, 0.9225, 0.7042, 0.6865, 0.1866, 0.5944, 0.2077, 0.3844, 0.1388,\n",
      "         0.5686, 0.4526, 0.5953, 0.9195, 0.4620, 0.7752, 0.7342, 0.7497, 0.4728,\n",
      "         0.3924, 0.6246, 0.8547, 0.9289, 0.5537, 0.9264, 0.3014, 0.1774, 0.1622,\n",
      "         0.8300, 0.0668, 0.5803, 0.6120, 0.6903, 0.6915, 0.4663, 0.9743, 0.9305,\n",
      "         0.5858, 0.9133, 0.6884, 0.6693, 0.9496, 0.2779, 0.7801, 0.2958, 0.3776,\n",
      "         0.1932, 0.4329, 0.7481, 0.2710, 0.8351, 0.3238, 0.8590, 0.2741, 0.2739,\n",
      "         0.4225, 0.3897, 0.4450, 0.2420, 0.0663, 0.6379, 0.6236, 0.7605, 0.7459,\n",
      "         0.2735, 0.0753, 0.2372, 0.1266, 0.7790, 0.3176, 0.1238, 0.6152, 0.6567,\n",
      "         0.7884, 0.8248, 0.8441, 0.9151, 0.8883, 0.8943, 0.1833, 0.2181, 0.7776,\n",
      "         0.4251, 0.8501, 0.9195, 0.9361, 0.2106, 0.2402, 0.7084, 0.6965],\n",
      "        [0.9799, 0.9696, 0.9866, 0.9418, 0.9361, 0.9584, 0.9759, 0.9166, 0.6908,\n",
      "         0.0204, 0.9722, 0.7945, 0.0143, 0.7956, 0.9530, 0.8382, 0.0413, 0.1388,\n",
      "         0.1836, 0.8516, 0.0754, 0.8967, 0.1058, 0.0506, 0.0518, 0.1677, 0.8618,\n",
      "         0.8780, 0.4724, 0.8619, 0.9389, 0.6769, 0.1256, 0.0749, 0.0625, 0.0320,\n",
      "         0.8704, 0.7880, 0.0534, 0.5805, 0.0835, 0.8555, 0.9375, 0.1360, 0.8610,\n",
      "         0.0906, 0.1884, 0.9256, 0.1653, 0.0991, 0.8596, 0.0641, 0.9160, 0.8680,\n",
      "         0.9320, 0.7941, 0.8779, 0.2601, 0.9022, 0.1266, 0.0616, 0.3302, 0.9643,\n",
      "         0.7038, 0.0544, 0.1668, 0.1068, 0.8602, 0.9272, 0.8176, 0.1031, 0.0961,\n",
      "         0.8147, 0.0383, 0.0762, 0.9360, 0.0474, 0.1220, 0.0568, 0.6293, 0.0988,\n",
      "         0.0788, 0.9002, 0.2127, 0.0840, 0.5495, 0.7044, 0.1220, 0.0659, 0.0816,\n",
      "         0.9287, 0.8944, 0.8711, 0.1267, 0.1630, 0.8610, 0.2384, 0.8265, 0.9108,\n",
      "         0.9360, 0.0865, 0.9388, 0.7845, 0.0771, 0.1217, 0.8444, 0.0550, 0.7027,\n",
      "         0.9156, 0.0673, 0.0800, 0.1196, 0.8215, 0.7578, 0.0423, 0.8452, 0.0707,\n",
      "         0.1497, 0.8610, 0.3373, 0.9449, 0.9493, 0.0849, 0.0677, 0.0676, 0.0557,\n",
      "         0.9246, 0.8921, 0.0984, 0.6806, 0.8603, 0.9192, 0.8951, 0.9678],\n",
      "        [0.8626, 0.9735, 0.9546, 0.8962, 0.5815, 0.8433, 0.9684, 0.4446, 0.7440,\n",
      "         0.3993, 0.7419, 0.9257, 0.0384, 0.9482, 0.4698, 0.5483, 0.5397, 0.3855,\n",
      "         0.9108, 0.2833, 0.0608, 0.8370, 0.3051, 0.3422, 0.2589, 0.2030, 0.8189,\n",
      "         0.8154, 0.9424, 0.8693, 0.6521, 0.5127, 0.3142, 0.3719, 0.1442, 0.0188,\n",
      "         0.5371, 0.3745, 0.3599, 0.8116, 0.8464, 0.6801, 0.9418, 0.1884, 0.6952,\n",
      "         0.7283, 0.8343, 0.7165, 0.4103, 0.2143, 0.6091, 0.1054, 0.7796, 0.3433,\n",
      "         0.7692, 0.5430, 0.5300, 0.7812, 0.7614, 0.3871, 0.2838, 0.5108, 0.8509,\n",
      "         0.7736, 0.2762, 0.1918, 0.6444, 0.7555, 0.9517, 0.6349, 0.1836, 0.3641,\n",
      "         0.9000, 0.0662, 0.3177, 0.8804, 0.2993, 0.8369, 0.0455, 0.9010, 0.9386,\n",
      "         0.2137, 0.5442, 0.3687, 0.2563, 0.9432, 0.5062, 0.4053, 0.3843, 0.2686,\n",
      "         0.2935, 0.7967, 0.7763, 0.4147, 0.5170, 0.5120, 0.2573, 0.5737, 0.7999,\n",
      "         0.7873, 0.4346, 0.7154, 0.6648, 0.1095, 0.1972, 0.8314, 0.1830, 0.4989,\n",
      "         0.5211, 0.0631, 0.2543, 0.1706, 0.6663, 0.5383, 0.0545, 0.5459, 0.7280,\n",
      "         0.7661, 0.9033, 0.7002, 0.9263, 0.9139, 0.2124, 0.1286, 0.1940, 0.2630,\n",
      "         0.8535, 0.8377, 0.4588, 0.9491, 0.6146, 0.6736, 0.8200, 0.7385]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[71139, 2048], edge_index=[2, 640251], y=[71139, 2], pos=[71139, 2], censor=[4], duration=[4], batch=[71139], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  0.0698,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.4881,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.8008,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.1489,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  22\n",
      "Data[0]:  tensor([[6.3054e+01, 5.0391e+00, 2.2946e+00, 9.2391e+00, 0.0000e+00, 4.6151e+00,\n",
      "         0.0000e+00, 8.2298e-02, 6.3051e-02, 0.0000e+00, 6.9722e+00, 0.0000e+00,\n",
      "         4.7528e+00, 3.8878e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.8898e+01, 6.5091e+00, 4.0333e+00, 6.6318e+00, 0.0000e+00, 3.0631e+00,\n",
      "         0.0000e+00, 9.3951e+00, 4.2323e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.9587e+00, 1.7273e+00, 9.2221e-01, 4.5454e-01, 1.7466e-01],\n",
      "        [9.0075e+01, 4.7512e+00, 2.6868e+00, 2.4870e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.5630e+01, 9.3253e+00, 2.6042e+00, 5.6648e+00, 3.6649e+00, 1.0898e+01,\n",
      "         0.0000e+00, 3.7193e+00, 2.0788e+00, 0.0000e+00, 1.2697e+01, 0.0000e+00,\n",
      "         3.7184e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.8350, 0.8720, 0.9767, 0.9525, 0.8991, 0.9249, 0.9685, 0.6780, 0.4054,\n",
      "         0.4178, 0.4985, 0.5612, 0.0351, 0.8218, 0.7817, 0.5232, 0.5231, 0.2999,\n",
      "         0.8848, 0.7653, 0.0748, 0.6036, 0.5018, 0.1666, 0.5365, 0.2496, 0.5665,\n",
      "         0.5836, 0.9302, 0.8862, 0.7406, 0.7916, 0.2821, 0.6781, 0.1014, 0.0558,\n",
      "         0.6571, 0.6270, 0.3071, 0.8906, 0.8731, 0.3584, 0.8869, 0.2992, 0.6073,\n",
      "         0.5436, 0.8345, 0.7219, 0.5668, 0.2221, 0.5546, 0.1684, 0.5819, 0.6332,\n",
      "         0.5607, 0.6853, 0.4804, 0.9062, 0.7383, 0.5872, 0.2065, 0.8170, 0.8533,\n",
      "         0.5646, 0.7630, 0.4803, 0.8478, 0.7341, 0.9316, 0.6146, 0.1542, 0.6389,\n",
      "         0.9028, 0.2671, 0.7365, 0.8811, 0.7934, 0.6845, 0.4326, 0.9385, 0.9074,\n",
      "         0.1672, 0.9100, 0.5689, 0.4210, 0.9315, 0.4501, 0.5748, 0.3170, 0.2815,\n",
      "         0.7465, 0.7440, 0.8161, 0.3516, 0.7164, 0.8469, 0.7432, 0.3629, 0.7092,\n",
      "         0.4793, 0.5649, 0.8602, 0.6787, 0.1035, 0.4233, 0.8684, 0.3084, 0.6316,\n",
      "         0.4842, 0.1083, 0.5787, 0.2763, 0.2216, 0.6419, 0.0874, 0.7746, 0.3622,\n",
      "         0.8324, 0.4752, 0.7142, 0.9068, 0.5262, 0.5563, 0.5508, 0.2086, 0.1981,\n",
      "         0.8450, 0.6951, 0.9207, 0.9508, 0.3829, 0.3804, 0.8078, 0.9069],\n",
      "        [0.9219, 0.9803, 0.9889, 0.9334, 0.8360, 0.8336, 0.9822, 0.7740, 0.8092,\n",
      "         0.3773, 0.9030, 0.5844, 0.0203, 0.9466, 0.8826, 0.5106, 0.0981, 0.3806,\n",
      "         0.4828, 0.7350, 0.0821, 0.7996, 0.2687, 0.1902, 0.1664, 0.2391, 0.5966,\n",
      "         0.7874, 0.5801, 0.8939, 0.7457, 0.6869, 0.4571, 0.3567, 0.1765, 0.0458,\n",
      "         0.7322, 0.6703, 0.2634, 0.7201, 0.3723, 0.7879, 0.9136, 0.1709, 0.7349,\n",
      "         0.3427, 0.3402, 0.8458, 0.5681, 0.1834, 0.7623, 0.0883, 0.7999, 0.6810,\n",
      "         0.9346, 0.6924, 0.8303, 0.6386, 0.8513, 0.4452, 0.2181, 0.2968, 0.8761,\n",
      "         0.8182, 0.0567, 0.2902, 0.4835, 0.7816, 0.9240, 0.6841, 0.1725, 0.2667,\n",
      "         0.7352, 0.0936, 0.2598, 0.8040, 0.4611, 0.4158, 0.0675, 0.8964, 0.5687,\n",
      "         0.2557, 0.9416, 0.2989, 0.2103, 0.9327, 0.5679, 0.5215, 0.1700, 0.2798,\n",
      "         0.7155, 0.8366, 0.8868, 0.3813, 0.5483, 0.7777, 0.5497, 0.8277, 0.8215,\n",
      "         0.8439, 0.2779, 0.9150, 0.6869, 0.0983, 0.1991, 0.7732, 0.1499, 0.6185,\n",
      "         0.8314, 0.0767, 0.2603, 0.1695, 0.6430, 0.7212, 0.0968, 0.8596, 0.2008,\n",
      "         0.3583, 0.8202, 0.7234, 0.9497, 0.9391, 0.4981, 0.0635, 0.1417, 0.2390,\n",
      "         0.8686, 0.8716, 0.3344, 0.9440, 0.7116, 0.7926, 0.8375, 0.8751],\n",
      "        [0.7642, 0.9714, 0.7376, 0.6729, 0.2722, 0.8817, 0.6255, 0.3394, 0.2024,\n",
      "         0.7129, 0.7720, 0.2415, 0.0119, 0.8601, 0.6798, 0.2764, 0.0939, 0.4615,\n",
      "         0.8058, 0.6504, 0.0769, 0.5544, 0.4212, 0.1022, 0.2521, 0.1545, 0.5525,\n",
      "         0.5550, 0.6521, 0.8841, 0.7069, 0.3752, 0.1416, 0.3897, 0.0906, 0.0361,\n",
      "         0.5203, 0.4340, 0.3787, 0.2975, 0.3093, 0.5539, 0.6784, 0.1756, 0.6139,\n",
      "         0.2294, 0.7346, 0.9010, 0.2613, 0.1647, 0.8422, 0.0471, 0.6619, 0.5489,\n",
      "         0.5245, 0.3174, 0.2560, 0.6793, 0.7342, 0.2726, 0.0640, 0.5067, 0.6145,\n",
      "         0.5707, 0.1041, 0.1828, 0.7650, 0.6695, 0.8729, 0.4296, 0.1587, 0.6368,\n",
      "         0.8774, 0.0753, 0.3177, 0.9037, 0.1561, 0.8989, 0.1726, 0.7429, 0.5511,\n",
      "         0.3072, 0.6505, 0.1614, 0.0738, 0.9209, 0.2931, 0.6274, 0.1003, 0.2295,\n",
      "         0.3036, 0.7443, 0.7691, 0.7670, 0.1769, 0.4397, 0.4967, 0.4563, 0.4784,\n",
      "         0.8028, 0.1000, 0.6877, 0.7073, 0.1217, 0.4301, 0.2461, 0.3616, 0.2482,\n",
      "         0.5845, 0.0905, 0.1812, 0.1422, 0.1689, 0.5959, 0.0610, 0.4572, 0.2827,\n",
      "         0.3277, 0.8062, 0.8111, 0.7773, 0.8853, 0.1907, 0.1477, 0.2546, 0.0862,\n",
      "         0.5149, 0.5222, 0.8715, 0.7692, 0.7172, 0.6893, 0.5599, 0.5819],\n",
      "        [0.7011, 0.9779, 0.9809, 0.9301, 0.8285, 0.8554, 0.9738, 0.5848, 0.7840,\n",
      "         0.6593, 0.9121, 0.8494, 0.0348, 0.9497, 0.8514, 0.4528, 0.3434, 0.4769,\n",
      "         0.7430, 0.5731, 0.0943, 0.5534, 0.5173, 0.3650, 0.3457, 0.2967, 0.8113,\n",
      "         0.6925, 0.9375, 0.8873, 0.5552, 0.7196, 0.2241, 0.6272, 0.1411, 0.0819,\n",
      "         0.6462, 0.5111, 0.4866, 0.7646, 0.8536, 0.7699, 0.8092, 0.1968, 0.5370,\n",
      "         0.6383, 0.5488, 0.5350, 0.2397, 0.3041, 0.8626, 0.1741, 0.7953, 0.5014,\n",
      "         0.8948, 0.5086, 0.6506, 0.6660, 0.8760, 0.4545, 0.2930, 0.4871, 0.8573,\n",
      "         0.7742, 0.2780, 0.2665, 0.8604, 0.8382, 0.9536, 0.5421, 0.1787, 0.3026,\n",
      "         0.8925, 0.2025, 0.3386, 0.6904, 0.3553, 0.7518, 0.0452, 0.9258, 0.9436,\n",
      "         0.4248, 0.8778, 0.4219, 0.3125, 0.9451, 0.5364, 0.6164, 0.1275, 0.3549,\n",
      "         0.6003, 0.8023, 0.8982, 0.2993, 0.5974, 0.6925, 0.5945, 0.8268, 0.5899,\n",
      "         0.7972, 0.5767, 0.8354, 0.5987, 0.0733, 0.2920, 0.8665, 0.4341, 0.5574,\n",
      "         0.6828, 0.2336, 0.1767, 0.1472, 0.4884, 0.4543, 0.0514, 0.6996, 0.1688,\n",
      "         0.6534, 0.7309, 0.4614, 0.9507, 0.9163, 0.3419, 0.1178, 0.2466, 0.2869,\n",
      "         0.7655, 0.7298, 0.7851, 0.9586, 0.5943, 0.6317, 0.6885, 0.9141]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[95166, 2048], edge_index=[2, 856494], y=[95166, 2], pos=[95166, 2], censor=[4], duration=[4], batch=[95166], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000,  0.6394,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.9290,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.3877,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.4304,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  23\n",
      "Data[0]:  tensor([[61.8227,  5.3264,  4.2147,  7.5518,  0.0000,  2.0586,  0.0000,  3.7247,\n",
      "          1.0865,  0.0000,  1.5524,  0.0000,  5.0045,  1.8527,  1.1269,  0.3770,\n",
      "          4.3012],\n",
      "        [58.5326,  9.9532,  8.7534,  6.6720,  0.0000,  4.1691,  0.0000,  1.0985,\n",
      "          0.6673,  0.0000,  5.6110,  0.0000,  2.7125,  1.8304,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [84.9765,  1.0978,  7.4589,  1.4052,  0.0000,  0.3262,  0.0000,  0.5822,\n",
      "          0.4201,  0.0000,  0.6239,  0.0000,  0.4751,  0.0000,  2.5374,  0.0000,\n",
      "          0.0967],\n",
      "        [69.9012,  3.5287,  5.2116,  3.9077,  0.0000,  1.2715,  0.0000,  0.0000,\n",
      "          1.0573,  0.0000,  2.5127,  0.0000,  6.2053,  2.5236,  0.2670,  0.6481,\n",
      "          2.9651]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6701, 0.9690, 0.9014, 0.8489, 0.8706, 0.8117, 0.9747, 0.4385, 0.6654,\n",
      "         0.4461, 0.8562, 0.9346, 0.2253, 0.9321, 0.8938, 0.3564, 0.0943, 0.4178,\n",
      "         0.4361, 0.7833, 0.0765, 0.8599, 0.3603, 0.2810, 0.5614, 0.2272, 0.3726,\n",
      "         0.7952, 0.9466, 0.8709, 0.4928, 0.5537, 0.1787, 0.3413, 0.0850, 0.0485,\n",
      "         0.7314, 0.5892, 0.5302, 0.9188, 0.6467, 0.7696, 0.6462, 0.4430, 0.7643,\n",
      "         0.6437, 0.7821, 0.7840, 0.2258, 0.2237, 0.7280, 0.0771, 0.8318, 0.6279,\n",
      "         0.8974, 0.5002, 0.4293, 0.6568, 0.8739, 0.7014, 0.1761, 0.5677, 0.7064,\n",
      "         0.7960, 0.1638, 0.2401, 0.6777, 0.6796, 0.7431, 0.5300, 0.1747, 0.2447,\n",
      "         0.9249, 0.1505, 0.1423, 0.8706, 0.4742, 0.8432, 0.1298, 0.9763, 0.8558,\n",
      "         0.1464, 0.8570, 0.3949, 0.1843, 0.9547, 0.3269, 0.4982, 0.1142, 0.2925,\n",
      "         0.2380, 0.7274, 0.8397, 0.4060, 0.5958, 0.7101, 0.8945, 0.5763, 0.3482,\n",
      "         0.8394, 0.4793, 0.6804, 0.5262, 0.2392, 0.2186, 0.7441, 0.1690, 0.2898,\n",
      "         0.4205, 0.0712, 0.5871, 0.1159, 0.6458, 0.4782, 0.0796, 0.5183, 0.2406,\n",
      "         0.8698, 0.5665, 0.7963, 0.9163, 0.4895, 0.5807, 0.0671, 0.1544, 0.2607,\n",
      "         0.6743, 0.7968, 0.8474, 0.9621, 0.6712, 0.6316, 0.6146, 0.8052],\n",
      "        [0.8664, 0.9635, 0.9754, 0.9489, 0.8643, 0.9149, 0.9653, 0.4596, 0.7192,\n",
      "         0.6180, 0.8325, 0.9326, 0.0286, 0.9517, 0.8781, 0.4942, 0.0634, 0.3575,\n",
      "         0.7976, 0.7187, 0.1006, 0.8499, 0.3313, 0.2443, 0.2465, 0.2741, 0.7336,\n",
      "         0.8025, 0.9156, 0.8776, 0.7115, 0.5428, 0.3043, 0.3628, 0.1765, 0.0381,\n",
      "         0.7504, 0.6046, 0.2705, 0.8585, 0.7186, 0.8564, 0.9254, 0.1422, 0.7643,\n",
      "         0.5172, 0.7848, 0.7870, 0.2742, 0.2254, 0.8557, 0.3040, 0.8637, 0.6572,\n",
      "         0.9261, 0.6181, 0.7563, 0.7322, 0.9209, 0.4334, 0.1344, 0.4729, 0.8425,\n",
      "         0.7506, 0.1268, 0.3100, 0.6431, 0.5858, 0.9303, 0.6231, 0.1372, 0.3306,\n",
      "         0.8914, 0.0966, 0.3337, 0.8323, 0.7160, 0.7196, 0.0675, 0.8921, 0.9262,\n",
      "         0.2573, 0.9354, 0.3901, 0.1995, 0.9410, 0.6044, 0.4339, 0.2692, 0.3054,\n",
      "         0.5062, 0.8293, 0.8150, 0.3683, 0.4333, 0.7975, 0.5993, 0.8520, 0.6405,\n",
      "         0.9223, 0.3551, 0.9182, 0.7139, 0.0923, 0.2157, 0.8504, 0.2635, 0.7210,\n",
      "         0.8888, 0.1259, 0.2439, 0.1505, 0.5517, 0.6061, 0.0894, 0.5765, 0.3983,\n",
      "         0.6273, 0.8716, 0.8138, 0.9394, 0.9008, 0.3323, 0.0737, 0.2174, 0.3725,\n",
      "         0.8851, 0.8593, 0.6032, 0.9234, 0.7411, 0.8314, 0.8219, 0.8732],\n",
      "        [0.9674, 0.9535, 0.9769, 0.9526, 0.9510, 0.9404, 0.9737, 0.7268, 0.8835,\n",
      "         0.1604, 0.9084, 0.7578, 0.0212, 0.9547, 0.9521, 0.5801, 0.0555, 0.2281,\n",
      "         0.4400, 0.9011, 0.0735, 0.9019, 0.1352, 0.1168, 0.1657, 0.1913, 0.7533,\n",
      "         0.7178, 0.7022, 0.9203, 0.8779, 0.7092, 0.1218, 0.1706, 0.0622, 0.0491,\n",
      "         0.7468, 0.6907, 0.1317, 0.7891, 0.2366, 0.9069, 0.9239, 0.2840, 0.8284,\n",
      "         0.1386, 0.7916, 0.8970, 0.2593, 0.1732, 0.9254, 0.4138, 0.9584, 0.8137,\n",
      "         0.9208, 0.6018, 0.9176, 0.3792, 0.9263, 0.2186, 0.0507, 0.3533, 0.9485,\n",
      "         0.7439, 0.1083, 0.1725, 0.2412, 0.7730, 0.9380, 0.6657, 0.1385, 0.1995,\n",
      "         0.8715, 0.0476, 0.2807, 0.9402, 0.0905, 0.3990, 0.1996, 0.7588, 0.2054,\n",
      "         0.1309, 0.9294, 0.2362, 0.0688, 0.8111, 0.6689, 0.2821, 0.0833, 0.1384,\n",
      "         0.9083, 0.7312, 0.8618, 0.1899, 0.2054, 0.9258, 0.2873, 0.8340, 0.9015,\n",
      "         0.9322, 0.1395, 0.8440, 0.7396, 0.0730, 0.1447, 0.8727, 0.0775, 0.8934,\n",
      "         0.8675, 0.0534, 0.0761, 0.2910, 0.8893, 0.6385, 0.0902, 0.7439, 0.0868,\n",
      "         0.4196, 0.9066, 0.7761, 0.9315, 0.9426, 0.0926, 0.0655, 0.0675, 0.0847,\n",
      "         0.9341, 0.8920, 0.5590, 0.7586, 0.7239, 0.8768, 0.8729, 0.8127],\n",
      "        [0.9691, 0.9831, 0.9893, 0.8125, 0.8813, 0.9713, 0.9832, 0.8279, 0.9176,\n",
      "         0.2926, 0.9760, 0.9552, 0.0132, 0.9245, 0.9046, 0.6634, 0.4759, 0.3987,\n",
      "         0.8460, 0.7299, 0.0821, 0.8793, 0.3720, 0.2681, 0.4574, 0.2333, 0.7989,\n",
      "         0.8032, 0.6912, 0.9057, 0.8479, 0.7059, 0.2259, 0.5743, 0.0978, 0.0255,\n",
      "         0.7721, 0.6372, 0.4658, 0.7741, 0.2871, 0.9049, 0.9207, 0.2787, 0.8312,\n",
      "         0.4068, 0.8651, 0.9377, 0.7735, 0.2298, 0.8857, 0.1309, 0.9273, 0.6584,\n",
      "         0.9319, 0.7012, 0.7301, 0.7210, 0.9190, 0.5353, 0.0935, 0.8003, 0.9511,\n",
      "         0.8799, 0.2660, 0.4244, 0.6180, 0.8531, 0.9527, 0.7474, 0.1278, 0.3362,\n",
      "         0.9333, 0.0714, 0.5359, 0.8970, 0.4982, 0.7363, 0.4978, 0.8831, 0.5320,\n",
      "         0.1385, 0.9406, 0.4531, 0.0979, 0.9186, 0.6978, 0.4584, 0.1727, 0.1950,\n",
      "         0.8022, 0.8008, 0.7656, 0.5711, 0.3621, 0.8950, 0.2866, 0.8499, 0.9267,\n",
      "         0.9231, 0.3579, 0.9385, 0.7877, 0.0871, 0.3852, 0.6197, 0.1590, 0.8681,\n",
      "         0.9224, 0.0683, 0.2054, 0.2765, 0.3827, 0.7696, 0.0527, 0.7215, 0.2980,\n",
      "         0.8065, 0.9136, 0.7824, 0.9364, 0.9402, 0.1942, 0.1613, 0.2001, 0.3615,\n",
      "         0.9158, 0.8625, 0.9487, 0.9438, 0.7552, 0.8156, 0.8956, 0.9350]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[71021, 2048], edge_index=[2, 639189], y=[71021, 2], pos=[71021, 2], censor=[4], duration=[4], batch=[71021], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  1.5601,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.5432,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.2177,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.0729,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  24\n",
      "Data[0]:  tensor([[6.7640e+01, 1.4640e+00, 6.6191e+00, 5.3447e+00, 0.0000e+00, 8.9960e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0466e-01, 2.2862e+00, 0.0000e+00,\n",
      "         4.7725e+00, 3.6925e+00, 1.0559e+00, 9.9776e-01, 4.5230e+00],\n",
      "        [5.9638e+01, 6.9200e+00, 2.2580e+00, 6.8535e+00, 0.0000e+00, 4.4051e+00,\n",
      "         0.0000e+00, 2.5097e+00, 1.5174e+00, 0.0000e+00, 5.8925e+00, 0.0000e+00,\n",
      "         4.4268e+00, 3.4694e+00, 7.3524e-01, 7.5940e-01, 6.1483e-01],\n",
      "        [8.1338e+01, 2.9522e+00, 4.4264e+00, 3.3031e+00, 0.0000e+00, 1.2143e+00,\n",
      "         0.0000e+00, 2.7159e-01, 9.4009e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3476e+00, 2.2866e+00, 5.9168e-01, 2.9477e-01, 3.3434e-02],\n",
      "        [5.7835e+01, 8.7745e+00, 0.0000e+00, 5.2322e+00, 0.0000e+00, 2.5427e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5113e+00, 0.0000e+00,\n",
      "         1.3393e+01, 3.7116e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7632, 0.9846, 0.9512, 0.9623, 0.9328, 0.9589, 0.9820, 0.5635, 0.8030,\n",
      "         0.9639, 0.9803, 0.4542, 0.1337, 0.9595, 0.9656, 0.5022, 0.6376, 0.4029,\n",
      "         0.9002, 0.2543, 0.0609, 0.8586, 0.3816, 0.1432, 0.3382, 0.2320, 0.7550,\n",
      "         0.8043, 0.9249, 0.9408, 0.7286, 0.8232, 0.1021, 0.6548, 0.0638, 0.0201,\n",
      "         0.8176, 0.6819, 0.4980, 0.9134, 0.8221, 0.8472, 0.9287, 0.1420, 0.7921,\n",
      "         0.7609, 0.9422, 0.9068, 0.1895, 0.1857, 0.8142, 0.0665, 0.8820, 0.6416,\n",
      "         0.8563, 0.6173, 0.5595, 0.8310, 0.7974, 0.3065, 0.0828, 0.7618, 0.9326,\n",
      "         0.8925, 0.6581, 0.4963, 0.8058, 0.9009, 0.9527, 0.7290, 0.0650, 0.2467,\n",
      "         0.8763, 0.0443, 0.2790, 0.8803, 0.4233, 0.8642, 0.0983, 0.9193, 0.8613,\n",
      "         0.1262, 0.9310, 0.6962, 0.2607, 0.9579, 0.4038, 0.3598, 0.1247, 0.2131,\n",
      "         0.5897, 0.8248, 0.8921, 0.2893, 0.6992, 0.8827, 0.8262, 0.6620, 0.7997,\n",
      "         0.6254, 0.2523, 0.8788, 0.8097, 0.1121, 0.2543, 0.8888, 0.2573, 0.6463,\n",
      "         0.5771, 0.0497, 0.0764, 0.0713, 0.7218, 0.5460, 0.0441, 0.8976, 0.1527,\n",
      "         0.8361, 0.8590, 0.8382, 0.9505, 0.9428, 0.7393, 0.2539, 0.1721, 0.1768,\n",
      "         0.8222, 0.8145, 0.9532, 0.9505, 0.3025, 0.2999, 0.6860, 0.9108],\n",
      "        [0.8029, 0.9677, 0.9794, 0.9382, 0.9044, 0.7531, 0.9540, 0.7276, 0.6872,\n",
      "         0.4844, 0.7908, 0.9316, 0.0143, 0.9456, 0.8990, 0.4131, 0.1560, 0.3259,\n",
      "         0.7345, 0.6517, 0.0644, 0.8419, 0.3469, 0.1911, 0.1572, 0.1914, 0.7176,\n",
      "         0.5064, 0.5617, 0.8769, 0.6255, 0.4728, 0.2096, 0.2346, 0.1290, 0.0550,\n",
      "         0.6114, 0.5889, 0.3299, 0.5135, 0.4566, 0.7349, 0.9424, 0.1813, 0.6618,\n",
      "         0.3283, 0.5245, 0.7344, 0.5907, 0.1800, 0.7288, 0.1153, 0.8128, 0.6132,\n",
      "         0.9013, 0.7284, 0.7582, 0.6541, 0.8245, 0.4232, 0.2193, 0.4969, 0.9010,\n",
      "         0.7718, 0.1127, 0.2886, 0.5760, 0.7048, 0.9568, 0.6880, 0.1348, 0.3160,\n",
      "         0.8533, 0.0817, 0.3364, 0.8605, 0.4710, 0.5494, 0.2880, 0.9286, 0.5594,\n",
      "         0.2233, 0.9212, 0.3457, 0.2541, 0.8277, 0.4110, 0.5093, 0.1580, 0.2903,\n",
      "         0.7207, 0.7877, 0.8878, 0.4032, 0.5319, 0.7885, 0.3365, 0.7769, 0.7100,\n",
      "         0.6666, 0.3145, 0.8417, 0.6525, 0.0945, 0.2313, 0.6222, 0.0976, 0.6580,\n",
      "         0.7703, 0.0817, 0.2885, 0.1433, 0.6210, 0.6562, 0.0629, 0.6472, 0.2498,\n",
      "         0.4737, 0.8428, 0.7385, 0.9518, 0.8677, 0.3218, 0.0650, 0.1948, 0.3167,\n",
      "         0.7898, 0.8242, 0.6522, 0.9213, 0.6504, 0.7450, 0.7801, 0.8332],\n",
      "        [0.9526, 0.9794, 0.9902, 0.9367, 0.9556, 0.9487, 0.9790, 0.8871, 0.7835,\n",
      "         0.7144, 0.9377, 0.9738, 0.0125, 0.9620, 0.9211, 0.4577, 0.4373, 0.2692,\n",
      "         0.7918, 0.7865, 0.0471, 0.9265, 0.2114, 0.2385, 0.2581, 0.1703, 0.8159,\n",
      "         0.8548, 0.6316, 0.8738, 0.7983, 0.7190, 0.4777, 0.6473, 0.0935, 0.0206,\n",
      "         0.7795, 0.6824, 0.5785, 0.6810, 0.2543, 0.8886, 0.9055, 0.1808, 0.7224,\n",
      "         0.3528, 0.7741, 0.8595, 0.6904, 0.1312, 0.8268, 0.0335, 0.8048, 0.7372,\n",
      "         0.9003, 0.6759, 0.6743, 0.5849, 0.8781, 0.6129, 0.0759, 0.6292, 0.9023,\n",
      "         0.7360, 0.1940, 0.1891, 0.5779, 0.7662, 0.9476, 0.7889, 0.1308, 0.1989,\n",
      "         0.8577, 0.0459, 0.3250, 0.9072, 0.5292, 0.5516, 0.1104, 0.8641, 0.4524,\n",
      "         0.3744, 0.9315, 0.3191, 0.1173, 0.9197, 0.4733, 0.4101, 0.2150, 0.1181,\n",
      "         0.8252, 0.8376, 0.8420, 0.2764, 0.6688, 0.8298, 0.5111, 0.8353, 0.8896,\n",
      "         0.8433, 0.1446, 0.9291, 0.7288, 0.0598, 0.1165, 0.4630, 0.0685, 0.2972,\n",
      "         0.8537, 0.0675, 0.1736, 0.1546, 0.4635, 0.7815, 0.0562, 0.8369, 0.4813,\n",
      "         0.5733, 0.9100, 0.8843, 0.9386, 0.9072, 0.6633, 0.0843, 0.1600, 0.1407,\n",
      "         0.8641, 0.9059, 0.3290, 0.8604, 0.7114, 0.8529, 0.8773, 0.8458],\n",
      "        [0.8286, 0.8739, 0.7916, 0.9312, 0.8256, 0.6691, 0.9214, 0.5107, 0.3763,\n",
      "         0.7541, 0.8381, 0.9578, 0.0182, 0.7947, 0.6703, 0.3914, 0.3419, 0.3863,\n",
      "         0.8835, 0.5734, 0.0788, 0.8390, 0.2716, 0.3566, 0.2217, 0.1886, 0.4570,\n",
      "         0.5124, 0.8497, 0.8704, 0.6407, 0.4869, 0.1945, 0.5812, 0.1252, 0.0241,\n",
      "         0.4424, 0.5566, 0.2606, 0.9481, 0.7075, 0.6377, 0.9480, 0.2041, 0.6324,\n",
      "         0.6337, 0.9182, 0.7358, 0.5566, 0.2315, 0.8204, 0.1949, 0.7851, 0.5735,\n",
      "         0.6616, 0.6660, 0.6358, 0.8910, 0.5408, 0.5342, 0.1776, 0.8665, 0.9227,\n",
      "         0.7852, 0.1007, 0.2007, 0.7340, 0.8104, 0.9368, 0.4971, 0.1939, 0.3801,\n",
      "         0.9203, 0.1081, 0.4174, 0.7905, 0.3529, 0.8586, 0.3659, 0.9580, 0.9543,\n",
      "         0.1370, 0.8570, 0.6803, 0.4633, 0.9477, 0.3700, 0.5944, 0.2398, 0.3544,\n",
      "         0.2343, 0.7615, 0.8343, 0.4652, 0.8523, 0.8685, 0.7465, 0.7345, 0.3795,\n",
      "         0.8947, 0.4238, 0.8636, 0.4220, 0.3514, 0.2764, 0.8176, 0.2053, 0.4110,\n",
      "         0.5963, 0.2585, 0.5591, 0.1495, 0.2599, 0.4732, 0.0959, 0.7655, 0.3618,\n",
      "         0.8920, 0.8490, 0.7096, 0.9367, 0.7899, 0.5770, 0.3527, 0.2944, 0.6014,\n",
      "         0.4496, 0.5322, 0.9304, 0.9531, 0.3350, 0.3698, 0.7402, 0.8924]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[85349, 2048], edge_index=[2, 768141], y=[85349, 2], pos=[85349, 2], censor=[4], duration=[4], batch=[85349], ptr=[5])\n",
      "Data[3]:  tensor([[1.0000, 0.4307, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.1145, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.8597, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.2844, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  25\n",
      "Data[0]:  tensor([[57.8460,  5.5456,  0.0000,  5.7622,  0.0000,  5.9405,  0.0000,  0.6644,\n",
      "          0.9282,  0.0000,  9.9126,  0.0000,  9.9698,  3.1152,  0.0789,  0.1403,\n",
      "          0.0963],\n",
      "        [73.7008,  2.4837,  5.0823,  5.6592,  0.0000,  1.7289,  0.0000,  3.6596,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  3.6801,  1.2975,  0.8122,  0.5237,\n",
      "          1.3719],\n",
      "        [61.3703,  5.8863,  0.0000,  6.5615,  0.0000,  1.8614,  0.0000,  3.7958,\n",
      "          0.9421,  0.0000,  0.0000,  0.0000,  8.4631,  1.3064,  0.0000,  0.0000,\n",
      "          9.8133],\n",
      "        [61.8227,  5.3264,  4.2147,  7.5518,  0.0000,  2.0586,  0.0000,  3.7247,\n",
      "          1.0865,  0.0000,  1.5524,  0.0000,  5.0045,  1.8527,  1.1269,  0.3770,\n",
      "          4.3012]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.6661, 0.9426, 0.8925, 0.8873, 0.8208, 0.8251, 0.9034, 0.4612, 0.6110,\n",
      "         0.7615, 0.7128, 0.7386, 0.0343, 0.7528, 0.6363, 0.4105, 0.4801, 0.6109,\n",
      "         0.8529, 0.4561, 0.0752, 0.7237, 0.3418, 0.3094, 0.2140, 0.2535, 0.6927,\n",
      "         0.6394, 0.9523, 0.8478, 0.5539, 0.5712, 0.2577, 0.4870, 0.1730, 0.0461,\n",
      "         0.5341, 0.6137, 0.4605, 0.8257, 0.7554, 0.6068, 0.6279, 0.2485, 0.7071,\n",
      "         0.6938, 0.7259, 0.7346, 0.1717, 0.2192, 0.7573, 0.1522, 0.7090, 0.5630,\n",
      "         0.8797, 0.5813, 0.5764, 0.7337, 0.6437, 0.5273, 0.2834, 0.4904, 0.8947,\n",
      "         0.7441, 0.1988, 0.3504, 0.7941, 0.7175, 0.9447, 0.5609, 0.4772, 0.2515,\n",
      "         0.8825, 0.1390, 0.5318, 0.8382, 0.3258, 0.8101, 0.0617, 0.9429, 0.9444,\n",
      "         0.3244, 0.8394, 0.3634, 0.5068, 0.9360, 0.3570, 0.4759, 0.1502, 0.2735,\n",
      "         0.5281, 0.5897, 0.8433, 0.6228, 0.6998, 0.7874, 0.7403, 0.6067, 0.5504,\n",
      "         0.7229, 0.3581, 0.7613, 0.6664, 0.1312, 0.1927, 0.8772, 0.1395, 0.6602,\n",
      "         0.5224, 0.0898, 0.2501, 0.3621, 0.5270, 0.5712, 0.0878, 0.6387, 0.2181,\n",
      "         0.6722, 0.6909, 0.7187, 0.9261, 0.7996, 0.6599, 0.4891, 0.1924, 0.4616,\n",
      "         0.5554, 0.7561, 0.8223, 0.9579, 0.6467, 0.7709, 0.6866, 0.8024],\n",
      "        [0.8141, 0.9569, 0.9832, 0.9533, 0.9394, 0.9511, 0.9136, 0.8135, 0.3341,\n",
      "         0.5450, 0.9416, 0.4719, 0.0132, 0.9467, 0.9146, 0.4558, 0.0917, 0.2879,\n",
      "         0.8453, 0.1843, 0.0700, 0.4592, 0.4193, 0.1372, 0.0801, 0.1906, 0.2348,\n",
      "         0.7004, 0.9523, 0.9028, 0.8176, 0.5373, 0.1244, 0.3594, 0.0758, 0.0287,\n",
      "         0.5841, 0.6371, 0.2267, 0.9360, 0.6345, 0.4592, 0.9391, 0.2994, 0.2005,\n",
      "         0.2265, 0.9184, 0.2418, 0.1049, 0.1624, 0.5189, 0.4374, 0.9154, 0.5957,\n",
      "         0.7231, 0.3929, 0.2827, 0.8256, 0.6436, 0.4057, 0.0747, 0.7500, 0.7057,\n",
      "         0.7639, 0.0559, 0.4820, 0.5469, 0.8094, 0.9431, 0.5555, 0.5338, 0.1536,\n",
      "         0.9059, 0.0773, 0.5342, 0.9289, 0.0421, 0.4711, 0.0511, 0.9526, 0.9425,\n",
      "         0.1386, 0.5329, 0.4455, 0.1329, 0.9465, 0.2512, 0.4225, 0.0997, 0.1666,\n",
      "         0.4625, 0.7050, 0.8614, 0.5130, 0.3311, 0.5042, 0.8350, 0.5848, 0.4327,\n",
      "         0.3501, 0.1987, 0.8267, 0.6318, 0.0592, 0.1859, 0.8097, 0.0949, 0.2772,\n",
      "         0.3877, 0.0661, 0.1373, 0.1524, 0.1166, 0.6512, 0.0640, 0.6026, 0.2449,\n",
      "         0.7425, 0.9018, 0.8205, 0.9313, 0.3809, 0.5202, 0.0490, 0.0909, 0.1293,\n",
      "         0.6755, 0.8333, 0.7661, 0.9273, 0.1811, 0.2084, 0.7628, 0.9294],\n",
      "        [0.9192, 0.9795, 0.9893, 0.7697, 0.7116, 0.6449, 0.9833, 0.5967, 0.6925,\n",
      "         0.4932, 0.9637, 0.5212, 0.1563, 0.9119, 0.9133, 0.4353, 0.6191, 0.3274,\n",
      "         0.8851, 0.2284, 0.0688, 0.9031, 0.6043, 0.4930, 0.4960, 0.2532, 0.3962,\n",
      "         0.7930, 0.9293, 0.8693, 0.8133, 0.7549, 0.1185, 0.6666, 0.0713, 0.0411,\n",
      "         0.5954, 0.5162, 0.4634, 0.9427, 0.9595, 0.3962, 0.7412, 0.2309, 0.3343,\n",
      "         0.6385, 0.9305, 0.3965, 0.3531, 0.2736, 0.6801, 0.6279, 0.8942, 0.4163,\n",
      "         0.6328, 0.4104, 0.4058, 0.8450, 0.4860, 0.7118, 0.0630, 0.6321, 0.7068,\n",
      "         0.7212, 0.1738, 0.3963, 0.6540, 0.8792, 0.9147, 0.6050, 0.4887, 0.5181,\n",
      "         0.9452, 0.0775, 0.6041, 0.8510, 0.4928, 0.8782, 0.2653, 0.9616, 0.9357,\n",
      "         0.1266, 0.4716, 0.4226, 0.1402, 0.9646, 0.3561, 0.5282, 0.1219, 0.1581,\n",
      "         0.4270, 0.4961, 0.8341, 0.6226, 0.7659, 0.6070, 0.7478, 0.5678, 0.3839,\n",
      "         0.5897, 0.4630, 0.9330, 0.6189, 0.1407, 0.4317, 0.4508, 0.4107, 0.4076,\n",
      "         0.4517, 0.5805, 0.4789, 0.1386, 0.4912, 0.6466, 0.0365, 0.8059, 0.2190,\n",
      "         0.9488, 0.6890, 0.8028, 0.9437, 0.4637, 0.4443, 0.2571, 0.1418, 0.1778,\n",
      "         0.3352, 0.6003, 0.9564, 0.9677, 0.2293, 0.2248, 0.6757, 0.6829],\n",
      "        [0.6701, 0.9690, 0.9014, 0.8489, 0.8706, 0.8117, 0.9747, 0.4385, 0.6654,\n",
      "         0.4461, 0.8562, 0.9346, 0.2253, 0.9321, 0.8938, 0.3564, 0.0943, 0.4178,\n",
      "         0.4361, 0.7833, 0.0765, 0.8599, 0.3603, 0.2810, 0.5614, 0.2272, 0.3726,\n",
      "         0.7952, 0.9466, 0.8709, 0.4928, 0.5537, 0.1787, 0.3413, 0.0850, 0.0485,\n",
      "         0.7314, 0.5892, 0.5302, 0.9188, 0.6467, 0.7696, 0.6462, 0.4430, 0.7643,\n",
      "         0.6437, 0.7821, 0.7840, 0.2258, 0.2237, 0.7280, 0.0771, 0.8318, 0.6279,\n",
      "         0.8974, 0.5002, 0.4293, 0.6568, 0.8739, 0.7014, 0.1761, 0.5677, 0.7064,\n",
      "         0.7960, 0.1638, 0.2401, 0.6777, 0.6796, 0.7431, 0.5300, 0.1747, 0.2447,\n",
      "         0.9249, 0.1505, 0.1423, 0.8706, 0.4742, 0.8432, 0.1298, 0.9763, 0.8558,\n",
      "         0.1464, 0.8570, 0.3949, 0.1843, 0.9547, 0.3269, 0.4982, 0.1142, 0.2925,\n",
      "         0.2380, 0.7274, 0.8397, 0.4060, 0.5958, 0.7101, 0.8945, 0.5763, 0.3482,\n",
      "         0.8394, 0.4793, 0.6804, 0.5262, 0.2392, 0.2186, 0.7441, 0.1690, 0.2898,\n",
      "         0.4205, 0.0712, 0.5871, 0.1159, 0.6458, 0.4782, 0.0796, 0.5183, 0.2406,\n",
      "         0.8698, 0.5665, 0.7963, 0.9163, 0.4895, 0.5807, 0.0671, 0.1544, 0.2607,\n",
      "         0.6743, 0.7968, 0.8474, 0.9621, 0.6712, 0.6316, 0.6146, 0.8052]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[92186, 2048], edge_index=[2, 829674], y=[92186, 2], pos=[92186, 2], censor=[4], duration=[4], batch=[92186], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -0.6104,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.7902,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000, -1.0688,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.5601,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  26\n",
      "Data[0]:  tensor([[80.6719,  2.2538,  6.2085,  4.0176,  0.0000,  0.8186,  0.0000,  0.0000,\n",
      "          1.2648,  0.0000,  0.0000,  0.0000,  1.8402,  1.9933,  0.4270,  0.3492,\n",
      "          0.1549],\n",
      "        [53.9056,  5.4602,  3.9773,  8.8118,  0.3172,  3.4108,  0.0000,  0.0000,\n",
      "          6.1128,  0.0000,  1.6640,  0.0000, 10.2163,  3.1485,  0.5077,  0.6556,\n",
      "          1.8121],\n",
      "        [65.9255,  6.9805,  1.8958,  7.2313,  0.0000,  2.5002,  0.0000,  0.3535,\n",
      "          1.6050,  0.0000,  3.2868,  0.0000,  5.7417,  2.3982,  0.7139,  0.5795,\n",
      "          0.7881],\n",
      "        [85.1781,  4.0856,  3.4698,  2.7223,  0.0000,  1.0746,  0.0000,  2.5407,\n",
      "          0.5547,  0.0000,  0.0000,  0.0000,  0.0000,  0.3742,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7508, 0.9759, 0.9903, 0.8661, 0.9386, 0.9683, 0.9849, 0.8610, 0.5288,\n",
      "         0.8238, 0.9060, 0.3495, 0.0640, 0.9559, 0.7469, 0.3110, 0.0818, 0.5339,\n",
      "         0.6506, 0.8016, 0.0860, 0.8619, 0.2849, 0.0831, 0.1536, 0.1529, 0.1756,\n",
      "         0.7304, 0.7948, 0.8855, 0.7961, 0.3685, 0.5575, 0.6724, 0.0910, 0.0385,\n",
      "         0.6297, 0.7416, 0.6163, 0.5839, 0.8057, 0.7605, 0.9099, 0.1610, 0.8473,\n",
      "         0.4809, 0.3875, 0.9014, 0.7414, 0.1280, 0.4632, 0.1553, 0.7975, 0.7791,\n",
      "         0.8746, 0.7115, 0.2807, 0.8777, 0.5862, 0.6735, 0.0616, 0.7068, 0.7845,\n",
      "         0.8304, 0.4561, 0.5314, 0.8003, 0.6554, 0.9464, 0.7510, 0.1575, 0.4506,\n",
      "         0.8893, 0.7675, 0.3445, 0.9093, 0.6846, 0.7099, 0.4656, 0.9589, 0.9242,\n",
      "         0.5261, 0.9218, 0.3981, 0.2411, 0.9647, 0.4318, 0.4494, 0.1084, 0.1476,\n",
      "         0.7628, 0.8701, 0.8664, 0.6936, 0.5922, 0.6107, 0.8533, 0.5299, 0.3303,\n",
      "         0.7893, 0.1464, 0.8897, 0.7869, 0.1484, 0.1222, 0.4919, 0.0744, 0.4482,\n",
      "         0.5154, 0.1102, 0.4959, 0.5055, 0.8229, 0.8028, 0.0486, 0.8732, 0.1276,\n",
      "         0.7293, 0.9162, 0.8279, 0.9557, 0.9502, 0.8350, 0.3625, 0.1638, 0.2776,\n",
      "         0.8903, 0.8353, 0.9186, 0.9328, 0.8197, 0.8918, 0.3432, 0.9233],\n",
      "        [0.7565, 0.9630, 0.9204, 0.9733, 0.9179, 0.9510, 0.9863, 0.7810, 0.8502,\n",
      "         0.5706, 0.9454, 0.8933, 0.0179, 0.8736, 0.9117, 0.5533, 0.5789, 0.3057,\n",
      "         0.7556, 0.5172, 0.0531, 0.8284, 0.3397, 0.2559, 0.4738, 0.2797, 0.5302,\n",
      "         0.7152, 0.8663, 0.8733, 0.5680, 0.6027, 0.5585, 0.6343, 0.0664, 0.0247,\n",
      "         0.6887, 0.6585, 0.4107, 0.8988, 0.7416, 0.7553, 0.8658, 0.1747, 0.8868,\n",
      "         0.7210, 0.7944, 0.8986, 0.5605, 0.2123, 0.8183, 0.2625, 0.7980, 0.6485,\n",
      "         0.8267, 0.5757, 0.7859, 0.7585, 0.6682, 0.6056, 0.0815, 0.6541, 0.9255,\n",
      "         0.8501, 0.2470, 0.5373, 0.7025, 0.8595, 0.9421, 0.7676, 0.1491, 0.4824,\n",
      "         0.8876, 0.0880, 0.5191, 0.8833, 0.6453, 0.6716, 0.5048, 0.8329, 0.8786,\n",
      "         0.1386, 0.8213, 0.5606, 0.2679, 0.9491, 0.4622, 0.5153, 0.0770, 0.2311,\n",
      "         0.6544, 0.7465, 0.8183, 0.4105, 0.6566, 0.8123, 0.6993, 0.7060, 0.5747,\n",
      "         0.8504, 0.4983, 0.8835, 0.7916, 0.1425, 0.3749, 0.8538, 0.3874, 0.7588,\n",
      "         0.5805, 0.0439, 0.1447, 0.2716, 0.7089, 0.7140, 0.0492, 0.8321, 0.1023,\n",
      "         0.7411, 0.7187, 0.7797, 0.9342, 0.7006, 0.5843, 0.2905, 0.1619, 0.1929,\n",
      "         0.7080, 0.8506, 0.9150, 0.9525, 0.3699, 0.4631, 0.7766, 0.9477],\n",
      "        [0.8658, 0.9698, 0.9853, 0.8911, 0.8235, 0.9151, 0.9669, 0.6700, 0.7664,\n",
      "         0.5839, 0.8163, 0.5587, 0.0196, 0.9078, 0.9309, 0.4591, 0.4408, 0.3779,\n",
      "         0.7699, 0.7675, 0.0814, 0.9297, 0.5247, 0.2307, 0.1515, 0.2216, 0.6654,\n",
      "         0.7458, 0.7977, 0.9032, 0.7334, 0.7527, 0.3896, 0.6583, 0.1257, 0.0471,\n",
      "         0.8031, 0.6716, 0.2897, 0.8629, 0.6619, 0.7995, 0.9310, 0.2964, 0.7867,\n",
      "         0.3337, 0.5330, 0.8322, 0.7180, 0.1874, 0.8143, 0.1257, 0.8187, 0.6935,\n",
      "         0.9252, 0.7119, 0.7796, 0.6903, 0.9281, 0.6116, 0.1790, 0.4864, 0.9259,\n",
      "         0.8120, 0.0906, 0.4947, 0.6026, 0.8112, 0.9602, 0.7767, 0.1128, 0.3289,\n",
      "         0.9214, 0.0895, 0.4798, 0.8881, 0.1048, 0.7854, 0.2979, 0.9570, 0.4601,\n",
      "         0.1410, 0.9182, 0.5618, 0.5419, 0.9327, 0.5772, 0.5068, 0.1346, 0.2164,\n",
      "         0.4311, 0.8144, 0.8536, 0.3753, 0.6108, 0.8400, 0.4801, 0.8121, 0.3879,\n",
      "         0.7483, 0.2844, 0.8683, 0.7640, 0.0857, 0.2421, 0.5620, 0.0963, 0.6693,\n",
      "         0.8352, 0.2762, 0.5554, 0.1741, 0.6162, 0.6933, 0.0727, 0.7571, 0.1542,\n",
      "         0.5772, 0.8701, 0.7769, 0.8528, 0.8552, 0.3628, 0.0863, 0.2577, 0.3014,\n",
      "         0.9066, 0.8485, 0.5122, 0.9670, 0.6222, 0.7672, 0.7575, 0.8223],\n",
      "        [0.3425, 0.5077, 0.6617, 0.4832, 0.3870, 0.8409, 0.7455, 0.1063, 0.3451,\n",
      "         0.4155, 0.5713, 0.2627, 0.0129, 0.4267, 0.6436, 0.2550, 0.3547, 0.1877,\n",
      "         0.7984, 0.3697, 0.0993, 0.7015, 0.7510, 0.1097, 0.6208, 0.2112, 0.1253,\n",
      "         0.5103, 0.6610, 0.8335, 0.1880, 0.6509, 0.1454, 0.5979, 0.0897, 0.0466,\n",
      "         0.1461, 0.7557, 0.3370, 0.7136, 0.9421, 0.1670, 0.8008, 0.2746, 0.1682,\n",
      "         0.2799, 0.8111, 0.2141, 0.7635, 0.1382, 0.6264, 0.2797, 0.3807, 0.7616,\n",
      "         0.7075, 0.3807, 0.1829, 0.9369, 0.2300, 0.7776, 0.0581, 0.4660, 0.4779,\n",
      "         0.5727, 0.0856, 0.4527, 0.7800, 0.7405, 0.2829, 0.1791, 0.4936, 0.4391,\n",
      "         0.8698, 0.1035, 0.7617, 0.6948, 0.7916, 0.9077, 0.3186, 0.9612, 0.9581,\n",
      "         0.0851, 0.4767, 0.6663, 0.2626, 0.9530, 0.1465, 0.4824, 0.1796, 0.1497,\n",
      "         0.1006, 0.3073, 0.6666, 0.2003, 0.6574, 0.1942, 0.9163, 0.1855, 0.1213,\n",
      "         0.3683, 0.3831, 0.4210, 0.3820, 0.0674, 0.6046, 0.3966, 0.0773, 0.1811,\n",
      "         0.1074, 0.0999, 0.1928, 0.1644, 0.1921, 0.2689, 0.0478, 0.2900, 0.5077,\n",
      "         0.7774, 0.2901, 0.8785, 0.6622, 0.1583, 0.8994, 0.0689, 0.1220, 0.1513,\n",
      "         0.3446, 0.4998, 0.9548, 0.9433, 0.1609, 0.1420, 0.2116, 0.5740]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[68231, 2048], edge_index=[2, 614079], y=[68231, 2], pos=[68231, 2], censor=[4], duration=[4], batch=[68231], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.1722,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.6693,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.3655,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.2043,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  27\n",
      "Data[0]:  tensor([[4.8950e+01, 4.8179e+00, 1.5071e+00, 7.9917e+00, 0.0000e+00, 3.7549e+00,\n",
      "         0.0000e+00, 7.1202e-01, 3.4448e+00, 0.0000e+00, 7.6873e+00, 0.0000e+00,\n",
      "         9.1031e+00, 3.0462e+00, 1.0841e+00, 1.1893e+00, 6.7114e+00],\n",
      "        [6.3513e+01, 8.5597e+00, 4.0462e-02, 5.6545e+00, 0.0000e+00, 3.7622e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6306e+00, 7.4314e+00, 0.0000e+00,\n",
      "         4.4329e+00, 2.9757e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.5642e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9939e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6831e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.9216e-01, 1.0684e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.5333e+01, 1.1105e+00, 5.4246e+00, 2.7706e+00, 0.0000e+00, 5.4532e-01,\n",
      "         0.0000e+00, 0.0000e+00, 7.9344e-02, 0.0000e+00, 1.7992e-01, 5.8436e-01,\n",
      "         9.2570e-01, 1.3544e+00, 1.6186e+00, 7.3805e-02, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7950, 0.9469, 0.9511, 0.8949, 0.8349, 0.8432, 0.8797, 0.5393, 0.8656,\n",
      "         0.5502, 0.7997, 0.4860, 0.0226, 0.9162, 0.9359, 0.5202, 0.4965, 0.3815,\n",
      "         0.9195, 0.5622, 0.0578, 0.7674, 0.4781, 0.4098, 0.3784, 0.2957, 0.7722,\n",
      "         0.7173, 0.9495, 0.8761, 0.6833, 0.6726, 0.2097, 0.8655, 0.0911, 0.0247,\n",
      "         0.8894, 0.5277, 0.5373, 0.9171, 0.8927, 0.6393, 0.9125, 0.2751, 0.7603,\n",
      "         0.5648, 0.8626, 0.8155, 0.3127, 0.2926, 0.8059, 0.0756, 0.7449, 0.4844,\n",
      "         0.7896, 0.5082, 0.5381, 0.8415, 0.6736, 0.5892, 0.1424, 0.7434, 0.7625,\n",
      "         0.8032, 0.6265, 0.2705, 0.8351, 0.8279, 0.9317, 0.5197, 0.2255, 0.5394,\n",
      "         0.8863, 0.0820, 0.3800, 0.9165, 0.0602, 0.8382, 0.1771, 0.9609, 0.9368,\n",
      "         0.2417, 0.6552, 0.5345, 0.4745, 0.9369, 0.4163, 0.6602, 0.0995, 0.2846,\n",
      "         0.3387, 0.6606, 0.7937, 0.3582, 0.7193, 0.6773, 0.7583, 0.6028, 0.7144,\n",
      "         0.9160, 0.5508, 0.7055, 0.6939, 0.0611, 0.3080, 0.8758, 0.3086, 0.5107,\n",
      "         0.5039, 0.0635, 0.2569, 0.2489, 0.4909, 0.5520, 0.0533, 0.7474, 0.1754,\n",
      "         0.8907, 0.6497, 0.7960, 0.9078, 0.9011, 0.5772, 0.1811, 0.2505, 0.2853,\n",
      "         0.7521, 0.7364, 0.9158, 0.9577, 0.3199, 0.3645, 0.6839, 0.9072],\n",
      "        [0.7047, 0.9845, 0.9904, 0.9121, 0.8108, 0.2828, 0.9522, 0.5188, 0.4812,\n",
      "         0.8542, 0.9345, 0.5384, 0.0235, 0.9583, 0.8562, 0.2757, 0.1793, 0.3516,\n",
      "         0.6972, 0.7076, 0.0601, 0.9122, 0.4290, 0.2247, 0.3487, 0.2495, 0.7956,\n",
      "         0.8493, 0.8932, 0.8995, 0.4436, 0.6602, 0.2046, 0.6595, 0.1860, 0.0243,\n",
      "         0.8184, 0.6940, 0.7533, 0.8665, 0.8822, 0.8118, 0.7756, 0.2157, 0.8243,\n",
      "         0.5078, 0.8256, 0.8342, 0.3574, 0.2270, 0.6959, 0.1027, 0.8612, 0.7346,\n",
      "         0.9284, 0.6912, 0.7754, 0.7281, 0.8929, 0.4297, 0.2694, 0.7445, 0.8712,\n",
      "         0.8434, 0.5842, 0.3671, 0.8846, 0.8238, 0.9449, 0.5804, 0.5798, 0.4966,\n",
      "         0.9073, 0.6498, 0.3861, 0.8860, 0.5959, 0.8138, 0.1033, 0.9374, 0.7237,\n",
      "         0.6446, 0.8786, 0.4213, 0.2625, 0.9583, 0.3768, 0.5165, 0.1345, 0.2650,\n",
      "         0.4775, 0.8703, 0.8795, 0.3526, 0.5208, 0.6979, 0.8616, 0.8309, 0.7397,\n",
      "         0.7013, 0.2920, 0.8605, 0.7157, 0.0855, 0.1863, 0.8071, 0.1299, 0.5686,\n",
      "         0.8112, 0.0735, 0.1877, 0.1393, 0.7283, 0.6963, 0.0941, 0.7948, 0.2053,\n",
      "         0.7117, 0.8590, 0.8127, 0.9328, 0.9175, 0.8233, 0.3826, 0.2433, 0.2279,\n",
      "         0.8978, 0.8415, 0.9086, 0.9538, 0.7992, 0.8928, 0.5050, 0.8895],\n",
      "        [0.9555, 0.9624, 0.9797, 0.9126, 0.9111, 0.9512, 0.9688, 0.8762, 0.7039,\n",
      "         0.0694, 0.8001, 0.9804, 0.0141, 0.9021, 0.6221, 0.5226, 0.0677, 0.1988,\n",
      "         0.1885, 0.5184, 0.0767, 0.8610, 0.1399, 0.1079, 0.0877, 0.1563, 0.7602,\n",
      "         0.7123, 0.2254, 0.8356, 0.8307, 0.6242, 0.1344, 0.0815, 0.0788, 0.0223,\n",
      "         0.7198, 0.4931, 0.1557, 0.2025, 0.0930, 0.6521, 0.9518, 0.1420, 0.5709,\n",
      "         0.1491, 0.2567, 0.8901, 0.1782, 0.1336, 0.8531, 0.0837, 0.6550, 0.6588,\n",
      "         0.9034, 0.5825, 0.7134, 0.2834, 0.8931, 0.2686, 0.0609, 0.1619, 0.9532,\n",
      "         0.5636, 0.0741, 0.1617, 0.1311, 0.7717, 0.9414, 0.6928, 0.2386, 0.1706,\n",
      "         0.7084, 0.0779, 0.1221, 0.8330, 0.0558, 0.1883, 0.0569, 0.3133, 0.3555,\n",
      "         0.0952, 0.9405, 0.1673, 0.0875, 0.3472, 0.5984, 0.1829, 0.0995, 0.1372,\n",
      "         0.9282, 0.8193, 0.7359, 0.2394, 0.1666, 0.7802, 0.1263, 0.5083, 0.8314,\n",
      "         0.9395, 0.1001, 0.8726, 0.6413, 0.0858, 0.1155, 0.6003, 0.0789, 0.7778,\n",
      "         0.8933, 0.0851, 0.1192, 0.1287, 0.6039, 0.7075, 0.0640, 0.7694, 0.1247,\n",
      "         0.1834, 0.8961, 0.4704, 0.9538, 0.8514, 0.1173, 0.0640, 0.1092, 0.0962,\n",
      "         0.9082, 0.8742, 0.3340, 0.5215, 0.7977, 0.8028, 0.8442, 0.7437],\n",
      "        [0.9728, 0.9659, 0.9857, 0.9257, 0.8825, 0.9519, 0.9749, 0.8942, 0.8205,\n",
      "         0.2999, 0.9543, 0.4234, 0.0133, 0.9226, 0.9479, 0.3737, 0.1662, 0.3839,\n",
      "         0.6144, 0.8372, 0.0707, 0.8735, 0.1182, 0.1712, 0.1381, 0.1763, 0.9160,\n",
      "         0.8919, 0.3407, 0.9502, 0.9125, 0.6500, 0.1513, 0.3100, 0.0768, 0.0189,\n",
      "         0.8764, 0.8104, 0.1407, 0.4220, 0.1851, 0.9318, 0.9251, 0.2060, 0.9196,\n",
      "         0.2543, 0.4957, 0.9124, 0.7312, 0.1097, 0.8314, 0.2787, 0.9129, 0.8212,\n",
      "         0.9061, 0.7700, 0.8909, 0.3754, 0.9193, 0.5355, 0.0522, 0.3067, 0.9525,\n",
      "         0.8789, 0.1370, 0.3942, 0.1947, 0.8481, 0.9379, 0.7374, 0.0538, 0.0866,\n",
      "         0.8260, 0.0525, 0.0849, 0.8895, 0.4057, 0.4478, 0.0569, 0.8701, 0.2497,\n",
      "         0.1736, 0.8874, 0.1802, 0.1642, 0.5626, 0.5567, 0.2126, 0.0744, 0.1210,\n",
      "         0.7119, 0.8137, 0.8366, 0.1587, 0.2855, 0.9265, 0.2950, 0.8665, 0.8461,\n",
      "         0.9320, 0.1088, 0.9149, 0.8136, 0.0599, 0.1745, 0.8605, 0.0787, 0.6373,\n",
      "         0.8747, 0.0770, 0.1419, 0.0911, 0.6426, 0.8372, 0.0573, 0.9199, 0.1268,\n",
      "         0.5726, 0.9268, 0.6777, 0.9332, 0.9496, 0.2628, 0.0574, 0.1450, 0.1010,\n",
      "         0.8559, 0.9236, 0.1223, 0.7263, 0.8838, 0.9160, 0.8922, 0.9417]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[102687, 2048], edge_index=[2, 924183], y=[102687, 2], pos=[102687, 2], censor=[4], duration=[4], batch=[102687], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.1263,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.1602,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.6857,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.4740,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  28\n",
      "Data[0]:  tensor([[6.6417e+01, 5.2410e+00, 0.0000e+00, 5.5464e+00, 0.0000e+00, 2.6990e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4332e+00, 0.0000e+00,\n",
      "         7.5685e+00, 3.0905e+00, 4.0280e-01, 5.8399e-01, 1.0173e+00],\n",
      "        [8.0621e+01, 7.2314e+00, 3.5311e+00, 1.5325e+00, 1.9134e+00, 6.5455e-01,\n",
      "         0.0000e+00, 4.5162e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.2348e+01, 3.1726e+00, 4.3945e+00, 8.5343e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.6480e+01, 9.4714e+00, 8.6832e-01, 8.8417e+00, 0.0000e+00, 3.0234e+00,\n",
      "         0.0000e+00, 9.3569e-01, 4.6362e-01, 1.8511e+00, 5.8772e+00, 0.0000e+00,\n",
      "         8.9079e+00, 3.2793e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9552, 0.9813, 0.7271, 0.7227, 0.9248, 0.9622, 0.9283, 0.3497, 0.7808,\n",
      "         0.8940, 0.9660, 0.9686, 0.0777, 0.9173, 0.9339, 0.6396, 0.6352, 0.2610,\n",
      "         0.9317, 0.8379, 0.0609, 0.9090, 0.4533, 0.2496, 0.2896, 0.2479, 0.3538,\n",
      "         0.7036, 0.9702, 0.9050, 0.8461, 0.4147, 0.1806, 0.4802, 0.0857, 0.0417,\n",
      "         0.3573, 0.2468, 0.3711, 0.9100, 0.7386, 0.5158, 0.9344, 0.2949, 0.8583,\n",
      "         0.8504, 0.9124, 0.9190, 0.4715, 0.1532, 0.8165, 0.2364, 0.9090, 0.2820,\n",
      "         0.7651, 0.6904, 0.3645, 0.8857, 0.8456, 0.4052, 0.5761, 0.9206, 0.3429,\n",
      "         0.8850, 0.0889, 0.6499, 0.8668, 0.9153, 0.9413, 0.4159, 0.1213, 0.6384,\n",
      "         0.9339, 0.0828, 0.6122, 0.9085, 0.1977, 0.8325, 0.6176, 0.9664, 0.9410,\n",
      "         0.1356, 0.2879, 0.7470, 0.3932, 0.9672, 0.2235, 0.8616, 0.1246, 0.1538,\n",
      "         0.2510, 0.7362, 0.8754, 0.5276, 0.8870, 0.6734, 0.8679, 0.5150, 0.3863,\n",
      "         0.9521, 0.6028, 0.8734, 0.7671, 0.3785, 0.6382, 0.9043, 0.6588, 0.3083,\n",
      "         0.7600, 0.3061, 0.4627, 0.1336, 0.1915, 0.7182, 0.0430, 0.5972, 0.3178,\n",
      "         0.9018, 0.9117, 0.8749, 0.7112, 0.3949, 0.8311, 0.1157, 0.1542, 0.3841,\n",
      "         0.5294, 0.8709, 0.9575, 0.9625, 0.2710, 0.2691, 0.4656, 0.6497],\n",
      "        [0.4806, 0.8963, 0.3981, 0.8561, 0.0213, 0.0406, 0.3796, 0.1467, 0.3949,\n",
      "         0.7766, 0.4592, 0.1890, 0.0120, 0.2552, 0.7339, 0.1513, 0.7916, 0.2653,\n",
      "         0.2638, 0.6353, 0.2799, 0.2458, 0.6439, 0.1012, 0.1190, 0.1498, 0.3713,\n",
      "         0.2229, 0.8751, 0.8442, 0.4456, 0.2461, 0.1507, 0.6473, 0.1173, 0.0269,\n",
      "         0.1349, 0.4145, 0.1613, 0.5594, 0.3746, 0.3980, 0.3166, 0.1280, 0.3870,\n",
      "         0.8640, 0.8855, 0.6702, 0.1393, 0.1144, 0.1447, 0.0736, 0.4570, 0.6361,\n",
      "         0.5063, 0.2480, 0.1637, 0.8755, 0.5836, 0.2688, 0.6423, 0.6054, 0.1941,\n",
      "         0.3912, 0.7297, 0.2088, 0.6615, 0.3267, 0.9570, 0.1341, 0.1253, 0.1543,\n",
      "         0.2545, 0.0823, 0.1594, 0.1867, 0.7134, 0.7901, 0.7070, 0.8892, 0.8765,\n",
      "         0.2377, 0.7380, 0.2607, 0.7290, 0.9580, 0.1878, 0.3421, 0.1211, 0.4121,\n",
      "         0.1640, 0.3932, 0.3187, 0.2754, 0.3393, 0.2098, 0.9033, 0.5314, 0.1944,\n",
      "         0.5037, 0.3729, 0.6351, 0.1764, 0.0779, 0.6578, 0.3759, 0.0980, 0.2225,\n",
      "         0.5544, 0.0666, 0.1416, 0.0804, 0.1191, 0.1201, 0.0522, 0.2200, 0.1369,\n",
      "         0.1926, 0.1852, 0.8582, 0.7575, 0.2036, 0.9022, 0.1318, 0.1138, 0.3305,\n",
      "         0.4544, 0.3163, 0.9453, 0.9568, 0.1401, 0.1523, 0.4231, 0.3106],\n",
      "        [0.8645, 0.9594, 0.9862, 0.8215, 0.7672, 0.9631, 0.9408, 0.7975, 0.0551,\n",
      "         0.7903, 0.9272, 0.9846, 0.0114, 0.9567, 0.9062, 0.4701, 0.0717, 0.4892,\n",
      "         0.7588, 0.8748, 0.0571, 0.8989, 0.0918, 0.1891, 0.1025, 0.1460, 0.6837,\n",
      "         0.8364, 0.7670, 0.9048, 0.7990, 0.5517, 0.1355, 0.2088, 0.0819, 0.0320,\n",
      "         0.6425, 0.8261, 0.2826, 0.5490, 0.4014, 0.8219, 0.9506, 0.1737, 0.7448,\n",
      "         0.0884, 0.6777, 0.9051, 0.4961, 0.0842, 0.2008, 0.0340, 0.9136, 0.8370,\n",
      "         0.8804, 0.7623, 0.4074, 0.5832, 0.8005, 0.3434, 0.1275, 0.7337, 0.9335,\n",
      "         0.8830, 0.0970, 0.8002, 0.8863, 0.8855, 0.9512, 0.5241, 0.0484, 0.3260,\n",
      "         0.8488, 0.0359, 0.2926, 0.9071, 0.6530, 0.7453, 0.1173, 0.9427, 0.2526,\n",
      "         0.0577, 0.9158, 0.3527, 0.5696, 0.9189, 0.5424, 0.2179, 0.1392, 0.0902,\n",
      "         0.8728, 0.8687, 0.6358, 0.4327, 0.1901, 0.8883, 0.8498, 0.7820, 0.8557,\n",
      "         0.9280, 0.0686, 0.8271, 0.7835, 0.0472, 0.2746, 0.8313, 0.0566, 0.7924,\n",
      "         0.7764, 0.0725, 0.4229, 0.1696, 0.7672, 0.8503, 0.0536, 0.8982, 0.2009,\n",
      "         0.6123, 0.9347, 0.8924, 0.8756, 0.9243, 0.9332, 0.1345, 0.1785, 0.4298,\n",
      "         0.8747, 0.8617, 0.6305, 0.8943, 0.8669, 0.7777, 0.8847, 0.7979],\n",
      "        [0.6824, 0.9501, 0.9789, 0.9168, 0.8239, 0.8133, 0.9415, 0.6933, 0.6103,\n",
      "         0.6546, 0.6484, 0.8865, 0.1678, 0.9365, 0.8577, 0.5546, 0.2997, 0.4476,\n",
      "         0.8634, 0.6007, 0.0824, 0.8255, 0.3970, 0.3874, 0.4012, 0.3275, 0.7502,\n",
      "         0.6986, 0.9141, 0.8605, 0.5801, 0.7297, 0.3019, 0.5424, 0.2184, 0.0452,\n",
      "         0.5212, 0.5143, 0.4236, 0.8826, 0.8837, 0.6677, 0.6748, 0.2555, 0.3732,\n",
      "         0.6339, 0.8092, 0.4981, 0.3920, 0.2263, 0.7326, 0.2811, 0.7374, 0.5115,\n",
      "         0.8229, 0.5720, 0.5760, 0.8176, 0.7313, 0.7417, 0.3300, 0.4934, 0.8644,\n",
      "         0.6950, 0.1027, 0.3937, 0.5363, 0.8776, 0.9596, 0.6438, 0.6058, 0.4460,\n",
      "         0.9073, 0.3136, 0.6431, 0.8297, 0.3139, 0.7952, 0.1896, 0.9397, 0.9391,\n",
      "         0.2717, 0.9515, 0.5509, 0.3304, 0.9529, 0.5695, 0.5165, 0.3211, 0.3476,\n",
      "         0.6370, 0.7925, 0.8391, 0.4212, 0.4997, 0.7708, 0.7693, 0.7550, 0.5016,\n",
      "         0.7891, 0.4744, 0.7530, 0.5715, 0.1228, 0.3693, 0.8309, 0.1889, 0.4812,\n",
      "         0.6028, 0.0949, 0.5309, 0.1804, 0.6370, 0.5248, 0.0814, 0.6346, 0.6413,\n",
      "         0.7859, 0.7208, 0.7900, 0.9072, 0.7192, 0.7087, 0.0969, 0.2497, 0.3501,\n",
      "         0.8283, 0.8253, 0.8982, 0.9560, 0.5182, 0.5541, 0.5845, 0.8558]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[109459, 2048], edge_index=[2, 985131], y=[109459, 2], pos=[109459, 2], censor=[4], duration=[4], batch=[109459], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -1.6077,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.2427,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -0.8267,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.1938,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  29\n",
      "Data[0]:  tensor([[41.7329,  5.1068,  0.0000,  3.1051,  0.0000,  9.1083,  0.0000,  0.0000,\n",
      "          0.0000,  4.5938, 26.3758,  0.0000,  6.6360,  3.3413,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [54.9198,  5.3049,  0.9651,  6.3566,  0.0000,  3.8182,  0.0000,  1.7920,\n",
      "          1.7834,  0.5599, 13.7708,  0.0000,  7.1234,  3.6058,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [55.6304, 11.7955,  2.2150,  4.3991,  0.0000,  7.0591,  0.0000,  0.0000,\n",
      "          0.0000,  3.8305,  7.5848,  0.0000,  2.5763,  1.7224,  1.5576,  0.6405,\n",
      "          0.9886],\n",
      "        [64.1130,  6.1990,  2.1501,  8.2112,  0.0000,  4.2122,  0.0000,  4.8491,\n",
      "          1.5326,  0.0000,  5.0002,  0.0000,  2.0040,  1.7286,  0.0000,  0.0000,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7561, 0.8472, 0.6677, 0.7435, 0.8524, 0.9368, 0.8439, 0.5060, 0.7707,\n",
      "         0.6503, 0.6260, 0.8732, 0.0311, 0.8330, 0.8759, 0.5080, 0.0869, 0.4017,\n",
      "         0.7720, 0.7620, 0.0950, 0.8724, 0.4968, 0.4281, 0.2369, 0.2200, 0.7043,\n",
      "         0.6327, 0.9182, 0.8437, 0.6789, 0.5520, 0.1523, 0.6908, 0.1007, 0.0585,\n",
      "         0.5470, 0.6092, 0.4275, 0.6714, 0.8042, 0.6397, 0.7943, 0.2242, 0.6300,\n",
      "         0.5008, 0.5480, 0.6726, 0.1442, 0.2088, 0.7980, 0.2872, 0.7329, 0.5956,\n",
      "         0.7961, 0.6402, 0.7021, 0.6838, 0.7234, 0.4793, 0.1706, 0.4570, 0.8428,\n",
      "         0.6414, 0.3371, 0.1766, 0.7862, 0.8914, 0.9569, 0.7061, 0.2573, 0.3568,\n",
      "         0.8706, 0.1524, 0.3374, 0.6996, 0.1383, 0.7384, 0.0902, 0.9642, 0.9552,\n",
      "         0.2855, 0.8983, 0.4900, 0.4089, 0.9186, 0.4750, 0.6126, 0.1172, 0.2554,\n",
      "         0.4670, 0.8318, 0.7964, 0.3108, 0.6789, 0.6924, 0.7634, 0.6705, 0.4929,\n",
      "         0.9281, 0.3638, 0.7417, 0.7272, 0.1526, 0.2068, 0.7059, 0.1509, 0.4136,\n",
      "         0.5932, 0.3501, 0.3420, 0.2597, 0.4486, 0.5145, 0.0768, 0.6262, 0.1063,\n",
      "         0.5934, 0.6663, 0.6585, 0.7856, 0.8944, 0.5320, 0.1034, 0.2289, 0.3641,\n",
      "         0.6101, 0.7555, 0.6216, 0.9561, 0.6050, 0.7041, 0.7732, 0.8843],\n",
      "        [0.7720, 0.9702, 0.9734, 0.9032, 0.8636, 0.9335, 0.9709, 0.5543, 0.6743,\n",
      "         0.7153, 0.9095, 0.5746, 0.5220, 0.9306, 0.9029, 0.3654, 0.5017, 0.3311,\n",
      "         0.8497, 0.3989, 0.0736, 0.8693, 0.4913, 0.2507, 0.4950, 0.2164, 0.4866,\n",
      "         0.8328, 0.9431, 0.8408, 0.6466, 0.8028, 0.1469, 0.6972, 0.0958, 0.0245,\n",
      "         0.8625, 0.6059, 0.5456, 0.8820, 0.8652, 0.8364, 0.9217, 0.1871, 0.5223,\n",
      "         0.4666, 0.7675, 0.5438, 0.1075, 0.1964, 0.7532, 0.4172, 0.7400, 0.4536,\n",
      "         0.8782, 0.5342, 0.4535, 0.6923, 0.7192, 0.5069, 0.2565, 0.6037, 0.7358,\n",
      "         0.7920, 0.2941, 0.5029, 0.8148, 0.8573, 0.9251, 0.6430, 0.5732, 0.2758,\n",
      "         0.8811, 0.3732, 0.3489, 0.8906, 0.2383, 0.7431, 0.3493, 0.9392, 0.9403,\n",
      "         0.2529, 0.6844, 0.4918, 0.4178, 0.9451, 0.5075, 0.5662, 0.1004, 0.2007,\n",
      "         0.3657, 0.7424, 0.8261, 0.3249, 0.6562, 0.8192, 0.7676, 0.8427, 0.6574,\n",
      "         0.8687, 0.4370, 0.8902, 0.7068, 0.3511, 0.2580, 0.8607, 0.2943, 0.4173,\n",
      "         0.5179, 0.1046, 0.2130, 0.1451, 0.5488, 0.6429, 0.0510, 0.7654, 0.1760,\n",
      "         0.7330, 0.5224, 0.7344, 0.9385, 0.9342, 0.6345, 0.1048, 0.2735, 0.1975,\n",
      "         0.6457, 0.8356, 0.8625, 0.9198, 0.4156, 0.4818, 0.7077, 0.9231],\n",
      "        [0.8876, 0.9856, 0.9910, 0.9624, 0.8330, 0.9272, 0.9816, 0.7437, 0.7405,\n",
      "         0.3253, 0.8547, 0.6298, 0.0129, 0.9465, 0.8578, 0.5345, 0.0924, 0.4382,\n",
      "         0.5407, 0.7787, 0.0557, 0.8487, 0.3664, 0.2904, 0.2435, 0.2719, 0.8350,\n",
      "         0.8506, 0.7078, 0.8513, 0.7356, 0.7208, 0.2364, 0.3416, 0.1944, 0.0305,\n",
      "         0.6772, 0.6381, 0.3221, 0.6187, 0.4848, 0.8529, 0.9495, 0.1542, 0.7288,\n",
      "         0.3786, 0.5242, 0.8285, 0.3875, 0.2390, 0.8215, 0.0564, 0.8380, 0.6072,\n",
      "         0.9276, 0.6950, 0.8100, 0.7039, 0.8725, 0.4262, 0.3200, 0.5323, 0.8264,\n",
      "         0.8124, 0.1543, 0.4194, 0.4924, 0.7696, 0.9553, 0.6721, 0.3789, 0.2622,\n",
      "         0.7964, 0.1347, 0.2403, 0.8442, 0.6113, 0.5778, 0.0979, 0.8897, 0.5701,\n",
      "         0.2962, 0.8887, 0.3943, 0.2407, 0.9245, 0.5580, 0.5131, 0.1358, 0.2925,\n",
      "         0.7813, 0.8861, 0.8703, 0.3483, 0.4417, 0.7945, 0.5168, 0.8850, 0.7593,\n",
      "         0.8598, 0.3692, 0.9140, 0.6859, 0.1494, 0.2287, 0.8418, 0.1950, 0.6273,\n",
      "         0.8835, 0.0632, 0.2582, 0.1777, 0.6743, 0.6054, 0.1145, 0.7504, 0.2110,\n",
      "         0.4838, 0.8212, 0.7949, 0.9564, 0.8656, 0.4397, 0.0720, 0.2128, 0.2312,\n",
      "         0.8634, 0.8093, 0.7452, 0.9274, 0.7406, 0.7993, 0.8099, 0.9199],\n",
      "        [0.8812, 0.9660, 0.9831, 0.9072, 0.9000, 0.9277, 0.9637, 0.7702, 0.7597,\n",
      "         0.3871, 0.8374, 0.9383, 0.0373, 0.9432, 0.9128, 0.6398, 0.1306, 0.3468,\n",
      "         0.5240, 0.7977, 0.1012, 0.9136, 0.3420, 0.2988, 0.1667, 0.2296, 0.8201,\n",
      "         0.7835, 0.8019, 0.8368, 0.7844, 0.7889, 0.2741, 0.3854, 0.2037, 0.0589,\n",
      "         0.7778, 0.6040, 0.2125, 0.8155, 0.5145, 0.8129, 0.9532, 0.2594, 0.7951,\n",
      "         0.3054, 0.7672, 0.7898, 0.2157, 0.1869, 0.7764, 0.5919, 0.8627, 0.6582,\n",
      "         0.8962, 0.6329, 0.8654, 0.7294, 0.8801, 0.5707, 0.1933, 0.4611, 0.9225,\n",
      "         0.8191, 0.1116, 0.2131, 0.4398, 0.7719, 0.9597, 0.7718, 0.5390, 0.2881,\n",
      "         0.8673, 0.5045, 0.4462, 0.8687, 0.3649, 0.7289, 0.0688, 0.9417, 0.4658,\n",
      "         0.2411, 0.9446, 0.3652, 0.3441, 0.9417, 0.4889, 0.4691, 0.1674, 0.2438,\n",
      "         0.6727, 0.8282, 0.8808, 0.4883, 0.3650, 0.8203, 0.3627, 0.7784, 0.7994,\n",
      "         0.8789, 0.2805, 0.8466, 0.7468, 0.1415, 0.1231, 0.8507, 0.0743, 0.7378,\n",
      "         0.8164, 0.0749, 0.3611, 0.1772, 0.7395, 0.6908, 0.0800, 0.7859, 0.1803,\n",
      "         0.3444, 0.8352, 0.6460, 0.9367, 0.8983, 0.3169, 0.1590, 0.1886, 0.3427,\n",
      "         0.9238, 0.8948, 0.6446, 0.9532, 0.6793, 0.8329, 0.8669, 0.9091]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[96110, 2048], edge_index=[2, 864990], y=[96110, 2], pos=[96110, 2], censor=[4], duration=[4], batch=[96110], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  0.6317,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.6883,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -0.9833,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.4450,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  30\n",
      "Data[0]:  tensor([[77.0109,  1.1829,  0.0000,  2.9330,  0.0000,  1.3031,  0.0000,  0.0000,\n",
      "          9.6846,  0.0000,  0.0000,  0.5159,  5.7129,  1.6568,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [89.3170,  3.7518,  0.0000,  3.5065,  0.0000,  1.3940,  0.0000,  0.0000,\n",
      "          0.0000,  1.0402,  0.3242,  0.0000,  0.0000,  0.6663,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [85.4823,  3.4031,  2.5540,  2.0038,  0.0000,  0.0000,  0.0000,  3.7731,\n",
      "          2.7836,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [31.5415,  9.3135,  0.0000,  7.2593,  1.3182,  4.5544,  0.0000,  3.0213,\n",
      "          1.9759,  3.1146, 14.0135,  0.0000, 12.9449,  2.5854,  0.9807,  1.8117,\n",
      "          5.5651]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.5464, 0.7289, 0.9850, 0.9553, 0.8554, 0.8184, 0.7286, 0.1926, 0.6788,\n",
      "         0.4685, 0.6490, 0.3144, 0.0134, 0.9475, 0.9455, 0.6052, 0.4044, 0.1945,\n",
      "         0.8774, 0.7290, 0.0599, 0.4163, 0.5482, 0.1745, 0.4010, 0.1462, 0.4302,\n",
      "         0.5500, 0.9551, 0.8773, 0.5203, 0.5619, 0.3220, 0.5217, 0.0476, 0.0564,\n",
      "         0.1847, 0.7411, 0.1715, 0.9522, 0.8581, 0.3688, 0.9454, 0.1107, 0.7474,\n",
      "         0.6642, 0.9088, 0.7949, 0.1263, 0.1682, 0.8210, 0.0535, 0.7122, 0.7215,\n",
      "         0.5027, 0.6412, 0.4196, 0.8721, 0.4186, 0.2541, 0.0804, 0.6780, 0.3450,\n",
      "         0.6057, 0.3345, 0.1566, 0.8249, 0.7733, 0.9572, 0.5141, 0.1155, 0.4645,\n",
      "         0.9294, 0.0457, 0.6528, 0.8345, 0.0316, 0.7149, 0.0567, 0.9688, 0.8745,\n",
      "         0.1133, 0.9172, 0.2715, 0.6513, 0.9568, 0.1708, 0.3021, 0.0683, 0.2012,\n",
      "         0.1344, 0.5004, 0.6066, 0.5892, 0.7471, 0.5743, 0.8250, 0.3452, 0.6493,\n",
      "         0.3785, 0.1473, 0.6199, 0.5683, 0.0773, 0.1696, 0.8242, 0.0677, 0.3943,\n",
      "         0.2114, 0.0643, 0.1757, 0.1576, 0.6937, 0.5039, 0.0389, 0.3419, 0.0951,\n",
      "         0.8670, 0.3305, 0.8398, 0.9415, 0.3309, 0.7670, 0.0604, 0.1046, 0.1786,\n",
      "         0.4010, 0.6481, 0.9536, 0.9572, 0.1980, 0.2232, 0.5775, 0.8771],\n",
      "        [0.1215, 0.9672, 0.9743, 0.7742, 0.1420, 0.0223, 0.7452, 0.6869, 0.6771,\n",
      "         0.1436, 0.0621, 0.9878, 0.0081, 0.7653, 0.6874, 0.1472, 0.6862, 0.3793,\n",
      "         0.8894, 0.1590, 0.1023, 0.5615, 0.6727, 0.1611, 0.4131, 0.4066, 0.7599,\n",
      "         0.5140, 0.7430, 0.8119, 0.0979, 0.4347, 0.2463, 0.3243, 0.3500, 0.0208,\n",
      "         0.3946, 0.1341, 0.4223, 0.8483, 0.7229, 0.1701, 0.7098, 0.0688, 0.1262,\n",
      "         0.8114, 0.7973, 0.1947, 0.8978, 0.1766, 0.7740, 0.0321, 0.2558, 0.1698,\n",
      "         0.8089, 0.3073, 0.4092, 0.7601, 0.2605, 0.8026, 0.4371, 0.6030, 0.9380,\n",
      "         0.1718, 0.0524, 0.5884, 0.9111, 0.4409, 0.9504, 0.3070, 0.0749, 0.7163,\n",
      "         0.7048, 0.0364, 0.2168, 0.9062, 0.2713, 0.9217, 0.4660, 0.5278, 0.4921,\n",
      "         0.6526, 0.8193, 0.3492, 0.3626, 0.9519, 0.2781, 0.6022, 0.2289, 0.1340,\n",
      "         0.8096, 0.2496, 0.7046, 0.1488, 0.6124, 0.2228, 0.3352, 0.7026, 0.9062,\n",
      "         0.2972, 0.4832, 0.4618, 0.6363, 0.0435, 0.5338, 0.5465, 0.2570, 0.5394,\n",
      "         0.2085, 0.0548, 0.1327, 0.0986, 0.7811, 0.4052, 0.1793, 0.6854, 0.4271,\n",
      "         0.3152, 0.7247, 0.5182, 0.9691, 0.7944, 0.3854, 0.6965, 0.2496, 0.4565,\n",
      "         0.8416, 0.6397, 0.9276, 0.7407, 0.1257, 0.1193, 0.0788, 0.1536],\n",
      "        [0.5308, 0.9785, 0.9913, 0.3580, 0.9166, 0.6927, 0.9832, 0.8041, 0.8677,\n",
      "         0.2259, 0.9613, 0.4405, 0.0112, 0.9281, 0.9104, 0.2188, 0.2838, 0.1740,\n",
      "         0.5308, 0.5843, 0.0735, 0.7395, 0.5027, 0.0835, 0.2182, 0.1799, 0.5753,\n",
      "         0.8341, 0.7053, 0.6874, 0.5615, 0.7134, 0.0914, 0.1830, 0.0780, 0.0364,\n",
      "         0.5602, 0.6997, 0.1905, 0.6391, 0.1601, 0.9161, 0.9519, 0.1707, 0.2581,\n",
      "         0.3032, 0.8134, 0.4330, 0.6509, 0.1380, 0.8527, 0.0588, 0.9265, 0.7540,\n",
      "         0.9374, 0.6864, 0.6786, 0.4962, 0.9390, 0.1733, 0.0502, 0.5240, 0.9255,\n",
      "         0.8400, 0.0356, 0.1087, 0.2676, 0.7281, 0.9479, 0.7250, 0.1259, 0.1095,\n",
      "         0.8549, 0.0515, 0.2681, 0.9189, 0.2846, 0.8427, 0.2563, 0.9394, 0.4922,\n",
      "         0.1608, 0.9334, 0.2399, 0.0962, 0.9060, 0.3475, 0.2466, 0.1335, 0.1147,\n",
      "         0.7284, 0.6840, 0.8640, 0.1695, 0.2056, 0.7915, 0.1762, 0.8594, 0.8564,\n",
      "         0.9275, 0.1134, 0.9376, 0.8164, 0.0716, 0.0746, 0.3789, 0.0522, 0.6637,\n",
      "         0.9312, 0.1403, 0.1127, 0.1071, 0.1629, 0.6915, 0.0351, 0.5319, 0.1388,\n",
      "         0.6327, 0.8728, 0.3950, 0.9619, 0.9187, 0.1606, 0.0791, 0.0786, 0.1606,\n",
      "         0.9145, 0.8156, 0.7967, 0.9347, 0.7065, 0.4942, 0.3176, 0.7935],\n",
      "        [0.7860, 0.9668, 0.9884, 0.9175, 0.7261, 0.8627, 0.9740, 0.5569, 0.7654,\n",
      "         0.7061, 0.8977, 0.8949, 0.0128, 0.8543, 0.8401, 0.4045, 0.0958, 0.5368,\n",
      "         0.7541, 0.5289, 0.0822, 0.7340, 0.4161, 0.4311, 0.2854, 0.3078, 0.7472,\n",
      "         0.8080, 0.9211, 0.8775, 0.5903, 0.6942, 0.3001, 0.7447, 0.1867, 0.0428,\n",
      "         0.7207, 0.4793, 0.5745, 0.7657, 0.7757, 0.7122, 0.8636, 0.2206, 0.6292,\n",
      "         0.6192, 0.6903, 0.6858, 0.3828, 0.3623, 0.8118, 0.1173, 0.7642, 0.4471,\n",
      "         0.8724, 0.5243, 0.6895, 0.6342, 0.8472, 0.6238, 0.3295, 0.4449, 0.8911,\n",
      "         0.7633, 0.3003, 0.2447, 0.6416, 0.7862, 0.9564, 0.6184, 0.2146, 0.3475,\n",
      "         0.8970, 0.1219, 0.3636, 0.7578, 0.2309, 0.7332, 0.0825, 0.9174, 0.9528,\n",
      "         0.3307, 0.7645, 0.5306, 0.2757, 0.8707, 0.5474, 0.7354, 0.1499, 0.3369,\n",
      "         0.3838, 0.7336, 0.8592, 0.3962, 0.7372, 0.7601, 0.6021, 0.7357, 0.5513,\n",
      "         0.7183, 0.5180, 0.8464, 0.6513, 0.0869, 0.3656, 0.8217, 0.3067, 0.5609,\n",
      "         0.7149, 0.1391, 0.2463, 0.2064, 0.4175, 0.5515, 0.0831, 0.7101, 0.2363,\n",
      "         0.6786, 0.7199, 0.6271, 0.9071, 0.8840, 0.4401, 0.1745, 0.1869, 0.2661,\n",
      "         0.7107, 0.8133, 0.7817, 0.9540, 0.4988, 0.6090, 0.7243, 0.8367]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[84724, 2048], edge_index=[2, 762516], y=[84724, 2], pos=[84724, 2], censor=[4], duration=[4], batch=[84724], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000, -0.3992,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000, -1.2212,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -6.1688,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
      "        [ 1.0000, -1.0920,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n",
      "Batch:  31\n",
      "Data[0]:  tensor([[4.5598e+01, 4.9321e+00, 0.0000e+00, 4.3966e+00, 3.0699e-01, 6.2962e+00,\n",
      "         0.0000e+00, 3.2464e+00, 2.9431e+00, 5.6112e-01, 2.2429e+01, 0.0000e+00,\n",
      "         7.4694e+00, 1.8203e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.9732e+01, 9.0987e+00, 0.0000e+00, 4.4687e+00, 0.0000e+00, 9.3397e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3673e+00, 0.0000e+00,\n",
      "         3.9325e+00, 2.4667e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.1473e+01, 1.7226e+00, 0.0000e+00, 3.2694e+00, 0.0000e+00, 5.5366e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0526e+00, 0.0000e+00,\n",
      "         6.0087e+00, 2.9373e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.7636e+01, 4.7213e+00, 5.1381e+00, 4.1862e+00, 1.9754e-02, 8.6268e-01,\n",
      "         0.0000e+00, 0.0000e+00, 3.4241e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.6609e+00, 1.0066e+00, 8.8450e-01, 6.1099e-02, 4.8027e-01]],\n",
      "       dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.7972, 0.9836, 0.9785, 0.9199, 0.8678, 0.8974, 0.9835, 0.7155, 0.7844,\n",
      "         0.5989, 0.9016, 0.9373, 0.0149, 0.9588, 0.8673, 0.5029, 0.3923, 0.4493,\n",
      "         0.7960, 0.7336, 0.0440, 0.8695, 0.4708, 0.2667, 0.4094, 0.2046, 0.8512,\n",
      "         0.7895, 0.9088, 0.8825, 0.7063, 0.7278, 0.2059, 0.7908, 0.1777, 0.0345,\n",
      "         0.8377, 0.6186, 0.5372, 0.7775, 0.8037, 0.7348, 0.9413, 0.1649, 0.7727,\n",
      "         0.6438, 0.6531, 0.8273, 0.1047, 0.2290, 0.7986, 0.0928, 0.7843, 0.5983,\n",
      "         0.8968, 0.5157, 0.6120, 0.6930, 0.7885, 0.3720, 0.2988, 0.4485, 0.9079,\n",
      "         0.8026, 0.1806, 0.3367, 0.7747, 0.8505, 0.9419, 0.6453, 0.1544, 0.3070,\n",
      "         0.9162, 0.1301, 0.3302, 0.8662, 0.1088, 0.7400, 0.0704, 0.9599, 0.9463,\n",
      "         0.2915, 0.8543, 0.5395, 0.4108, 0.9504, 0.4144, 0.5751, 0.1315, 0.2556,\n",
      "         0.5924, 0.8145, 0.9012, 0.4235, 0.6444, 0.7849, 0.6953, 0.8202, 0.6733,\n",
      "         0.8308, 0.4327, 0.8794, 0.6883, 0.2572, 0.1878, 0.8504, 0.1135, 0.4248,\n",
      "         0.5510, 0.0895, 0.2557, 0.1303, 0.6017, 0.6399, 0.0684, 0.7678, 0.1671,\n",
      "         0.6687, 0.6136, 0.6840, 0.9326, 0.9239, 0.5442, 0.0691, 0.1775, 0.2283,\n",
      "         0.7572, 0.7375, 0.6946, 0.9634, 0.5157, 0.6328, 0.7341, 0.9186],\n",
      "        [0.6086, 0.9794, 0.9890, 0.9196, 0.8359, 0.8733, 0.9821, 0.7919, 0.1936,\n",
      "         0.6611, 0.8239, 0.4947, 0.0139, 0.9273, 0.8028, 0.6130, 0.0589, 0.5364,\n",
      "         0.4954, 0.6797, 0.0765, 0.5009, 0.3144, 0.2182, 0.2342, 0.2189, 0.8614,\n",
      "         0.8235, 0.7950, 0.8911, 0.5505, 0.3244, 0.2629, 0.7669, 0.1406, 0.0533,\n",
      "         0.5530, 0.4024, 0.7086, 0.5054, 0.3518, 0.8428, 0.9479, 0.2415, 0.6077,\n",
      "         0.3338, 0.4784, 0.7963, 0.1643, 0.1687, 0.7823, 0.1050, 0.8292, 0.5603,\n",
      "         0.9349, 0.4779, 0.6976, 0.5938, 0.8633, 0.4307, 0.0772, 0.4362, 0.8153,\n",
      "         0.7356, 0.0680, 0.4036, 0.4975, 0.7172, 0.5078, 0.6196, 0.1499, 0.4870,\n",
      "         0.8947, 0.6624, 0.4563, 0.7699, 0.4314, 0.4609, 0.0844, 0.5804, 0.4864,\n",
      "         0.2010, 0.8698, 0.2641, 0.1571, 0.9316, 0.5462, 0.4166, 0.1764, 0.2683,\n",
      "         0.7768, 0.8254, 0.8686, 0.7654, 0.4485, 0.8469, 0.8161, 0.8056, 0.5909,\n",
      "         0.5709, 0.2750, 0.8991, 0.7385, 0.0851, 0.2256, 0.4555, 0.2052, 0.3062,\n",
      "         0.8615, 0.0768, 0.1584, 0.2242, 0.6993, 0.7287, 0.0784, 0.8257, 0.3951,\n",
      "         0.3888, 0.8308, 0.8264, 0.9634, 0.5090, 0.8153, 0.0748, 0.2106, 0.2295,\n",
      "         0.8780, 0.8418, 0.5061, 0.8285, 0.7386, 0.7825, 0.4416, 0.7848],\n",
      "        [0.6310, 0.5548, 0.4953, 0.9617, 0.9511, 0.8680, 0.9733, 0.3737, 0.5382,\n",
      "         0.8399, 0.6895, 0.4695, 0.0307, 0.9544, 0.5536, 0.6497, 0.0478, 0.2443,\n",
      "         0.8734, 0.4032, 0.0646, 0.8883, 0.2987, 0.0722, 0.1535, 0.1856, 0.3587,\n",
      "         0.5213, 0.9530, 0.8579, 0.5104, 0.7708, 0.1066, 0.5989, 0.0621, 0.0482,\n",
      "         0.4311, 0.7328, 0.3552, 0.8731, 0.6086, 0.4478, 0.5417, 0.1266, 0.8944,\n",
      "         0.3232, 0.8233, 0.8537, 0.0690, 0.1451, 0.7531, 0.0496, 0.6019, 0.7708,\n",
      "         0.6573, 0.5279, 0.2888, 0.6682, 0.4037, 0.5687, 0.0836, 0.5271, 0.5304,\n",
      "         0.8403, 0.0998, 0.1555, 0.6382, 0.8491, 0.9469, 0.4310, 0.0763, 0.1364,\n",
      "         0.8932, 0.0491, 0.4985, 0.9046, 0.0450, 0.6023, 0.0394, 0.9650, 0.9478,\n",
      "         0.1551, 0.3984, 0.3543, 0.2298, 0.9581, 0.2092, 0.4717, 0.1280, 0.1730,\n",
      "         0.2037, 0.7158, 0.8065, 0.2283, 0.3170, 0.5220, 0.6396, 0.3581, 0.5138,\n",
      "         0.9268, 0.1599, 0.8988, 0.7185, 0.0715, 0.1630, 0.8742, 0.0550, 0.2218,\n",
      "         0.2252, 0.1125, 0.1163, 0.1204, 0.8213, 0.7265, 0.0365, 0.5169, 0.2557,\n",
      "         0.5748, 0.5388, 0.7893, 0.8141, 0.8763, 0.5134, 0.0797, 0.1200, 0.2583,\n",
      "         0.7940, 0.7210, 0.8835, 0.9453, 0.8576, 0.8018, 0.5544, 0.8409],\n",
      "        [0.8570, 0.9825, 0.9914, 0.8229, 0.8156, 0.9223, 0.9639, 0.4130, 0.1029,\n",
      "         0.2567, 0.8952, 0.8772, 0.0230, 0.9597, 0.9371, 0.5787, 0.7057, 0.6646,\n",
      "         0.3669, 0.7852, 0.0691, 0.8683, 0.1941, 0.2419, 0.1865, 0.2055, 0.3907,\n",
      "         0.7275, 0.4590, 0.8799, 0.4597, 0.2580, 0.2215, 0.1574, 0.1806, 0.0189,\n",
      "         0.6817, 0.5068, 0.2412, 0.5010, 0.2789, 0.8309, 0.9377, 0.0795, 0.5406,\n",
      "         0.2485, 0.8024, 0.6945, 0.6568, 0.1536, 0.6729, 0.0463, 0.8619, 0.5503,\n",
      "         0.8470, 0.3304, 0.5622, 0.5485, 0.8786, 0.3379, 0.5187, 0.4552, 0.9042,\n",
      "         0.8150, 0.1206, 0.6810, 0.3175, 0.8116, 0.9401, 0.5598, 0.1273, 0.1360,\n",
      "         0.7901, 0.0373, 0.1779, 0.8557, 0.3033, 0.8069, 0.0534, 0.9053, 0.4342,\n",
      "         0.3307, 0.6468, 0.2254, 0.1562, 0.2873, 0.2442, 0.3217, 0.1565, 0.1906,\n",
      "         0.4287, 0.7802, 0.8251, 0.3494, 0.4452, 0.5970, 0.3649, 0.8238, 0.8980,\n",
      "         0.8272, 0.3575, 0.7639, 0.6602, 0.0668, 0.3604, 0.7808, 0.1728, 0.6721,\n",
      "         0.7471, 0.0533, 0.1758, 0.3589, 0.5935, 0.6286, 0.0342, 0.3083, 0.6366,\n",
      "         0.3155, 0.8851, 0.8457, 0.8982, 0.9260, 0.4379, 0.0586, 0.1675, 0.1700,\n",
      "         0.7381, 0.8287, 0.2409, 0.8999, 0.5762, 0.5982, 0.5492, 0.7942]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[77907, 2048], edge_index=[2, 701163], y=[77907, 2], pos=[77907, 2], censor=[4], duration=[4], batch=[77907], ptr=[5])\n",
      "Data[3]:  tensor([[ 1.0000,  0.0792,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000, -1.3205,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.1067,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0115,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  32\n",
      "Data[0]:  tensor([[61.3703,  5.8863,  0.0000,  6.5615,  0.0000,  1.8614,  0.0000,  3.7958,\n",
      "          0.9421,  0.0000,  0.0000,  0.0000,  8.4631,  1.3064,  0.0000,  0.0000,\n",
      "          9.8133],\n",
      "        [50.6579,  8.8478,  0.2112,  5.7599,  0.0000,  7.1246,  0.0000,  2.3557,\n",
      "          0.9785,  0.0000, 11.4859,  0.0000, 10.7248,  1.8536,  0.0000,  0.0000,\n",
      "          0.0000],\n",
      "        [67.1014,  5.2324,  4.3886,  6.3359,  0.0000,  3.5570,  0.0000,  0.6934,\n",
      "          2.1692,  0.0000,  2.8005,  0.0000,  5.0212,  1.2872,  0.8544,  0.2197,\n",
      "          0.3392],\n",
      "        [59.8627, 11.2783,  2.3968,  7.2642,  0.3230,  2.1679,  0.0000,  0.0000,\n",
      "          0.0000,  2.9095,  4.2767,  0.0000,  4.3346,  1.6277,  0.5068,  0.1062,\n",
      "          2.9456]], dtype=torch.float64)\n",
      "Data[1]:  tensor([[0.9192, 0.9795, 0.9893, 0.7697, 0.7116, 0.6449, 0.9833, 0.5967, 0.6925,\n",
      "         0.4932, 0.9637, 0.5212, 0.1563, 0.9119, 0.9133, 0.4353, 0.6191, 0.3274,\n",
      "         0.8851, 0.2284, 0.0688, 0.9031, 0.6043, 0.4930, 0.4960, 0.2532, 0.3962,\n",
      "         0.7930, 0.9293, 0.8693, 0.8133, 0.7549, 0.1185, 0.6666, 0.0713, 0.0411,\n",
      "         0.5954, 0.5162, 0.4634, 0.9427, 0.9595, 0.3962, 0.7412, 0.2309, 0.3343,\n",
      "         0.6385, 0.9305, 0.3965, 0.3531, 0.2736, 0.6801, 0.6279, 0.8942, 0.4163,\n",
      "         0.6328, 0.4104, 0.4058, 0.8450, 0.4860, 0.7118, 0.0630, 0.6321, 0.7068,\n",
      "         0.7212, 0.1738, 0.3963, 0.6540, 0.8792, 0.9147, 0.6050, 0.4887, 0.5181,\n",
      "         0.9452, 0.0775, 0.6041, 0.8510, 0.4928, 0.8782, 0.2653, 0.9616, 0.9357,\n",
      "         0.1266, 0.4716, 0.4226, 0.1402, 0.9646, 0.3561, 0.5282, 0.1219, 0.1581,\n",
      "         0.4270, 0.4961, 0.8341, 0.6226, 0.7659, 0.6070, 0.7478, 0.5678, 0.3839,\n",
      "         0.5897, 0.4630, 0.9330, 0.6189, 0.1407, 0.4317, 0.4508, 0.4107, 0.4076,\n",
      "         0.4517, 0.5805, 0.4789, 0.1386, 0.4912, 0.6466, 0.0365, 0.8059, 0.2190,\n",
      "         0.9488, 0.6890, 0.8028, 0.9437, 0.4637, 0.4443, 0.2571, 0.1418, 0.1778,\n",
      "         0.3352, 0.6003, 0.9564, 0.9677, 0.2293, 0.2248, 0.6757, 0.6829],\n",
      "        [0.7512, 0.9686, 0.9329, 0.8319, 0.8003, 0.8762, 0.9313, 0.6922, 0.6473,\n",
      "         0.5637, 0.8049, 0.8987, 0.0664, 0.9150, 0.8001, 0.3626, 0.2092, 0.3777,\n",
      "         0.6010, 0.6550, 0.0492, 0.8546, 0.3166, 0.2696, 0.1910, 0.1943, 0.6551,\n",
      "         0.7129, 0.8079, 0.8748, 0.6371, 0.6862, 0.2102, 0.5279, 0.0494, 0.0260,\n",
      "         0.7229, 0.5362, 0.4084, 0.5490, 0.5730, 0.7076, 0.9105, 0.2354, 0.5312,\n",
      "         0.5158, 0.6662, 0.5929, 0.3268, 0.2403, 0.7638, 0.0620, 0.7281, 0.5122,\n",
      "         0.8837, 0.6333, 0.6684, 0.5883, 0.7920, 0.4059, 0.2018, 0.5446, 0.9061,\n",
      "         0.7537, 0.1429, 0.3104, 0.5067, 0.7364, 0.9613, 0.6079, 0.1425, 0.2989,\n",
      "         0.8194, 0.2125, 0.2908, 0.7946, 0.0696, 0.5471, 0.0500, 0.9172, 0.7759,\n",
      "         0.1845, 0.8781, 0.4277, 0.2358, 0.9055, 0.5671, 0.5343, 0.1140, 0.2868,\n",
      "         0.6243, 0.7423, 0.8589, 0.3536, 0.6580, 0.7426, 0.5163, 0.7432, 0.6450,\n",
      "         0.7532, 0.4970, 0.7936, 0.6319, 0.0975, 0.1979, 0.8356, 0.0981, 0.5572,\n",
      "         0.7006, 0.0861, 0.2123, 0.1865, 0.5154, 0.5491, 0.1019, 0.6325, 0.2196,\n",
      "         0.6040, 0.7390, 0.4536, 0.9240, 0.7785, 0.3546, 0.0691, 0.1591, 0.3145,\n",
      "         0.7662, 0.7403, 0.7980, 0.9411, 0.6657, 0.7241, 0.7296, 0.8481],\n",
      "        [0.8794, 0.9713, 0.9869, 0.9282, 0.8659, 0.8819, 0.9792, 0.7871, 0.7879,\n",
      "         0.3234, 0.8392, 0.8487, 0.0253, 0.9449, 0.9329, 0.6034, 0.1296, 0.3357,\n",
      "         0.5843, 0.7036, 0.0736, 0.6950, 0.2622, 0.1941, 0.2205, 0.2282, 0.5253,\n",
      "         0.8332, 0.7704, 0.8796, 0.6925, 0.7487, 0.2841, 0.3442, 0.2386, 0.0237,\n",
      "         0.7267, 0.6116, 0.1866, 0.8915, 0.2872, 0.8796, 0.8704, 0.2010, 0.6709,\n",
      "         0.5231, 0.7747, 0.7456, 0.6928, 0.1574, 0.8951, 0.1285, 0.7948, 0.6531,\n",
      "         0.9186, 0.6309, 0.7357, 0.6195, 0.9181, 0.4651, 0.2526, 0.5737, 0.9343,\n",
      "         0.7527, 0.1524, 0.2748, 0.4680, 0.7350, 0.9585, 0.5814, 0.2107, 0.2743,\n",
      "         0.9238, 0.0893, 0.3441, 0.8925, 0.2347, 0.5273, 0.1326, 0.9337, 0.4507,\n",
      "         0.2557, 0.8973, 0.4068, 0.1980, 0.8887, 0.6211, 0.4753, 0.1547, 0.3003,\n",
      "         0.8508, 0.7995, 0.8801, 0.6759, 0.2614, 0.7618, 0.2647, 0.8303, 0.7920,\n",
      "         0.8537, 0.2668, 0.9198, 0.5969, 0.0704, 0.2204, 0.5941, 0.1225, 0.7879,\n",
      "         0.8362, 0.0718, 0.2378, 0.2174, 0.6805, 0.6789, 0.0678, 0.6605, 0.2595,\n",
      "         0.7591, 0.9224, 0.6322, 0.9479, 0.9257, 0.1797, 0.2479, 0.2102, 0.2898,\n",
      "         0.8465, 0.8794, 0.5718, 0.9347, 0.6905, 0.6342, 0.8263, 0.8519],\n",
      "        [0.5574, 0.9053, 0.7490, 0.7243, 0.6455, 0.2292, 0.8894, 0.4735, 0.6779,\n",
      "         0.7531, 0.2708, 0.4332, 0.0285, 0.8673, 0.7125, 0.2572, 0.7009, 0.5926,\n",
      "         0.8773, 0.4953, 0.0864, 0.6655, 0.5785, 0.4793, 0.4599, 0.3282, 0.7532,\n",
      "         0.5402, 0.9655, 0.8579, 0.5681, 0.3639, 0.5247, 0.8119, 0.2584, 0.0822,\n",
      "         0.4057, 0.6315, 0.4479, 0.9347, 0.9272, 0.3739, 0.8668, 0.2820, 0.6429,\n",
      "         0.9123, 0.8861, 0.8841, 0.7142, 0.4055, 0.8578, 0.1452, 0.3549, 0.5973,\n",
      "         0.4102, 0.4325, 0.5843, 0.8969, 0.6622, 0.6123, 0.5864, 0.7747, 0.8860,\n",
      "         0.3469, 0.8487, 0.2162, 0.8636, 0.6269, 0.9455, 0.4184, 0.1976, 0.5710,\n",
      "         0.9415, 0.1146, 0.3861, 0.8375, 0.7850, 0.8906, 0.3936, 0.9466, 0.9367,\n",
      "         0.6973, 0.8889, 0.6313, 0.4618, 0.9516, 0.3777, 0.6535, 0.1876, 0.3705,\n",
      "         0.2662, 0.4971, 0.7364, 0.3884, 0.6508, 0.8127, 0.8651, 0.3140, 0.5733,\n",
      "         0.8488, 0.8154, 0.7674, 0.7708, 0.0889, 0.4255, 0.4770, 0.6556, 0.3378,\n",
      "         0.3873, 0.1068, 0.2236, 0.1805, 0.2050, 0.3374, 0.0719, 0.6917, 0.2653,\n",
      "         0.9376, 0.8087, 0.8387, 0.9239, 0.9087, 0.7708, 0.5964, 0.2436, 0.4971,\n",
      "         0.8519, 0.6565, 0.9556, 0.9639, 0.3505, 0.4072, 0.4357, 0.5059]],\n",
      "       dtype=torch.float64)\n",
      "Data[2]:  DataBatch(x=[104732, 2048], edge_index=[2, 942588], y=[104732, 2], pos=[104732, 2], censor=[4], duration=[4], batch=[104732], ptr=[5])\n",
      "Data[3]:  tensor([[ 0.0000, -1.0688,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.2136,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  1.1444,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.6315,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "____________________________________________\n"
     ]
    }
   ],
   "source": [
    "for batch_idx,data in enumerate(val_loader):\n",
    "    print('Batch: ', batch_idx)\n",
    "    print('Data[0]: ', data[0])\n",
    "    print('Data[1]: ', data[1])\n",
    "    print('Data[2]: ', data[2])\n",
    "    print('Data[3]: ', data[3])\n",
    "    #HiTIMED_data = data[0].to(device).double()\n",
    "    #dnam_data = data[1].to(device)\n",
    "    #wsi_data = data[2]\n",
    "    print('____________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6966252",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107bbd7",
   "metadata": {},
   "source": [
    "#### Define Interaction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b778c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_outer(x):\n",
    "    return torch.einsum('bi,bj->bij',x,x).reshape(x.shape[0],-1)\n",
    "\n",
    "def outer(x,y):\n",
    "    return torch.einsum('bi,bj->bij',x,y).reshape(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2eeea",
   "metadata": {},
   "source": [
    "### WSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac94dfc",
   "metadata": {},
   "source": [
    "- Load Pretrained Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf304434",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_state_dict = torch.load('/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/WSI/Model_Saving/No_Dropout_with_AgeStandSexStage_WSIPhenoInteraction/model_epoch_39.pth', map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12f02be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.lin_l.weight',\n",
       "              tensor([[-0.0084,  0.1024, -0.0935,  ..., -0.0861, -0.0004,  0.0488],\n",
       "                      [-0.0823, -0.0877, -0.0770,  ..., -0.0469, -0.0821,  0.0318],\n",
       "                      [-0.0706, -0.0675, -0.0582,  ..., -0.0568, -0.0832, -0.0468],\n",
       "                      ...,\n",
       "                      [-0.0544, -0.0535,  0.0542,  ..., -0.0831, -0.1057, -0.0549],\n",
       "                      [-0.0582, -0.0863, -0.0457,  ...,  0.0214, -0.0566, -0.0721],\n",
       "                      [ 0.0628, -0.0527, -0.0076,  ...,  0.0333,  0.0475, -0.0329]],\n",
       "                     device='cuda:0')),\n",
       "             ('conv1.lin_l.bias',\n",
       "              tensor([ 1.4507e-03, -6.1996e-04, -4.7271e-04, -1.0241e-03, -4.4189e-04,\n",
       "                       2.0766e-04, -9.4094e-04, -4.0474e-04, -2.0211e-04, -6.9797e-06,\n",
       "                      -1.2518e-03, -2.1925e-04, -1.4888e-03, -8.5834e-04, -9.5103e-04,\n",
       "                       1.1241e-03, -7.8168e-04, -2.4209e-03, -1.8910e-03, -1.4700e-03,\n",
       "                      -1.5231e-03, -4.7852e-04,  1.0257e-03, -3.4122e-04,  1.2126e-03,\n",
       "                       3.7827e-04, -2.7776e-03, -4.6337e-04, -2.2042e-03, -1.4649e-03,\n",
       "                       9.9770e-04,  9.8744e-04, -1.9060e-03, -7.1300e-04, -3.4881e-04,\n",
       "                       1.8411e-03, -1.3203e-03,  3.4329e-04, -1.5503e-03, -1.3813e-03,\n",
       "                      -1.6568e-03,  7.7193e-04,  6.3360e-04, -1.4087e-04, -2.5664e-03,\n",
       "                       3.1726e-03, -1.5083e-03,  1.2507e-03,  1.4508e-03, -5.8831e-04,\n",
       "                      -1.9946e-04,  1.0798e-03, -1.0996e-04, -3.4495e-04, -4.4965e-04,\n",
       "                      -5.1798e-05, -4.4710e-04, -1.5716e-04, -2.7454e-07,  1.0427e-04,\n",
       "                       4.8283e-04, -4.2180e-04, -1.4995e-04,  1.1296e-03, -4.8332e-04,\n",
       "                       7.6965e-04, -3.9708e-04, -8.5739e-04, -5.0759e-04,  1.0005e-03,\n",
       "                      -9.0535e-04, -4.1457e-05, -8.0475e-04, -2.4421e-04, -1.6746e-03,\n",
       "                       1.0649e-03, -1.5342e-03, -9.9203e-04,  4.7130e-04, -1.0953e-03,\n",
       "                      -6.0804e-04, -1.4008e-03, -2.9695e-04, -1.1565e-03, -5.2903e-04,\n",
       "                       1.0700e-03,  1.3699e-03, -4.9527e-04, -3.0114e-04, -3.9401e-04,\n",
       "                      -2.4416e-03, -2.1181e-03, -3.4231e-04, -5.1291e-04, -6.6825e-04,\n",
       "                      -3.1098e-04,  1.0974e-03,  2.2353e-04, -2.8137e-04, -2.0979e-03,\n",
       "                      -1.1981e-03, -1.4850e-03, -1.8394e-03, -2.7327e-04,  4.3615e-04,\n",
       "                       2.0918e-03,  2.7937e-04,  1.9344e-03, -1.3560e-03, -2.9952e-04,\n",
       "                       3.0047e-04, -1.3470e-03, -3.4859e-04, -1.0606e-04, -2.2564e-03,\n",
       "                      -3.4724e-04, -1.5295e-03,  1.0996e-03, -6.3506e-04, -4.4515e-04,\n",
       "                      -2.8748e-04, -7.8896e-04, -1.7516e-04,  4.8668e-04, -9.8890e-05,\n",
       "                      -3.4849e-04, -1.9690e-04,  1.2948e-03, -4.0408e-04, -1.1959e-04,\n",
       "                       6.9450e-04, -9.5382e-05, -7.7654e-04,  2.5484e-05, -1.6757e-04,\n",
       "                      -4.8993e-04, -1.3635e-03, -8.1467e-04, -4.7035e-04,  4.5719e-04,\n",
       "                      -6.1843e-05,  1.6245e-04,  4.1722e-03, -1.4754e-03, -1.2193e-04,\n",
       "                       2.3564e-03, -4.9494e-04, -1.1073e-05, -9.4977e-04,  9.1191e-04,\n",
       "                       4.2831e-03,  3.8306e-05, -9.0525e-04,  9.9848e-04, -5.9686e-04,\n",
       "                      -6.3186e-04,  9.9519e-04, -1.4784e-04, -6.4221e-04, -7.5281e-04,\n",
       "                       8.1992e-04, -1.0152e-03, -8.9502e-05, -3.5792e-05, -3.4086e-04,\n",
       "                      -9.9425e-04,  5.4758e-04,  1.0091e-03, -9.2515e-05,  8.0656e-04,\n",
       "                       2.2109e-03,  2.4496e-03,  6.2328e-04, -6.7575e-04,  2.3141e-03,\n",
       "                       3.9098e-04, -3.6375e-04, -4.9531e-04,  8.9618e-04, -2.0259e-03,\n",
       "                      -1.5279e-03, -4.8403e-06, -2.1840e-03, -2.3651e-04,  2.4595e-04,\n",
       "                      -2.1450e-05,  6.7234e-05, -1.4314e-04, -3.4173e-06, -4.7040e-05,\n",
       "                      -1.1826e-03, -3.4618e-04, -2.8367e-04, -1.7895e-04, -1.8235e-03,\n",
       "                       2.5912e-03, -8.1964e-04,  9.5886e-04,  1.9734e-04, -7.0330e-04,\n",
       "                       7.3085e-05, -1.4589e-04,  2.6599e-03, -4.0609e-04,  1.3315e-03,\n",
       "                      -1.9291e-03, -6.3686e-04, -1.9668e-03, -1.2005e-04,  2.6192e-04,\n",
       "                      -8.3311e-05,  2.7599e-03, -2.4665e-04,  1.2436e-03, -1.6814e-04,\n",
       "                      -9.5503e-04,  4.1748e-03,  9.6093e-04,  2.3887e-04, -1.6455e-03,\n",
       "                      -3.1841e-04,  1.1008e-03, -1.5268e-04, -8.9866e-04, -4.0288e-04,\n",
       "                      -4.8914e-04, -6.6575e-04, -1.3109e-04, -1.5132e-04, -2.0918e-04,\n",
       "                       6.2127e-04,  1.4219e-03, -9.3262e-04,  1.1980e-04, -2.2953e-04,\n",
       "                      -2.4511e-04,  3.2033e-03, -5.9862e-04, -4.8073e-05, -1.1349e-03,\n",
       "                       2.1326e-03, -5.5286e-04,  2.1779e-03, -1.3059e-04, -9.8038e-04,\n",
       "                       7.2168e-04, -6.5954e-04, -8.0062e-04, -8.4219e-05, -1.9807e-03,\n",
       "                       1.4702e-04, -9.3106e-04, -1.9513e-04, -1.2145e-03, -1.5268e-04,\n",
       "                      -4.2541e-05], device='cuda:0')),\n",
       "             ('conv1.lin_r.weight',\n",
       "              tensor([[ 0.0021,  0.0841, -0.0950,  ..., -0.0750, -0.0106,  0.0476],\n",
       "                      [-0.0709, -0.0553, -0.0717,  ..., -0.0782, -0.0487,  0.0307],\n",
       "                      [-0.0452, -0.0715, -0.0546,  ..., -0.0555, -0.0571, -0.0417],\n",
       "                      ...,\n",
       "                      [-0.0584, -0.0490,  0.0702,  ..., -0.0910, -0.1065, -0.0505],\n",
       "                      [-0.0440, -0.0636, -0.0755,  ...,  0.0254, -0.0775, -0.0725],\n",
       "                      [ 0.0434, -0.0381, -0.0093,  ...,  0.0361,  0.0877, -0.0562]],\n",
       "                     device='cuda:0')),\n",
       "             ('conv2.lin_l.weight',\n",
       "              tensor([[ 0.0490,  0.0318,  0.0587,  ...,  0.0161, -0.1059,  0.0551],\n",
       "                      [ 0.0496,  0.0633,  0.0710,  ...,  0.0211,  0.1172,  0.0754],\n",
       "                      [-0.0250, -0.0229, -0.0370,  ...,  0.0830, -0.0140, -0.1013],\n",
       "                      ...,\n",
       "                      [-0.0780, -0.0852, -0.0302,  ..., -0.0051,  0.0013, -0.0043],\n",
       "                      [ 0.0193,  0.0195,  0.0857,  ..., -0.0893,  0.0881,  0.1015],\n",
       "                      [ 0.0148,  0.0321,  0.0226,  ...,  0.0313,  0.0032,  0.0748]],\n",
       "                     device='cuda:0')),\n",
       "             ('conv2.lin_l.bias',\n",
       "              tensor([-6.2700e-02,  1.0420e-01,  6.2483e-02, -2.6969e-02, -6.9312e-02,\n",
       "                      -1.3212e-01, -4.9117e-02, -8.9018e-02, -4.4716e-02, -1.1891e-01,\n",
       "                      -5.1345e-02, -9.3366e-03, -3.8656e-02, -7.6526e-02, -9.7729e-02,\n",
       "                       1.3333e-01, -1.1424e-01, -4.0438e-02,  1.0645e-01,  5.9765e-02,\n",
       "                      -3.7686e-02, -4.6413e-02,  1.1135e-01,  3.9790e-02, -4.3166e-02,\n",
       "                      -9.0323e-02,  1.1110e-02, -9.7862e-03, -7.0018e-02, -5.9770e-02,\n",
       "                       1.7130e-02, -7.3706e-02,  1.0294e-01, -5.9446e-02,  1.2786e-01,\n",
       "                      -3.0630e-02, -9.3430e-02,  4.7042e-02, -1.1120e-01,  4.5077e-02,\n",
       "                      -1.1839e-01,  3.1832e-02,  5.8790e-02, -1.9897e-02, -1.0207e-02,\n",
       "                       3.1086e-02, -6.3041e-02, -1.0421e-01,  9.6998e-02,  1.2765e-01,\n",
       "                      -9.2914e-02, -1.1504e-01, -3.4252e-02, -1.1090e-01,  9.8260e-02,\n",
       "                      -5.4562e-02, -3.1705e-02,  1.9185e-02, -1.2360e-03, -7.0122e-02,\n",
       "                       1.1871e-01,  1.9530e-02, -2.1490e-02,  8.4269e-02,  2.5457e-02,\n",
       "                       1.0264e-01,  8.2634e-02, -4.3109e-02, -7.2162e-05, -8.2590e-02,\n",
       "                      -8.6868e-02,  1.2563e-01, -6.3092e-02, -4.3023e-02, -1.1478e-01,\n",
       "                       1.0688e-01, -8.3811e-02, -4.9447e-02, -1.1516e-01,  1.4727e-02,\n",
       "                      -4.2660e-02, -4.2762e-02, -5.1544e-02,  7.4320e-02, -9.3070e-02,\n",
       "                       3.0871e-02,  8.5819e-02,  6.9240e-02, -6.8768e-02, -8.4148e-02,\n",
       "                       3.4085e-02, -1.7013e-02,  8.7786e-03, -2.1535e-02, -1.5443e-02,\n",
       "                      -1.7560e-02,  1.1494e-02,  7.8462e-02, -1.0107e-01,  5.8747e-02,\n",
       "                       3.0132e-02, -8.4433e-02, -8.9666e-02, -1.2176e-02, -8.9678e-02,\n",
       "                      -2.5318e-02,  4.8021e-02, -4.2164e-02, -1.1881e-01,  2.9971e-02,\n",
       "                       5.7595e-02,  4.8453e-03,  4.5751e-02, -7.6163e-02,  7.3710e-02,\n",
       "                      -1.0532e-01,  9.1572e-02, -1.1650e-01, -5.7106e-02,  3.3650e-02,\n",
       "                      -3.9703e-02,  2.9186e-02, -2.6424e-02, -9.3812e-02, -9.9542e-02,\n",
       "                      -7.5216e-02, -1.2143e-01,  1.1501e-02, -9.0369e-02, -9.4376e-02,\n",
       "                       2.1121e-02, -1.0871e-01, -1.2888e-01, -9.6921e-02,  8.1338e-02,\n",
       "                      -7.2838e-02,  1.8056e-02, -3.8409e-02,  3.0739e-02,  9.4630e-02,\n",
       "                      -3.3733e-02, -3.0491e-02,  6.7782e-02, -4.6651e-02, -8.2460e-02,\n",
       "                       1.1953e-01, -5.0491e-02, -3.9550e-02, -1.1420e-01,  3.3721e-02,\n",
       "                      -2.5647e-02,  1.1614e-01, -1.0101e-01, -3.2694e-02, -1.0299e-01,\n",
       "                      -3.2987e-02, -9.5080e-02,  2.8681e-02, -1.7203e-02,  8.5640e-02,\n",
       "                      -1.1082e-01, -1.2755e-01,  4.2925e-02, -4.5660e-02, -3.6041e-02,\n",
       "                      -1.1274e-01, -9.6304e-02,  3.9863e-02,  3.8047e-02,  5.3141e-02,\n",
       "                      -5.7754e-02, -7.5231e-02, -5.2626e-02, -5.9338e-02, -8.5639e-02,\n",
       "                       3.9344e-02, -1.9016e-02, -1.1708e-01,  1.1666e-01, -4.8617e-03,\n",
       "                      -2.2308e-02, -1.1982e-01,  7.0394e-02, -1.3476e-02, -5.2091e-02,\n",
       "                       8.0379e-02,  1.5182e-02, -2.0170e-02,  3.8521e-02,  1.3175e-01,\n",
       "                      -1.0978e-01, -1.2003e-01, -4.1482e-02, -1.0589e-01,  7.0255e-02,\n",
       "                       2.9193e-02,  6.3789e-02,  1.1023e-01, -7.3870e-02, -2.6088e-02,\n",
       "                      -2.2125e-02, -1.0650e-02,  1.3606e-01,  4.8247e-02, -5.2804e-02,\n",
       "                      -5.7468e-02,  9.6914e-02, -1.1791e-01,  9.9519e-02, -6.5602e-02,\n",
       "                      -1.3599e-02,  1.3877e-01,  9.0975e-02, -6.1383e-02, -2.2486e-02,\n",
       "                       2.5794e-02,  1.2701e-01,  7.8384e-02,  2.9465e-02, -5.6049e-03,\n",
       "                       6.9392e-02, -1.2054e-01, -4.0653e-02, -1.0178e-01, -6.0577e-02,\n",
       "                      -3.9240e-02, -4.4236e-02, -6.0212e-02,  5.5953e-02, -1.0491e-01,\n",
       "                      -2.9245e-02, -1.0337e-01,  3.1231e-02,  1.9537e-02, -9.3638e-03,\n",
       "                      -1.0919e-01, -6.5015e-02, -2.1307e-02, -1.3187e-02,  1.9512e-02,\n",
       "                      -1.2278e-01, -9.6575e-02, -1.3485e-01, -7.4853e-02, -2.0877e-02,\n",
       "                      -1.0097e-01,  1.3711e-01, -4.6461e-02, -3.7870e-02, -8.7641e-02,\n",
       "                      -1.2066e-02, -7.5395e-02, -1.3852e-01, -1.1630e-01, -3.8768e-02,\n",
       "                      -6.9560e-02], device='cuda:0')),\n",
       "             ('conv2.lin_r.weight',\n",
       "              tensor([[ 0.0194,  0.0968,  0.0199,  ...,  0.0184, -0.0112,  0.0897],\n",
       "                      [ 0.0945,  0.1250,  0.0456,  ...,  0.0860,  0.1049,  0.0857],\n",
       "                      [ 0.0298, -0.0941, -0.0592,  ...,  0.0162, -0.1020, -0.0471],\n",
       "                      ...,\n",
       "                      [-0.0523, -0.0703, -0.0114,  ..., -0.0309,  0.0135, -0.0272],\n",
       "                      [ 0.1244,  0.0691,  0.1130,  ..., -0.0441,  0.0224,  0.0251],\n",
       "                      [ 0.0986,  0.0878,  0.0909,  ...,  0.0079,  0.0464,  0.0570]],\n",
       "                     device='cuda:0')),\n",
       "             ('conv3.lin_l.weight',\n",
       "              tensor([[-0.1027, -0.0539,  0.0785,  ..., -0.1424,  0.0676, -0.0411],\n",
       "                      [ 0.1206,  0.1281, -0.0391,  ...,  0.1154, -0.0505,  0.1047],\n",
       "                      [ 0.1089,  0.0424, -0.0352,  ...,  0.0769, -0.1221,  0.0086],\n",
       "                      ...,\n",
       "                      [-0.1045, -0.0246,  0.0964,  ..., -0.0853,  0.0578, -0.0911],\n",
       "                      [ 0.0513,  0.0350, -0.1003,  ...,  0.0626,  0.0507,  0.0363],\n",
       "                      [-0.1086, -0.0243,  0.1261,  ..., -0.0615, -0.0042, -0.0621]],\n",
       "                     device='cuda:0')),\n",
       "             ('conv3.lin_l.bias',\n",
       "              tensor([ 0.1074,  0.0265,  0.0211,  0.0187,  0.1358,  0.1053,  0.0124,  0.1114,\n",
       "                       0.0367,  0.0681,  0.1045,  0.0226,  0.0545, -0.1165, -0.1053,  0.1233,\n",
       "                      -0.0375,  0.1239,  0.1232, -0.1030,  0.1285,  0.0586,  0.0770,  0.0853,\n",
       "                       0.0841, -0.0439, -0.0829,  0.0571,  0.1066, -0.1160,  0.0124,  0.0286,\n",
       "                      -0.0207,  0.0077, -0.0529,  0.1196,  0.0213, -0.0220,  0.0008, -0.0528,\n",
       "                       0.0754, -0.0725, -0.0917, -0.1105, -0.0520,  0.0710, -0.1237,  0.0413,\n",
       "                       0.0704, -0.0639, -0.0979,  0.0260, -0.0626, -0.1389,  0.0260,  0.0389,\n",
       "                      -0.0786,  0.0783,  0.0345, -0.0362, -0.0322, -0.0271, -0.1083,  0.0295,\n",
       "                      -0.0313, -0.0923, -0.0794, -0.0982, -0.0549, -0.0736, -0.1156, -0.1305,\n",
       "                      -0.0762, -0.0665, -0.0116,  0.1111,  0.0205, -0.1039, -0.0356,  0.0301,\n",
       "                      -0.0796,  0.0364, -0.0835,  0.0864,  0.0886,  0.0112, -0.0187,  0.1090,\n",
       "                      -0.0693, -0.0170,  0.1161,  0.0144, -0.0695, -0.0975,  0.0532, -0.0250,\n",
       "                      -0.0425, -0.1060, -0.0973, -0.1304, -0.0159, -0.0168, -0.0891,  0.0043,\n",
       "                       0.1252,  0.0282, -0.0321,  0.1266,  0.0591,  0.0646, -0.0423,  0.0501,\n",
       "                      -0.0184, -0.0919, -0.1373, -0.0686, -0.0421, -0.0140, -0.0895,  0.0616,\n",
       "                       0.0221,  0.0160, -0.1043,  0.0266, -0.0241, -0.0578, -0.1024,  0.1173,\n",
       "                       0.1258, -0.0665,  0.1001,  0.0640,  0.0745,  0.0414,  0.0258,  0.0569,\n",
       "                       0.0275,  0.0139, -0.0676, -0.1013, -0.1181, -0.0085,  0.0255,  0.1003,\n",
       "                      -0.0519,  0.1216,  0.1263,  0.1335,  0.1208, -0.0205, -0.1118, -0.0986,\n",
       "                       0.1129,  0.0250,  0.0043,  0.0861,  0.1043,  0.0231,  0.0382, -0.0885,\n",
       "                       0.1116,  0.0266, -0.0596, -0.0449, -0.0552, -0.0674, -0.0523,  0.0859,\n",
       "                      -0.1046,  0.1020, -0.1093,  0.0763, -0.0565,  0.1401,  0.0534,  0.0288,\n",
       "                      -0.1019, -0.1223, -0.0718, -0.0211, -0.1156,  0.1005, -0.0675, -0.1340,\n",
       "                      -0.0912,  0.0327, -0.0380,  0.1025,  0.0934, -0.0900, -0.1377,  0.0858,\n",
       "                      -0.0718, -0.0715,  0.0815, -0.0983, -0.0693, -0.0762,  0.0941,  0.0317,\n",
       "                      -0.0993,  0.1280,  0.0332,  0.1123, -0.1047,  0.1271, -0.0349, -0.1302,\n",
       "                       0.0475, -0.0714,  0.1133, -0.0483, -0.1010,  0.1271,  0.0555, -0.0779,\n",
       "                      -0.0177, -0.0055, -0.0364,  0.1165, -0.0740, -0.0369,  0.0521,  0.1217,\n",
       "                       0.0664, -0.1135,  0.0365, -0.1102,  0.0255, -0.0265,  0.0085, -0.0622,\n",
       "                       0.0990, -0.0115, -0.1180,  0.0713,  0.1216, -0.0281,  0.0831, -0.0614,\n",
       "                      -0.1148,  0.0140,  0.1043,  0.0515,  0.0970, -0.0235,  0.0837, -0.0765,\n",
       "                      -0.0587, -0.0416, -0.0339, -0.0480,  0.1340,  0.1053,  0.0170,  0.1447],\n",
       "                     device='cuda:0')),\n",
       "             ('conv3.lin_r.weight',\n",
       "              tensor([[-0.1398, -0.0162,  0.0822,  ..., -0.0452,  0.0247, -0.1300],\n",
       "                      [ 0.1064,  0.1176, -0.0802,  ...,  0.0712, -0.1148,  0.0884],\n",
       "                      [ 0.0241,  0.0165, -0.1027,  ...,  0.0117, -0.0286, -0.0717],\n",
       "                      ...,\n",
       "                      [-0.1036, -0.1165,  0.0375,  ..., -0.0912, -0.0026, -0.1066],\n",
       "                      [ 0.0126,  0.0281, -0.0272,  ...,  0.0573,  0.0417,  0.0301],\n",
       "                      [-0.0489, -0.0328,  0.1119,  ..., -0.0906,  0.0197, -0.0969]],\n",
       "                     device='cuda:0')),\n",
       "             ('pool.gnn.lin_rel.weight',\n",
       "              tensor([[-0.0539, -0.0963, -0.1290,  0.1017,  0.0738, -0.0501, -0.1174, -0.0039,\n",
       "                        0.0417,  0.0832,  0.0191, -0.0993,  0.0186, -0.0668,  0.0420,  0.0606,\n",
       "                        0.0267,  0.0184,  0.0784, -0.0549, -0.1132, -0.0818, -0.0235,  0.0550,\n",
       "                        0.0465,  0.0922,  0.1096, -0.0901, -0.0597,  0.0073, -0.0383,  0.0989,\n",
       "                        0.0051, -0.0800, -0.1098,  0.1040, -0.0293,  0.0876,  0.0131, -0.0418,\n",
       "                        0.0318, -0.0277, -0.0652, -0.0774,  0.0156,  0.1191,  0.0087, -0.0443,\n",
       "                       -0.0534, -0.0279, -0.1049, -0.0364, -0.0806, -0.0686, -0.1245, -0.0453,\n",
       "                       -0.0519,  0.1203, -0.0442,  0.0822, -0.0460, -0.0811, -0.0627,  0.1032,\n",
       "                       -0.0439,  0.1253, -0.1134, -0.0397,  0.0291, -0.0399,  0.0360,  0.1164,\n",
       "                       -0.0988, -0.0299, -0.0463, -0.0388, -0.1081,  0.0481,  0.1131, -0.0597,\n",
       "                       -0.1210,  0.0156, -0.0442,  0.0732, -0.0351,  0.0621, -0.0782,  0.0822,\n",
       "                       -0.0638, -0.0979,  0.0125, -0.1135, -0.0869, -0.1016, -0.0651,  0.0660,\n",
       "                        0.1209, -0.0324, -0.0587,  0.0167, -0.0961, -0.0547,  0.0210, -0.0792,\n",
       "                        0.0865, -0.0186, -0.0618,  0.1016,  0.0832, -0.0569, -0.1156,  0.0427,\n",
       "                       -0.0428, -0.0436,  0.0162, -0.0922,  0.0145, -0.0771,  0.0410, -0.0927,\n",
       "                       -0.0995,  0.0949, -0.0631, -0.0161, -0.0844, -0.0526, -0.0743, -0.0598,\n",
       "                       -0.0844, -0.0353, -0.0746, -0.0184, -0.1202, -0.0897, -0.1023,  0.1132,\n",
       "                       -0.0475,  0.1097, -0.0953, -0.0727, -0.1212, -0.0865, -0.0479,  0.0142,\n",
       "                       -0.1058, -0.0041, -0.0168, -0.1218, -0.0949,  0.1062,  0.0452,  0.0677,\n",
       "                        0.0501,  0.1093, -0.1085, -0.0948, -0.0477,  0.0302, -0.1041,  0.0216,\n",
       "                        0.0725, -0.0875, -0.1081, -0.0348, -0.0052,  0.0245, -0.0746,  0.1198,\n",
       "                       -0.0205,  0.1187, -0.0084,  0.1194, -0.0168,  0.0743,  0.0443, -0.0093,\n",
       "                       -0.0887, -0.0148,  0.1197,  0.0086, -0.0495, -0.0692, -0.1198, -0.1153,\n",
       "                       -0.0522, -0.0251,  0.0971,  0.1149, -0.1062, -0.0934, -0.1223, -0.0323,\n",
       "                        0.0345, -0.0919, -0.0607,  0.1134,  0.0269, -0.0680,  0.0904, -0.0142,\n",
       "                       -0.0989, -0.0806, -0.0117, -0.0568, -0.0983,  0.1141, -0.1069, -0.0220,\n",
       "                       -0.0571,  0.0620, -0.0970,  0.0882, -0.0476,  0.1261, -0.0782, -0.0338,\n",
       "                        0.1189, -0.0328, -0.0605, -0.1209, -0.0509,  0.0863, -0.0517, -0.1087,\n",
       "                       -0.0822, -0.1249, -0.1120, -0.0050, -0.0329, -0.0419,  0.0525,  0.1113,\n",
       "                        0.0225, -0.0266, -0.0520, -0.0133,  0.1173,  0.0466, -0.0882,  0.0168,\n",
       "                       -0.0192, -0.0554, -0.0748, -0.0465, -0.1294,  0.0909, -0.1067,  0.0595,\n",
       "                       -0.0878,  0.0093,  0.0751, -0.1132, -0.0311, -0.0668, -0.0196, -0.0373]],\n",
       "                     device='cuda:0')),\n",
       "             ('pool.gnn.lin_rel.bias', tensor([0.0933], device='cuda:0')),\n",
       "             ('pool.gnn.lin_root.weight',\n",
       "              tensor([[-0.0759, -0.1174, -0.0485,  0.0679,  0.0830, -0.0606, -0.0398, -0.0235,\n",
       "                        0.0490,  0.1044,  0.0419, -0.0317,  0.1120, -0.0290,  0.0160,  0.0836,\n",
       "                        0.0181,  0.0550,  0.0573, -0.0379, -0.1211, -0.0128, -0.0316,  0.0478,\n",
       "                       -0.0389,  0.0874,  0.1186, -0.1232, -0.1059,  0.0179, -0.0713,  0.1252,\n",
       "                        0.0603, -0.1167, -0.0096,  0.1265, -0.0566,  0.0263,  0.0369, -0.1049,\n",
       "                        0.0217, -0.1080, -0.0263, -0.0102,  0.0312,  0.0645,  0.1128, -0.0311,\n",
       "                       -0.0702, -0.0997, -0.0691, -0.0075, -0.1118, -0.1239, -0.0105, -0.0485,\n",
       "                       -0.1154,  0.0210, -0.0831,  0.1257, -0.0474, -0.0509, -0.1147,  0.0470,\n",
       "                       -0.0620,  0.1114, -0.0824, -0.0829,  0.1240, -0.0556,  0.0533,  0.0598,\n",
       "                       -0.1063, -0.0806, -0.0133, -0.0383, -0.1042,  0.0663,  0.0604, -0.0145,\n",
       "                       -0.1154,  0.0404, -0.0832,  0.0175, -0.0478,  0.0985, -0.0679,  0.0889,\n",
       "                       -0.0379, -0.0253,  0.0138, -0.0430, -0.0238, -0.0602, -0.0066,  0.0462,\n",
       "                        0.1069, -0.0123, -0.0290,  0.0820, -0.0224, -0.0332,  0.0277, -0.0035,\n",
       "                        0.1108, -0.0793, -0.0392,  0.1168,  0.0972, -0.0422, -0.0892,  0.0500,\n",
       "                       -0.1254, -0.0170,  0.0122, -0.0338, -0.0041, -0.0766,  0.0118, -0.1189,\n",
       "                       -0.0598,  0.0781, -0.1177, -0.0992, -0.0229, -0.0453, -0.0576, -0.0818,\n",
       "                       -0.1038, -0.0860, -0.0623, -0.0255, -0.0282, -0.0550, -0.0294,  0.0142,\n",
       "                       -0.1168,  0.1145, -0.0287, -0.0100, -0.0650, -0.0967, -0.0861,  0.0545,\n",
       "                       -0.0108, -0.0778, -0.0735, -0.0902, -0.0967,  0.0558,  0.1214,  0.0512,\n",
       "                        0.0422,  0.0796, -0.0555, -0.0709, -0.0656,  0.0121, -0.0621,  0.1262,\n",
       "                        0.1228, -0.0871, -0.0312, -0.1146, -0.0706,  0.0648, -0.0720,  0.0213,\n",
       "                       -0.0637,  0.0505, -0.1074,  0.0503, -0.0786,  0.0904,  0.0961, -0.0353,\n",
       "                       -0.0205, -0.0845,  0.1250,  0.0413, -0.0007, -0.0915, -0.0552, -0.0644,\n",
       "                       -0.0659, -0.1261,  0.1244,  0.0853, -0.0469, -0.0551, -0.0166, -0.0633,\n",
       "                        0.0201, -0.0653, -0.1078,  0.0922,  0.0602, -0.0072,  0.1061, -0.0444,\n",
       "                       -0.1110, -0.0366, -0.1243, -0.1249, -0.0806,  0.1223, -0.0301, -0.0831,\n",
       "                       -0.0247,  0.0840, -0.1270,  0.1159, -0.0910,  0.0464, -0.0914, -0.1284,\n",
       "                        0.0136, -0.1074, -0.0640, -0.0876, -0.0677,  0.0414, -0.0958, -0.0654,\n",
       "                       -0.1129, -0.0375, -0.0637, -0.1194, -0.1148, -0.1061,  0.1117,  0.0689,\n",
       "                        0.1053, -0.1282, -0.1004, -0.0661,  0.0305,  0.0153, -0.0570,  0.1008,\n",
       "                       -0.0868, -0.0641, -0.0046, -0.0212, -0.1001,  0.0800, -0.0088,  0.0494,\n",
       "                       -0.1108,  0.1294,  0.0839, -0.1066, -0.1157, -0.0939, -0.0865, -0.0781]],\n",
       "                     device='cuda:0')),\n",
       "             ('pool2.gnn.lin_rel.weight',\n",
       "              tensor([[-0.1050, -0.1203,  0.0970,  0.0301,  0.0399,  0.0091, -0.0326, -0.0183,\n",
       "                       -0.0335,  0.0438,  0.0199, -0.0782, -0.0359, -0.1322, -0.1374,  0.1240,\n",
       "                       -0.1011, -0.0584, -0.0510,  0.1233, -0.1230,  0.0256, -0.0704,  0.0946,\n",
       "                        0.0398, -0.0874, -0.1149,  0.0199, -0.0842, -0.1048, -0.0632,  0.0505,\n",
       "                       -0.0655, -0.1302, -0.0154, -0.0294,  0.0245,  0.0750, -0.0259, -0.0741,\n",
       "                       -0.0809, -0.0704, -0.0552,  0.0554,  0.0404,  0.1151, -0.1323, -0.1140,\n",
       "                       -0.0453, -0.0704, -0.1383, -0.0887, -0.0898, -0.0981, -0.0148, -0.0540,\n",
       "                       -0.0609, -0.0475, -0.1112, -0.1305, -0.0452,  0.1153, -0.0499, -0.0308,\n",
       "                        0.1104, -0.0801,  0.1000, -0.0831, -0.0973, -0.0081, -0.0912,  0.1163,\n",
       "                        0.0491, -0.1068, -0.0640,  0.1170, -0.1246, -0.1134, -0.0254, -0.1282,\n",
       "                       -0.1245, -0.0242, -0.0437,  0.1157, -0.0353, -0.0236,  0.0980, -0.0214,\n",
       "                        0.0317, -0.1098, -0.0728, -0.0824, -0.1077, -0.0344, -0.0892, -0.0958,\n",
       "                       -0.0583,  0.1093, -0.1172,  0.1015, -0.1085, -0.1172,  0.0543,  0.0393,\n",
       "                        0.0143, -0.0606, -0.1149,  0.0214, -0.1331, -0.0632,  0.1022, -0.0560,\n",
       "                       -0.0728, -0.0703, -0.0196, -0.1200, -0.0258, -0.0784, -0.1293,  0.0737,\n",
       "                       -0.1090, -0.0418, -0.0875, -0.0570, -0.1028, -0.0994, -0.0430, -0.0585,\n",
       "                        0.0100, -0.1405,  0.0826, -0.0446,  0.0422,  0.0116, -0.1061,  0.0465,\n",
       "                       -0.0257, -0.1002, -0.1408,  0.0586, -0.0552, -0.1385,  0.0683, -0.1296,\n",
       "                       -0.1010, -0.0964, -0.1011,  0.0595, -0.0540, -0.0829,  0.0540, -0.1037,\n",
       "                       -0.0199, -0.0726, -0.1202, -0.0650, -0.1379, -0.0578, -0.1122,  0.0912,\n",
       "                       -0.1308,  0.0178, -0.0509, -0.0685, -0.1291, -0.1219,  0.0669,  0.1226,\n",
       "                        0.0942,  0.1172, -0.0564,  0.0257, -0.0606,  0.0261, -0.0973,  0.1097,\n",
       "                       -0.1198,  0.0462,  0.1211, -0.0714, -0.0809, -0.1068, -0.0386,  0.0583,\n",
       "                       -0.1081, -0.0741, -0.0718, -0.0937, -0.0567,  0.1007, -0.1270,  0.0704,\n",
       "                       -0.1247, -0.0995,  0.0882, -0.0134, -0.0517,  0.1186, -0.0488, -0.1398,\n",
       "                        0.0273, -0.1281,  0.1119,  0.0713, -0.0587, -0.0993, -0.0798, -0.1000,\n",
       "                        0.1153, -0.0575, -0.1084,  0.0995, -0.0708, -0.0928,  0.0221,  0.1339,\n",
       "                       -0.0160,  0.0804,  0.1363, -0.0265, -0.0239,  0.0482, -0.0637, -0.0975,\n",
       "                        0.0545,  0.0227,  0.0419, -0.0664,  0.0885, -0.0431, -0.0377,  0.0387,\n",
       "                       -0.0230,  0.1071, -0.1120,  0.0515, -0.1022,  0.0405, -0.1340, -0.0215,\n",
       "                       -0.1390, -0.0307, -0.1185, -0.0970, -0.0483, -0.0831,  0.0797, -0.0965,\n",
       "                       -0.0128, -0.0733, -0.1417,  0.0496, -0.1052, -0.1088,  0.0525, -0.1119]],\n",
       "                     device='cuda:0')),\n",
       "             ('pool2.gnn.lin_rel.bias', tensor([0.1082], device='cuda:0')),\n",
       "             ('pool2.gnn.lin_root.weight',\n",
       "              tensor([[-0.1321, -0.0329,  0.0824,  0.0451,  0.1236,  0.0317, -0.0450, -0.0931,\n",
       "                       -0.0455,  0.0736,  0.0280, -0.0762, -0.0180, -0.0949, -0.0383,  0.0374,\n",
       "                       -0.1084, -0.0677, -0.1225,  0.0914, -0.0586,  0.1287, -0.0336,  0.0388,\n",
       "                        0.1257, -0.0811, -0.1065,  0.0891, -0.0535, -0.1111, -0.0860,  0.0642,\n",
       "                       -0.0569, -0.1213, -0.1274, -0.1311,  0.0773,  0.0278, -0.0324, -0.0140,\n",
       "                       -0.0837, -0.0828, -0.0931,  0.0324,  0.0827,  0.0570, -0.1101, -0.1007,\n",
       "                       -0.0200, -0.0713, -0.1071, -0.0736, -0.0250, -0.0309, -0.0445, -0.0676,\n",
       "                       -0.0849, -0.0901, -0.0477, -0.1288, -0.0434,  0.0680, -0.0505, -0.0593,\n",
       "                        0.0630, -0.1316,  0.1234, -0.0419, -0.0818, -0.0790, -0.1192,  0.0197,\n",
       "                        0.0326, -0.1140, -0.0650,  0.0703, -0.0739, -0.0577, -0.0656, -0.0462,\n",
       "                       -0.0629, -0.0956, -0.0500,  0.1288, -0.0872, -0.0528,  0.1259, -0.0305,\n",
       "                        0.0568, -0.0117, -0.1089, -0.1165, -0.0225, -0.0565, -0.1165, -0.0754,\n",
       "                       -0.0660,  0.1094, -0.0275,  0.0530, -0.1265, -0.1131,  0.0244,  0.0783,\n",
       "                        0.1142, -0.0879, -0.1076,  0.0332, -0.0303, -0.0569,  0.0587, -0.0554,\n",
       "                       -0.0801, -0.0158, -0.0486, -0.0855, -0.0660, -0.0726, -0.1237,  0.1145,\n",
       "                       -0.0338, -0.0424, -0.0596, -0.0315, -0.0965, -0.1119, -0.0906, -0.0678,\n",
       "                        0.0556, -0.0900,  0.0377, -0.0372,  0.0682,  0.0714, -0.0487,  0.0406,\n",
       "                       -0.0490, -0.0302, -0.1309,  0.1325, -0.1238, -0.1292,  0.0681, -0.0374,\n",
       "                       -0.0527, -0.1127, -0.0166,  0.1129, -0.0543, -0.0998,  0.1053, -0.0936,\n",
       "                       -0.0776, -0.0592, -0.0864, -0.0749, -0.0879, -0.0734, -0.0651,  0.1348,\n",
       "                       -0.1322,  0.1283, -0.0945, -0.0446, -0.1247, -0.0246,  0.0842,  0.0682,\n",
       "                        0.0678,  0.1111, -0.1064,  0.0831, -0.1154,  0.1111, -0.1191,  0.0582,\n",
       "                       -0.0459,  0.0287,  0.1170, -0.1218, -0.0999, -0.1149, -0.1297,  0.1124,\n",
       "                       -0.0783, -0.1290, -0.1287, -0.0291, -0.1133,  0.1152, -0.0403,  0.0350,\n",
       "                       -0.1283, -0.0924,  0.0715, -0.0538, -0.0690,  0.0654, -0.0972, -0.0453,\n",
       "                        0.0227, -0.0953,  0.1161,  0.1317, -0.1016, -0.0099, -0.0989, -0.0505,\n",
       "                        0.0803, -0.1301, -0.0672,  0.0396, -0.1310, -0.1153,  0.0964,  0.0946,\n",
       "                       -0.0471,  0.0941,  0.0345, -0.1385, -0.1293,  0.1372, -0.1223, -0.0757,\n",
       "                        0.0237,  0.1169,  0.0484, -0.1302,  0.0502, -0.0592, -0.0595,  0.0851,\n",
       "                       -0.0452,  0.1312, -0.0433,  0.1092, -0.0489,  0.0789, -0.1235, -0.0492,\n",
       "                       -0.0879, -0.0814, -0.1126, -0.1184, -0.0618, -0.0917,  0.0296, -0.0795,\n",
       "                       -0.0780, -0.0782, -0.0192,  0.1232, -0.0632, -0.0572,  0.0325, -0.1060]],\n",
       "                     device='cuda:0')),\n",
       "             ('pool3.gnn.lin_rel.weight',\n",
       "              tensor([[ 0.0304,  0.0440,  0.1086,  0.0587, -0.1118, -0.0690,  0.0338, -0.1275,\n",
       "                       -0.0930,  0.0603, -0.1209,  0.0335, -0.0789,  0.0912, -0.0276,  0.0286,\n",
       "                        0.0925,  0.0396, -0.1028,  0.0893,  0.0539,  0.0847,  0.1031, -0.1391,\n",
       "                        0.0735,  0.0980, -0.0567,  0.0134,  0.0166, -0.0501,  0.0836,  0.1193,\n",
       "                        0.0226,  0.0281,  0.0616, -0.0895,  0.0073,  0.1054,  0.0980,  0.1049,\n",
       "                        0.0349, -0.0572,  0.0783,  0.0258,  0.0898, -0.1223,  0.0969,  0.0534,\n",
       "                       -0.1265,  0.0374,  0.1033,  0.0865,  0.1036, -0.0376, -0.0595, -0.1355,\n",
       "                       -0.0331, -0.1194,  0.0522,  0.0945,  0.1266,  0.1085,  0.1289,  0.0236,\n",
       "                       -0.0622,  0.1292, -0.0390,  0.0869, -0.0429, -0.0247,  0.0663, -0.0619,\n",
       "                       -0.0224, -0.0343,  0.1218, -0.1044,  0.0271, -0.0212,  0.1193,  0.1347,\n",
       "                        0.1200,  0.1120,  0.1295,  0.0812, -0.1202, -0.1102,  0.1156,  0.0271,\n",
       "                        0.0818,  0.1266,  0.0247,  0.0101,  0.0560,  0.0158,  0.0692, -0.0426,\n",
       "                       -0.0675, -0.0187,  0.0663, -0.1010,  0.1339,  0.0529, -0.0772,  0.1134,\n",
       "                       -0.0851, -0.1105, -0.0574, -0.0914, -0.1072,  0.1214,  0.1101, -0.1419,\n",
       "                        0.0912, -0.0637, -0.0279, -0.0716,  0.1254,  0.0935,  0.1193,  0.0780,\n",
       "                        0.0180,  0.0894,  0.1104, -0.1331,  0.0875,  0.0952,  0.1160,  0.0359,\n",
       "                        0.0737,  0.1014,  0.0400, -0.0922, -0.1134,  0.0429,  0.0714, -0.0803,\n",
       "                       -0.1038, -0.0139,  0.0668,  0.1243, -0.0455,  0.1377, -0.0733, -0.0896,\n",
       "                       -0.0159,  0.0539,  0.0314, -0.1113, -0.1325,  0.1164, -0.0693,  0.1308,\n",
       "                       -0.1043,  0.0560,  0.1325,  0.0605,  0.0670, -0.0225,  0.0546,  0.0895,\n",
       "                       -0.0843,  0.0479,  0.0772,  0.1182,  0.0916,  0.0052, -0.0603,  0.0344,\n",
       "                       -0.0462,  0.0509, -0.0159,  0.0399, -0.0464, -0.1168,  0.0490,  0.1060,\n",
       "                       -0.0362, -0.0372, -0.0776, -0.0243,  0.1165,  0.0762, -0.0701, -0.0237,\n",
       "                        0.1254,  0.0205,  0.1013,  0.0591,  0.0310, -0.0655, -0.0324, -0.1377,\n",
       "                       -0.0257,  0.1065, -0.0767, -0.0348,  0.1272,  0.1147, -0.1326, -0.0711,\n",
       "                       -0.0248, -0.0980,  0.0611,  0.0102,  0.1107, -0.0798, -0.0679, -0.0524,\n",
       "                        0.1010, -0.0176, -0.1256, -0.0585,  0.0872,  0.0383, -0.0842, -0.0447,\n",
       "                        0.0968,  0.1019,  0.1117,  0.0463, -0.0200, -0.0566, -0.1373, -0.1077,\n",
       "                       -0.0978,  0.0721,  0.0566, -0.0405,  0.0206,  0.1196,  0.0712, -0.0285,\n",
       "                        0.1069,  0.1394,  0.1025,  0.0419,  0.0769, -0.0222,  0.1028,  0.0979,\n",
       "                       -0.0564,  0.0710, -0.1186,  0.0318,  0.0194, -0.0154, -0.0725,  0.1093,\n",
       "                        0.1102, -0.0487,  0.1376, -0.0857, -0.0768, -0.1040,  0.0913,  0.0246]],\n",
       "                     device='cuda:0')),\n",
       "             ('pool3.gnn.lin_rel.bias', tensor([-0.0369], device='cuda:0')),\n",
       "             ('pool3.gnn.lin_root.weight',\n",
       "              tensor([[ 0.0430,  0.0730,  0.0844,  0.1115, -0.1413, -0.0860,  0.1003, -0.0681,\n",
       "                       -0.0223,  0.0878, -0.0547,  0.0576, -0.0513,  0.0907, -0.1131,  0.0973,\n",
       "                        0.0240,  0.0877, -0.0466,  0.0109,  0.0561,  0.0455,  0.0574, -0.0809,\n",
       "                        0.0156,  0.0604, -0.0921,  0.0286,  0.0505, -0.0673,  0.0187,  0.0878,\n",
       "                        0.0620,  0.1216,  0.0808, -0.0755,  0.0772,  0.0556,  0.0513,  0.0614,\n",
       "                        0.1322, -0.0280,  0.1178,  0.0413,  0.1241, -0.0745,  0.0836,  0.0660,\n",
       "                       -0.0859,  0.0750,  0.0298,  0.0331,  0.1011, -0.0703, -0.0991, -0.0964,\n",
       "                       -0.0926, -0.0982,  0.0968,  0.0131,  0.0536,  0.1234,  0.0524,  0.0875,\n",
       "                       -0.1402,  0.0403, -0.0161, -0.0180, -0.0190, -0.0390,  0.1077, -0.1007,\n",
       "                       -0.0553, -0.0791,  0.0238, -0.0320, -0.0060, -0.0489,  0.0859,  0.0299,\n",
       "                        0.0891,  0.1086,  0.1408,  0.0441, -0.0645, -0.1317,  0.0693,  0.0819,\n",
       "                        0.0614,  0.0626,  0.0506,  0.1121,  0.0740,  0.1256, -0.1027, -0.0809,\n",
       "                       -0.0861, -0.0504,  0.0923, -0.0209,  0.1363,  0.0290, -0.0554,  0.0268,\n",
       "                       -0.0288, -0.0962, -0.0259, -0.0584, -0.0081,  0.1164,  0.1115, -0.0993,\n",
       "                        0.1217, -0.0580, -0.0267, -0.0554,  0.0261,  0.0981,  0.0637,  0.0771,\n",
       "                        0.1294,  0.0335,  0.0429, -0.0970,  0.0983,  0.0263,  0.0235,  0.0400,\n",
       "                        0.0295,  0.0594,  0.0134, -0.0704, -0.0899,  0.0947,  0.1111, -0.1079,\n",
       "                       -0.1019,  0.0208,  0.0576,  0.1081, -0.1147,  0.0731, -0.1008, -0.0920,\n",
       "                        0.0357,  0.0738,  0.1230, -0.0349, -0.0891,  0.0289, -0.0238,  0.1049,\n",
       "                       -0.0589,  0.0200,  0.0534,  0.0333,  0.0469,  0.0999,  0.0371,  0.0687,\n",
       "                       -0.0980,  0.0496,  0.0385,  0.0718,  0.0412,  0.0624, -0.0941,  0.0656,\n",
       "                       -0.0468,  0.0399, -0.0623,  0.0470, -0.0865, -0.1156,  0.0993,  0.0935,\n",
       "                       -0.1235, -0.0770, -0.0852, -0.0734,  0.0860,  0.1360, -0.0588, -0.0411,\n",
       "                        0.1158,  0.0277,  0.1023,  0.0476,  0.0893, -0.0237,  0.0303, -0.0361,\n",
       "                       -0.0579,  0.1287, -0.0840, -0.1361,  0.0683,  0.0457, -0.0956, -0.0297,\n",
       "                       -0.0762, -0.0781,  0.0369,  0.0888,  0.0629, -0.0810, -0.1034, -0.0937,\n",
       "                        0.0770, -0.0984, -0.0891, -0.1419,  0.0439,  0.0452, -0.0536, -0.0015,\n",
       "                        0.0571,  0.0226,  0.0949, -0.0210, -0.0250, -0.1183, -0.0821, -0.0774,\n",
       "                       -0.0959,  0.1141,  0.1165, -0.0946,  0.0291,  0.0522,  0.1071, -0.1154,\n",
       "                        0.0643,  0.1403,  0.0937,  0.0565, -0.0580, -0.1216,  0.0673,  0.0145,\n",
       "                       -0.0574,  0.0573, -0.0249,  0.0230,  0.0636, -0.0443, -0.1191,  0.0614,\n",
       "                        0.0573, -0.0755,  0.1004, -0.0595, -0.0232, -0.0820,  0.0979,  0.1300]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[-0.0653,  0.0541, -0.0820,  ..., -0.0385, -0.0613,  0.0229],\n",
       "                      [-0.0634,  0.0339, -0.0673,  ..., -0.0619,  0.0231,  0.0637],\n",
       "                      [-0.0944, -0.0028, -0.0303,  ...,  0.0238, -0.0869,  0.0098],\n",
       "                      ...,\n",
       "                      [ 0.0735,  0.0045,  0.1008,  ...,  0.0069, -0.0578, -0.0236],\n",
       "                      [ 0.0843,  0.0046,  0.1007,  ..., -0.0722,  0.0873, -0.0690],\n",
       "                      [-0.1049, -0.0460, -0.0389,  ..., -0.0375,  0.0555,  0.0716]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([-0.0256, -0.0760, -0.0960, -0.0491, -0.0383, -0.0581,  0.0448,  0.0624,\n",
       "                      -0.0988,  0.0262, -0.0473, -0.0763, -0.0343, -0.0728, -0.0744, -0.0753,\n",
       "                      -0.1023,  0.0374, -0.0636,  0.0417, -0.1018,  0.0234, -0.0796, -0.0688,\n",
       "                       0.0015,  0.0816,  0.0308,  0.0119, -0.0888,  0.0253, -0.0132, -0.0706,\n",
       "                      -0.0721, -0.0712,  0.0721,  0.0521,  0.0657,  0.0489,  0.0839, -0.0280,\n",
       "                       0.0743,  0.0536, -0.0584, -0.0653, -0.0999, -0.0881, -0.0388, -0.0524,\n",
       "                      -0.0837, -0.0587, -0.0778, -0.0610,  0.0688, -0.0545, -0.0749,  0.0233,\n",
       "                      -0.0622, -0.0606, -0.0672, -0.0206, -0.1020, -0.0716, -0.0261,  0.0343,\n",
       "                      -0.0822,  0.0066, -0.0678,  0.0131,  0.0564, -0.0393, -0.0912, -0.0164,\n",
       "                      -0.0818, -0.0677, -0.0671, -0.0380, -0.0649, -0.0546,  0.0414, -0.0677,\n",
       "                       0.0814, -0.0928, -0.0626,  0.0750, -0.0845, -0.0915, -0.0652, -0.0717,\n",
       "                      -0.0902, -0.0596, -0.0682,  0.0480,  0.0061, -0.0133,  0.0597, -0.0281,\n",
       "                      -0.0615,  0.0139,  0.0539, -0.0621, -0.0528,  0.0133, -0.0673, -0.0826,\n",
       "                      -0.1005,  0.0654, -0.0929, -0.0309, -0.0602, -0.0898, -0.0902, -0.0157,\n",
       "                       0.0038, -0.0427, -0.0425, -0.1005, -0.0960, -0.0692, -0.0839, -0.0629,\n",
       "                      -0.0695,  0.0142, -0.0865, -0.0467, -0.0165, -0.0400,  0.0657, -0.0562,\n",
       "                      -0.0243, -0.0816, -0.0723, -0.0780,  0.0730, -0.0966, -0.0600, -0.0586,\n",
       "                      -0.0027, -0.0046, -0.0642, -0.0646, -0.0919, -0.0092, -0.0435, -0.0678,\n",
       "                       0.0263, -0.0778, -0.0868, -0.0906, -0.0373, -0.0877, -0.0566, -0.0589,\n",
       "                      -0.0967, -0.0686, -0.0228, -0.0450, -0.0592,  0.0199, -0.0242, -0.0806,\n",
       "                       0.0498, -0.0779,  0.0470, -0.0800,  0.0453, -0.0125, -0.1084,  0.0072,\n",
       "                      -0.0033, -0.0671, -0.0522,  0.0414, -0.0341, -0.0840, -0.0429,  0.0224,\n",
       "                       0.0271, -0.0839, -0.0937, -0.0987,  0.0166, -0.0908,  0.0413, -0.0873,\n",
       "                      -0.0847, -0.0691, -0.0236, -0.0410, -0.0327, -0.0196,  0.0271, -0.0976,\n",
       "                      -0.0371, -0.0815, -0.0553, -0.0683, -0.0612, -0.0637, -0.0898, -0.0638,\n",
       "                      -0.0851, -0.0906,  0.0290, -0.0881, -0.0148, -0.0193,  0.0403, -0.0191,\n",
       "                       0.0559,  0.0464, -0.0808, -0.0288, -0.0474, -0.0382, -0.0733, -0.0767,\n",
       "                      -0.0661, -0.0979,  0.0392, -0.0695,  0.0413,  0.0039, -0.0561, -0.0591,\n",
       "                       0.0784, -0.0665, -0.0434, -0.0213,  0.0411, -0.0201, -0.0812, -0.0188,\n",
       "                      -0.0354, -0.0676, -0.0602,  0.0094, -0.0897,  0.0303, -0.0595, -0.0904,\n",
       "                      -0.0753, -0.0646, -0.0166, -0.0805, -0.0843, -0.0052,  0.0376, -0.0786,\n",
       "                      -0.0614, -0.0876,  0.0134,  0.0062, -0.0804,  0.0025, -0.0337, -0.0643],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0833, -0.0751,  0.0049,  ...,  0.0231,  0.0118,  0.0001],\n",
       "                      [-0.0158, -0.0403, -0.0401,  ..., -0.0055,  0.0469, -0.0430],\n",
       "                      [-0.1107, -0.0588, -0.0377,  ..., -0.0592, -0.0612,  0.0160],\n",
       "                      ...,\n",
       "                      [ 0.0916, -0.0448, -0.0332,  ...,  0.0817,  0.0056, -0.0757],\n",
       "                      [ 0.0357, -0.0843, -0.0948,  ..., -0.0779, -0.0841,  0.0701],\n",
       "                      [-0.1112,  0.0158,  0.0030,  ..., -0.1368, -0.1322, -0.0822]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0082, -0.0257, -0.0918, -0.0989, -0.0644, -0.0309, -0.0833,  0.0465,\n",
       "                       0.0006, -0.0309,  0.0431,  0.0948, -0.0998, -0.0015, -0.1156,  0.0846,\n",
       "                      -0.0530,  0.0968,  0.1192,  0.0477, -0.1099,  0.0371, -0.0421, -0.0715,\n",
       "                      -0.0083, -0.1028, -0.0588, -0.0458, -0.0696, -0.0144, -0.0251, -0.0447,\n",
       "                      -0.1156,  0.0518, -0.0923, -0.0166, -0.0676,  0.0282, -0.0526, -0.0424,\n",
       "                      -0.0906,  0.0812,  0.0165, -0.0878, -0.0222, -0.0979, -0.0065,  0.0825,\n",
       "                      -0.0574,  0.0077, -0.0896, -0.1033,  0.0469, -0.0718, -0.0182, -0.0594,\n",
       "                       0.0269,  0.0054, -0.0074, -0.0499, -0.0659, -0.0387, -0.0176,  0.0098,\n",
       "                      -0.1228,  0.1286, -0.0515, -0.0361, -0.0442, -0.0651, -0.0014, -0.0440,\n",
       "                       0.0242, -0.0779, -0.0766, -0.0913,  0.0033,  0.0549, -0.0993,  0.0012,\n",
       "                      -0.0953, -0.1040, -0.0259, -0.0371, -0.0618, -0.0431, -0.0758,  0.0948,\n",
       "                      -0.0164, -0.0180,  0.0383,  0.0730,  0.0181, -0.0835, -0.0523,  0.0770,\n",
       "                      -0.1035, -0.0719,  0.0075, -0.0454,  0.0710,  0.0267, -0.1107, -0.0439,\n",
       "                       0.0168, -0.0767, -0.0423, -0.1016, -0.0479, -0.0609, -0.0989, -0.0952,\n",
       "                      -0.0209, -0.1257,  0.0103, -0.0860,  0.0942, -0.0788,  0.0534, -0.1141,\n",
       "                       0.0545, -0.0830, -0.0101, -0.0625, -0.0222,  0.0839, -0.0520, -0.0998,\n",
       "                       0.0406, -0.0554,  0.0460,  0.0242,  0.0105, -0.0950,  0.0171,  0.0498,\n",
       "                       0.0243, -0.0490, -0.0127,  0.0926,  0.0002, -0.1056, -0.1142, -0.1324,\n",
       "                      -0.0336,  0.0895, -0.1193,  0.0646,  0.0435, -0.0450, -0.0918, -0.0034,\n",
       "                       0.0598, -0.0290, -0.0080, -0.1273, -0.0721, -0.0496,  0.1017, -0.0615,\n",
       "                      -0.0929, -0.0791, -0.1035, -0.0866,  0.0408,  0.0463,  0.0330, -0.0338,\n",
       "                       0.0038,  0.1118, -0.0425, -0.0085, -0.1160, -0.1272,  0.1083, -0.1057,\n",
       "                      -0.0190, -0.0532,  0.0936, -0.1047, -0.0678, -0.0175,  0.0231, -0.1110,\n",
       "                      -0.0454, -0.1276, -0.0544,  0.0010, -0.0835,  0.0564, -0.0448, -0.0680,\n",
       "                      -0.0659, -0.0384, -0.0407,  0.0676,  0.0977, -0.0561,  0.0730, -0.1137,\n",
       "                      -0.0183, -0.0091,  0.0625,  0.0242,  0.1023, -0.0832, -0.1198,  0.0227,\n",
       "                      -0.1101,  0.0391, -0.0469, -0.0692, -0.0425, -0.0321, -0.0474, -0.0635,\n",
       "                      -0.0720, -0.0425, -0.1254, -0.1251,  0.0252,  0.0086, -0.0425,  0.0998,\n",
       "                      -0.1248, -0.0966, -0.0370, -0.0352, -0.0234,  0.0070,  0.1133,  0.0793,\n",
       "                       0.0060, -0.0885,  0.1182, -0.0929, -0.0865, -0.0257, -0.0051, -0.0353,\n",
       "                       0.1008, -0.0302, -0.0211, -0.0364,  0.0422,  0.0064, -0.0803,  0.0749,\n",
       "                       0.0732,  0.0165, -0.0803, -0.0427, -0.0084, -0.0380,  0.0244, -0.1129],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 2.5465e-02, -4.2086e-02,  3.7688e-02,  ..., -3.8575e-02,\n",
       "                       -5.1735e-02, -1.2024e-01],\n",
       "                      [ 5.3402e-02, -1.0149e-01, -1.7311e-02,  ..., -8.9461e-02,\n",
       "                       -3.5742e-02, -2.7239e-02],\n",
       "                      [-3.0030e-05,  1.3240e-05, -5.6466e-06,  ...,  1.9189e-03,\n",
       "                       -3.0283e-03,  1.0675e-09],\n",
       "                      ...,\n",
       "                      [-6.7600e-03, -3.9082e-02, -5.5106e-02,  ...,  8.7849e-02,\n",
       "                       -1.3374e-01, -1.1362e-01],\n",
       "                      [-6.8570e-02, -1.0377e-01, -8.0102e-02,  ..., -6.2668e-02,\n",
       "                       -5.2141e-02, -1.7395e-02],\n",
       "                      [-9.5655e-02, -9.0036e-02,  8.3673e-02,  ..., -9.9011e-02,\n",
       "                       -1.2364e-01,  6.8014e-02]], device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.0699, -0.0412, -0.1148, -0.0456,  0.0828,  0.0625,  0.0595, -0.1152,\n",
       "                       0.0349, -0.0168, -0.0018, -0.0031, -0.0750,  0.0781,  0.0007, -0.0772,\n",
       "                       0.1418,  0.0712,  0.0687, -0.0775, -0.0047,  0.0039,  0.0541, -0.1106,\n",
       "                      -0.0611,  0.0181,  0.0945, -0.0775, -0.0776, -0.0608, -0.0904, -0.1034],\n",
       "                     device='cuda:0')),\n",
       "             ('out.weight',\n",
       "              tensor([[-0.0853,  0.0051,  0.0892,  0.0121,  0.0144,  0.0878, -0.0182, -0.1418,\n",
       "                        0.0951,  0.0618,  0.0511, -0.0408,  0.0065,  0.0863,  0.0118,  0.0474,\n",
       "                       -0.0509, -0.0011, -0.0341,  0.0973,  0.0110, -0.0901, -0.0303,  0.0430,\n",
       "                       -0.0677,  0.0308,  0.0832,  0.0764,  0.0593,  0.0772,  0.0465,  0.1065]],\n",
       "                     device='cuda:0')),\n",
       "             ('out.bias', tensor([0.0203], device='cuda:0'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644e8c4",
   "metadata": {},
   "source": [
    "- Create Encoder of WSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "263cdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeNorm(nn.Module): \n",
    "    # https://github.com/miafei/NodeNorm/blob/master/layers.py\n",
    "    def __init__(self, unbiased=False, eps=1e-5):\n",
    "        super(NodeNorm, self).__init__()\n",
    "        self.unbiased = unbiased\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        std = (torch.var(x, unbiased=self.unbiased, dim=1, keepdim=True) + self.eps).sqrt()\n",
    "        x = (x - mean) / std\n",
    "        return x\n",
    "\n",
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphEncoder,self).__init__()\n",
    "        \n",
    "        self.conv1 = SAGEConv(2048,256) # try lower, ex; 64 - then 0.7 pooling, then both\n",
    "        self.conv2 = SAGEConv(256,256)\n",
    "        self.conv3 = SAGEConv(256,256)\n",
    "        \n",
    "        self.norm = NodeNorm()\n",
    "        \n",
    "        self.pool = SAGPooling(256,0.3)\n",
    "        self.pool2 = SAGPooling(256,0.3)\n",
    "        self.pool3 = SAGPooling(256,0.3)\n",
    "        \n",
    "        self.fc = nn.Linear(1792,256) # 1792 = 256 x 7 (from demographic) -> for outer product\n",
    "        self.fc2 = nn.Linear(256,256)\n",
    "        self.fc3 = nn.Linear(256,32)\n",
    "        #self.out = nn.Linear(256,1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.jk = JumpingKnowledge(mode=\"max\")# max pooling jumping knowledge\n",
    "        \n",
    "    def forward(self, x, edge_index, batch, demogr):\n",
    "        \n",
    "        x = self.conv1(x,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm(x)\n",
    "        x,edge_index,edge_attr,batch,_, _ = self.pool(x,edge_index,batch=batch)\n",
    "        x1 = global_mean_pool(x,batch)\n",
    "        \n",
    "        x = self.conv2(x,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm(x)\n",
    "        x,edge_index,edge_attr,batch,_,_ = self.pool2(x,edge_index,batch=batch)\n",
    "        x2 = global_mean_pool(x,batch)\n",
    "        \n",
    "        x = self.conv3(x,edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm(x)\n",
    "        x,edge_index,edge_attr,batch,_, _ = self.pool3(x,edge_index,batch=batch)\n",
    "        x3 = global_mean_pool(x,batch)\n",
    "        \n",
    "        x = self.jk([x1, x2, x3])\n",
    "        x = outer(x, demogr)\n",
    "        \n",
    "        z = F.relu(self.fc(x))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = F.relu(self.fc3(z))\n",
    "        #hazard = self.out(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47d5f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_encoder = GraphEncoder().double()\n",
    "# self.double() is equivalent to self.to(torch.float64)\n",
    "# To transform all parameters and buffers of a module to float64 tensors, use model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42161095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['out.weight', 'out.bias'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsi_encoder.load_state_dict(graph_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a7995",
   "metadata": {},
   "source": [
    "### DNA Methylation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316e58e",
   "metadata": {},
   "source": [
    "- Load Pretrained Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a6caf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_state_dict = torch.load('/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/DNAm/Model_Saving/self_normalising_neural_networks_No_Dropout_with_AgeStandSexStage_MethyPhenoInteraction_CoxSelectedCpGs/model_best.pth', map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28765c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_layer.weight',\n",
       "              tensor([[-1.2237e-02,  1.8509e-02, -1.3463e-03,  ..., -6.9043e-03,\n",
       "                        6.2724e-03, -2.0016e-03],\n",
       "                      [-2.1274e-02,  7.8136e-03,  5.0463e-04,  ..., -7.1853e-03,\n",
       "                        5.8833e-04,  1.7078e-03],\n",
       "                      [-1.4273e-03, -1.8128e-03, -2.5361e-05,  ...,  9.5532e-04,\n",
       "                       -1.6643e-03,  1.1436e-03],\n",
       "                      ...,\n",
       "                      [-2.9441e-03, -1.9795e-02, -1.0337e-03,  ..., -1.8619e-03,\n",
       "                       -1.9366e-02,  6.2859e-04],\n",
       "                      [-1.2955e-02, -1.1432e-02, -8.0653e-04,  ..., -3.8350e-03,\n",
       "                        4.8401e-03, -1.8675e-03],\n",
       "                      [ 6.7060e-03, -2.4896e-03, -8.6429e-05,  ...,  6.6217e-03,\n",
       "                        6.5142e-03, -4.6955e-04]], device='cuda:0')),\n",
       "             ('input_layer.bias',\n",
       "              tensor([ 2.1097e-03,  9.5755e-03, -7.9015e-05, -6.0903e-04, -1.8484e-02,\n",
       "                      -5.7254e-03, -1.0619e-02, -1.3715e-03, -5.7922e-03,  6.6749e-03,\n",
       "                       1.4155e-02, -2.2344e-03, -1.0256e-02,  1.6234e-02, -6.9683e-04,\n",
       "                      -1.2234e-02, -1.9086e-02,  9.8589e-03,  2.1296e-03,  7.3085e-03,\n",
       "                       1.3122e-02,  1.8925e-02,  1.1904e-02,  5.5825e-03,  3.1632e-03,\n",
       "                       5.0380e-05,  1.1669e-04,  1.3965e-02,  2.5308e-03,  2.1220e-02,\n",
       "                      -3.4491e-03,  5.1861e-03,  1.1380e-02, -4.2715e-03,  2.2814e-03,\n",
       "                      -8.0783e-03,  1.0025e-02, -6.1282e-03, -5.4770e-03, -1.0823e-03,\n",
       "                      -1.0029e-02,  3.7323e-03, -1.0023e-02,  1.5061e-02, -1.3677e-02,\n",
       "                      -1.1639e-02,  2.1817e-03, -1.8584e-02, -9.6820e-04,  2.8759e-04,\n",
       "                      -1.3816e-03,  9.1198e-03,  1.5549e-02,  1.6698e-03, -1.0270e-03,\n",
       "                      -1.8219e-02,  3.7847e-03, -8.9723e-03, -5.6841e-03,  1.8566e-02,\n",
       "                      -1.0281e-03,  3.1158e-03, -1.4057e-04,  2.8812e-03, -8.7964e-03,\n",
       "                      -1.4786e-03,  9.1404e-03, -6.7033e-03, -1.4219e-02,  3.3384e-04,\n",
       "                       5.0450e-03, -1.3414e-02,  1.7168e-02, -8.2665e-04, -1.2783e-03,\n",
       "                       1.5959e-02, -6.5999e-03,  9.7424e-04,  1.9100e-03,  8.9571e-03,\n",
       "                      -6.2426e-03, -7.0758e-03, -8.3550e-03, -1.1734e-02, -3.0673e-03,\n",
       "                      -7.3424e-03,  9.1545e-04,  6.7831e-03,  2.0013e-03, -2.1560e-03,\n",
       "                       1.4905e-03, -2.4750e-03,  4.4915e-03,  7.3525e-03, -1.6001e-02,\n",
       "                       1.8561e-03,  1.0330e-02,  1.7135e-02,  3.7351e-03,  3.3042e-03,\n",
       "                      -2.9688e-03,  3.5733e-03,  6.3050e-03, -3.3018e-03,  5.9455e-03,\n",
       "                      -1.4738e-04, -7.7224e-04,  2.1214e-03,  4.7908e-04, -9.0337e-03,\n",
       "                       7.9988e-03,  1.7170e-02,  1.7895e-03, -2.4996e-02, -1.1973e-03,\n",
       "                       3.4987e-03,  4.3864e-03,  6.2498e-03, -6.7448e-04, -5.8431e-03,\n",
       "                       1.2959e-02,  1.6419e-02, -8.6032e-03, -2.0321e-03, -5.8959e-03,\n",
       "                       2.2246e-03,  1.0532e-03,  1.2203e-02,  5.5620e-03,  1.7329e-02,\n",
       "                       4.6936e-05,  2.3263e-03, -2.0897e-02,  1.4874e-02,  2.3792e-03,\n",
       "                      -1.3655e-02,  2.6357e-03, -1.2619e-02,  4.0084e-03, -1.4594e-02,\n",
       "                      -7.6100e-03, -3.8684e-04,  3.7987e-03,  1.9077e-02, -2.4174e-03,\n",
       "                       8.5378e-04,  1.4218e-02, -8.4850e-03, -1.0559e-02,  4.6866e-03,\n",
       "                      -6.8410e-03,  4.3737e-03, -1.5090e-03, -5.6705e-03,  1.5007e-02,\n",
       "                      -1.9490e-03,  4.2824e-03,  9.9466e-03, -1.8536e-02,  5.4081e-03,\n",
       "                       2.2672e-03, -7.5446e-03,  1.6555e-04,  1.2197e-03,  5.5293e-03,\n",
       "                       7.6066e-03, -4.5522e-04,  7.4225e-04,  1.9200e-02,  4.2398e-03,\n",
       "                       7.9984e-03,  7.4444e-03, -7.2279e-03, -5.4665e-03, -4.8970e-03,\n",
       "                       2.0406e-04,  7.7163e-04,  4.6649e-03,  7.7261e-03,  1.4484e-03,\n",
       "                       6.6016e-03,  1.1850e-02, -2.0967e-02,  1.0223e-02,  7.8495e-03,\n",
       "                       7.8315e-03, -2.5094e-03,  3.3787e-03,  1.4482e-02, -1.1655e-02,\n",
       "                      -3.2755e-03,  1.7698e-03, -6.1422e-03, -9.5176e-03, -1.0966e-02,\n",
       "                       1.4933e-03,  9.3528e-04, -9.4931e-03,  1.5541e-04,  1.6068e-02,\n",
       "                       2.4692e-03, -3.8811e-03,  6.7443e-03,  2.6620e-03,  5.5527e-03,\n",
       "                      -7.7177e-03,  1.5118e-02,  3.6460e-03, -9.7144e-03,  2.2078e-03,\n",
       "                      -9.6285e-03,  1.1218e-02, -1.0857e-03, -1.0368e-02,  9.6157e-03,\n",
       "                      -1.7828e-02,  6.7770e-03,  4.8941e-03, -7.8711e-03,  6.5536e-03,\n",
       "                      -1.1448e-03,  4.4275e-04,  1.7760e-02,  8.4230e-03,  2.4862e-03,\n",
       "                       1.7261e-02, -8.7505e-04, -1.0075e-03, -7.7158e-03, -4.9450e-03,\n",
       "                      -6.9752e-03,  6.4242e-03, -1.6765e-02,  1.4900e-03, -9.4979e-03,\n",
       "                       4.6703e-03, -7.2623e-03, -1.1936e-02,  4.4352e-03,  5.2495e-03,\n",
       "                      -2.6354e-03,  1.3280e-02, -2.2279e-02,  6.2197e-03,  1.0048e-02,\n",
       "                       1.5167e-03,  6.3554e-03,  5.2142e-03,  3.7483e-03, -1.2910e-02,\n",
       "                       2.2077e-03, -2.2464e-03,  7.7705e-03, -7.0661e-03,  2.0390e-03,\n",
       "                      -1.1085e-02,  6.2662e-03,  5.9874e-03, -1.9147e-02,  2.3263e-03,\n",
       "                       1.8215e-02,  2.1982e-03, -1.0176e-03, -1.4066e-03, -1.7466e-02,\n",
       "                       3.2325e-03, -1.0526e-03, -1.5792e-03,  5.6096e-03,  1.1820e-02,\n",
       "                      -5.8868e-04, -1.5079e-02,  4.8493e-04, -7.5013e-03, -1.1495e-02,\n",
       "                      -9.7877e-03, -1.8922e-03,  8.8735e-04,  5.8138e-03, -9.3715e-03,\n",
       "                      -6.2431e-03, -9.6409e-03, -1.7462e-02,  1.8906e-02, -6.6486e-03,\n",
       "                      -1.6925e-02,  6.4954e-04,  1.3756e-02,  3.3416e-03, -4.6561e-03,\n",
       "                       8.4118e-03,  7.3689e-04,  1.5423e-02, -1.3245e-02, -5.9708e-03,\n",
       "                      -1.4812e-02,  8.0796e-03,  3.1934e-03,  7.5994e-03,  2.9331e-04,\n",
       "                       7.1777e-03, -7.5716e-04,  7.6480e-03, -2.4384e-03, -5.8463e-04,\n",
       "                       9.2645e-03, -1.2622e-02, -6.5272e-03,  7.2829e-03,  1.4600e-03,\n",
       "                       8.6198e-03, -7.2817e-03, -1.2970e-02,  9.6400e-03, -1.5293e-02,\n",
       "                      -1.1739e-02, -6.7703e-03,  8.1849e-03,  4.7195e-03,  3.8418e-03,\n",
       "                       4.6945e-05, -7.1717e-03, -1.0973e-02,  4.5303e-03,  1.7208e-02,\n",
       "                      -4.7859e-03,  5.8240e-04,  7.2271e-03, -1.2486e-02,  1.3140e-04,\n",
       "                       9.1374e-03,  1.1927e-04,  1.0997e-03,  4.1646e-03, -1.1645e-02,\n",
       "                      -7.2363e-04,  9.2887e-04, -1.5858e-02, -4.9536e-03,  6.4670e-04,\n",
       "                      -5.3272e-04, -1.1009e-02, -1.2503e-02,  4.2915e-03, -7.6522e-03,\n",
       "                       6.2079e-03,  1.6344e-03,  1.4088e-02,  1.1629e-02, -9.9706e-03,\n",
       "                      -1.8939e-02, -1.7549e-03, -1.9124e-02, -4.8941e-03,  1.4864e-04,\n",
       "                      -3.3819e-03, -9.6911e-03,  3.9131e-03,  2.4825e-03,  1.5223e-03,\n",
       "                      -1.7998e-02,  3.2270e-03, -1.2778e-02, -5.2623e-03, -2.3919e-03,\n",
       "                       6.4860e-03,  1.5448e-02, -5.7397e-03,  2.1659e-03,  1.1425e-02,\n",
       "                       9.8476e-03, -1.0712e-02, -2.2769e-03,  4.8532e-03, -1.8945e-02,\n",
       "                       2.5662e-03,  2.8445e-03, -8.2046e-04, -2.7057e-03, -8.0624e-03,\n",
       "                      -1.4510e-02,  2.7584e-03, -4.1037e-04,  8.1133e-03, -3.7806e-04,\n",
       "                      -8.3208e-03,  1.4288e-03,  5.4385e-03,  4.0159e-03,  2.1306e-03,\n",
       "                      -2.7626e-02,  2.1917e-03, -3.5677e-04, -8.1100e-03,  3.2976e-03,\n",
       "                       6.7287e-03,  1.1840e-02,  1.2954e-02,  1.1364e-02, -1.3821e-02,\n",
       "                       5.8537e-03, -1.6501e-02, -9.7073e-03,  1.2398e-02, -4.7226e-03,\n",
       "                      -1.5783e-02, -1.9718e-02,  5.9305e-03, -1.7697e-02,  1.0554e-02,\n",
       "                       3.4057e-03, -6.5726e-03,  4.6761e-03, -1.4502e-03,  1.5603e-02,\n",
       "                       2.2334e-02, -8.3268e-03,  1.5516e-04, -1.0878e-02, -3.0504e-03,\n",
       "                       1.3106e-03, -2.0200e-03, -5.8883e-03, -7.5172e-03, -8.2053e-03,\n",
       "                      -7.6387e-03,  8.9778e-03,  2.6406e-03,  8.1319e-03, -2.1466e-03,\n",
       "                      -1.1778e-02, -2.3308e-02,  1.8594e-02,  7.4881e-03,  2.1955e-03,\n",
       "                      -1.5203e-03, -1.0526e-04, -1.5739e-02,  1.4925e-02, -8.5867e-03,\n",
       "                      -1.6836e-02, -3.0783e-03, -1.9200e-03, -6.2285e-04,  5.4937e-03,\n",
       "                       1.3653e-03,  1.4241e-02, -1.4934e-02,  1.2007e-03,  2.8318e-03,\n",
       "                      -1.9870e-02, -1.7470e-02, -8.8023e-03,  3.9439e-03,  2.7626e-03,\n",
       "                      -1.9169e-02,  1.8295e-02, -3.8934e-03,  1.2510e-03, -5.5513e-03,\n",
       "                      -7.9627e-03, -3.9762e-03,  1.3892e-02, -7.1646e-03,  4.0208e-03,\n",
       "                       1.3167e-02,  4.8169e-03, -2.0420e-02, -1.5648e-02, -3.9825e-03,\n",
       "                      -1.6057e-03, -1.4738e-02,  6.2301e-04,  2.0455e-03, -6.8785e-03,\n",
       "                      -3.6813e-03,  1.2214e-02,  3.2978e-03, -1.2741e-03,  2.7251e-03,\n",
       "                       1.6693e-02, -8.8653e-03,  3.4522e-03, -1.4271e-03, -5.4109e-03,\n",
       "                      -1.2220e-02, -1.9697e-03, -9.5623e-03,  5.2618e-03,  2.1302e-03,\n",
       "                      -1.1630e-02, -6.6143e-03, -1.7948e-03,  2.2969e-03, -8.2180e-03,\n",
       "                      -1.2820e-03, -9.6044e-03, -1.2396e-02,  1.5355e-03,  8.8322e-03,\n",
       "                       5.0310e-03,  2.2729e-03, -1.7629e-03, -3.6840e-03, -2.1506e-02,\n",
       "                       2.9082e-03,  9.5656e-04, -3.0112e-03, -9.4646e-03,  9.9568e-03,\n",
       "                      -5.8621e-03, -1.0885e-03], device='cuda:0')),\n",
       "             ('hidden_layers.0.weight',\n",
       "              tensor([[ 2.2646e-02,  1.7619e-03, -2.7089e-03,  ..., -4.6199e-03,\n",
       "                        1.7723e-02, -4.9834e-03],\n",
       "                      [-1.2033e-02,  6.6284e-03, -1.7161e-02,  ..., -2.8535e-02,\n",
       "                       -7.6436e-03,  3.4992e-03],\n",
       "                      [-8.9934e-04,  2.0099e-04, -6.4014e-05,  ..., -2.3684e-03,\n",
       "                       -1.1522e-03,  1.3787e-04],\n",
       "                      ...,\n",
       "                      [-1.0194e-02,  6.5186e-03, -4.0461e-05,  ...,  9.3478e-03,\n",
       "                       -1.5064e-02, -7.9628e-03],\n",
       "                      [-8.4206e-03, -7.8428e-04, -5.8885e-03,  ..., -2.3544e-03,\n",
       "                       -1.7658e-02, -8.3972e-04],\n",
       "                      [-5.5909e-04,  1.1156e-04, -2.1887e-04,  ...,  1.9918e-04,\n",
       "                        9.6598e-04, -5.1472e-05]], device='cuda:0')),\n",
       "             ('hidden_layers.0.bias',\n",
       "              tensor([-0.0080, -0.0046,  0.0023, -0.0069,  0.0129,  0.0103, -0.0125,  0.0242,\n",
       "                       0.0067,  0.0005,  0.0161, -0.0092, -0.0052,  0.0014,  0.0009, -0.0064,\n",
       "                       0.0236,  0.0041,  0.0182,  0.0129,  0.0079, -0.0005,  0.0057,  0.0017,\n",
       "                      -0.0054, -0.0049,  0.0097,  0.0020,  0.0080, -0.0123, -0.0163,  0.0079,\n",
       "                      -0.0261,  0.0107, -0.0053,  0.0022,  0.0024, -0.0079, -0.0173, -0.0219,\n",
       "                       0.0110, -0.0297,  0.0008, -0.0018, -0.0133,  0.0116,  0.0079, -0.0017,\n",
       "                       0.0108,  0.0142, -0.0111, -0.0011, -0.0111,  0.0007, -0.0097,  0.0052,\n",
       "                      -0.0026,  0.0032, -0.0098, -0.0034, -0.0287, -0.0158, -0.0145, -0.0037,\n",
       "                      -0.0073, -0.0026, -0.0223,  0.0053,  0.0044,  0.0192, -0.0174, -0.0171,\n",
       "                      -0.0008,  0.0077, -0.0003, -0.0189, -0.0012, -0.0214,  0.0053, -0.0325,\n",
       "                      -0.0083,  0.0028, -0.0115,  0.0160, -0.0043, -0.0121,  0.0147,  0.0109,\n",
       "                      -0.0127,  0.0100, -0.0137, -0.0215, -0.0107,  0.0033, -0.0108, -0.0097,\n",
       "                       0.0070, -0.0026,  0.0003,  0.0213,  0.0098, -0.0143,  0.0103,  0.0056,\n",
       "                      -0.0196, -0.0025, -0.0005, -0.0044, -0.0018,  0.0011, -0.0252, -0.0028,\n",
       "                      -0.0053, -0.0216,  0.0207, -0.0130, -0.0056, -0.0135,  0.0155,  0.0133,\n",
       "                       0.0072, -0.0016, -0.0008, -0.0010,  0.0014,  0.0074,  0.0091, -0.0069,\n",
       "                       0.0068,  0.0193, -0.0005, -0.0158, -0.0030, -0.0106,  0.0292,  0.0023,\n",
       "                      -0.0024, -0.0040, -0.0195,  0.0037,  0.0049, -0.0095,  0.0196,  0.0106,\n",
       "                      -0.0136, -0.0102, -0.0209, -0.0176,  0.0154, -0.0069, -0.0050, -0.0099,\n",
       "                       0.0154,  0.0049, -0.0146,  0.0163, -0.0054, -0.0261, -0.0004,  0.0252,\n",
       "                       0.0013, -0.0294, -0.0059,  0.0016, -0.0187, -0.0110, -0.0104, -0.0122,\n",
       "                       0.0262,  0.0073, -0.0013,  0.0059, -0.0008, -0.0131, -0.0262, -0.0126,\n",
       "                      -0.0078, -0.0083,  0.0074,  0.0001, -0.0002, -0.0057,  0.0068, -0.0241,\n",
       "                       0.0272,  0.0046,  0.0087,  0.0098,  0.0117, -0.0113,  0.0018, -0.0363,\n",
       "                       0.0053, -0.0111,  0.0067, -0.0094, -0.0153,  0.0178, -0.0015, -0.0083,\n",
       "                       0.0042,  0.0075,  0.0130, -0.0169, -0.0151, -0.0226,  0.0183,  0.0140,\n",
       "                      -0.0259, -0.0304, -0.0196,  0.0063,  0.0015,  0.0004,  0.0039, -0.0265,\n",
       "                       0.0031, -0.0090,  0.0115,  0.0061, -0.0251, -0.0090,  0.0011, -0.0093,\n",
       "                      -0.0154, -0.0011,  0.0085, -0.0061,  0.0159, -0.0005,  0.0120, -0.0165,\n",
       "                      -0.0192,  0.0086,  0.0076,  0.0091, -0.0073,  0.0247,  0.0027,  0.0193,\n",
       "                       0.0016,  0.0079, -0.0150,  0.0163, -0.0056, -0.0155,  0.0008, -0.0097,\n",
       "                       0.0022, -0.0179, -0.0049,  0.0143, -0.0132, -0.0220, -0.0110,  0.0034],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden_layers.1.weight',\n",
       "              tensor([[-1.0527e-02,  2.5756e-02, -5.2101e-05,  ...,  1.1145e-02,\n",
       "                        1.0028e-02,  5.2271e-03],\n",
       "                      [-3.6894e-03,  7.3654e-03,  2.8188e-04,  ...,  1.0041e-03,\n",
       "                       -1.7661e-03, -1.5192e-03],\n",
       "                      [-2.1751e-03,  3.2951e-02, -2.6392e-03,  ...,  1.7816e-02,\n",
       "                        9.7078e-03, -8.7589e-03],\n",
       "                      ...,\n",
       "                      [ 1.3050e-02, -2.5393e-02,  3.5919e-04,  ..., -2.7451e-03,\n",
       "                       -2.2843e-03,  7.1458e-05],\n",
       "                      [-7.8984e-03,  1.8627e-03, -3.1201e-04,  ..., -4.5420e-03,\n",
       "                       -1.1428e-02, -1.8099e-03],\n",
       "                      [ 1.4079e-03, -4.3156e-04,  5.0548e-05,  ..., -4.1817e-04,\n",
       "                       -6.1306e-04, -6.9868e-05]], device='cuda:0')),\n",
       "             ('hidden_layers.1.bias',\n",
       "              tensor([ 0.0306,  0.0015,  0.0015,  0.0252, -0.0289, -0.0111, -0.0064,  0.0188,\n",
       "                       0.0064,  0.0104, -0.0365, -0.0102, -0.0392,  0.0309, -0.0264, -0.0117,\n",
       "                      -0.0181, -0.0264,  0.0001, -0.0213, -0.0181,  0.0048,  0.0130,  0.0057,\n",
       "                      -0.0013, -0.0104, -0.0011, -0.0259,  0.0115, -0.0263, -0.0273, -0.0230,\n",
       "                       0.0048, -0.0055,  0.0177,  0.0119, -0.0048,  0.0217, -0.0037, -0.0073,\n",
       "                      -0.0241, -0.0339, -0.0056,  0.0068, -0.0398, -0.0146, -0.0086, -0.0320,\n",
       "                      -0.0122, -0.0226,  0.0030, -0.0320, -0.0003,  0.0106, -0.0267, -0.0236,\n",
       "                       0.0270, -0.0281, -0.0155, -0.0268,  0.0003, -0.0008, -0.0331,  0.0088,\n",
       "                       0.0075,  0.0060,  0.0139,  0.0038, -0.0110,  0.0059, -0.0417, -0.0352,\n",
       "                      -0.0031, -0.0171,  0.0088, -0.0333,  0.0183, -0.0106, -0.0310,  0.0153,\n",
       "                       0.0272,  0.0002,  0.0099, -0.0061, -0.0199,  0.0028, -0.0357,  0.0241,\n",
       "                      -0.0476,  0.0177, -0.0126, -0.0210, -0.0214,  0.0043, -0.0261,  0.0118,\n",
       "                      -0.0266,  0.0052, -0.0302,  0.0127, -0.0045,  0.0051, -0.0337, -0.0029,\n",
       "                      -0.0247, -0.0079, -0.0145, -0.0416, -0.0023, -0.0193, -0.0212,  0.0190,\n",
       "                      -0.0450,  0.0036,  0.0339,  0.0092, -0.0400,  0.0220, -0.0114, -0.0268,\n",
       "                       0.0143,  0.0345,  0.0210,  0.0011, -0.0083,  0.0149, -0.0106,  0.0025],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden_layers.2.weight',\n",
       "              tensor([[ 0.0096,  0.0188, -0.0317,  ...,  0.0630, -0.0093,  0.0045],\n",
       "                      [-0.0093, -0.0095, -0.0165,  ...,  0.0145, -0.0038,  0.0041],\n",
       "                      [ 0.0027,  0.0242,  0.0224,  ..., -0.0517, -0.0215, -0.0064],\n",
       "                      ...,\n",
       "                      [ 0.0006, -0.0053, -0.0012,  ...,  0.0023, -0.0037,  0.0002],\n",
       "                      [ 0.0159,  0.0026,  0.0284,  ...,  0.0017,  0.0152, -0.0012],\n",
       "                      [-0.0142, -0.0106, -0.0575,  ...,  0.0546, -0.0214,  0.0030]],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden_layers.2.bias',\n",
       "              tensor([ 0.0275, -0.0033, -0.0448,  0.0206, -0.0443,  0.0241, -0.0110, -0.0085,\n",
       "                      -0.0071, -0.0300, -0.0270, -0.0182,  0.0320,  0.0236, -0.0206, -0.0260,\n",
       "                       0.0014,  0.0477,  0.0088,  0.0201,  0.0298, -0.0093, -0.0049, -0.0630,\n",
       "                      -0.0071, -0.0137, -0.0163, -0.0394, -0.0598,  0.0308, -0.0238,  0.0175,\n",
       "                      -0.0303, -0.0057,  0.0465, -0.0358, -0.0086,  0.0388, -0.0106, -0.0234,\n",
       "                       0.0081, -0.0543,  0.0414, -0.0145, -0.0188, -0.0468, -0.0493, -0.0035,\n",
       "                       0.0079,  0.0442,  0.0167, -0.0250, -0.0335,  0.0022,  0.0069, -0.0090,\n",
       "                      -0.0024, -0.0185,  0.0010, -0.0428,  0.0429, -0.0211, -0.0245, -0.0274],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden_layers.3.weight',\n",
       "              tensor([[-0.0235,  0.0069,  0.0854,  ...,  0.0154,  0.0245, -0.0909],\n",
       "                      [-0.0028, -0.0007,  0.0019,  ..., -0.0073, -0.0124,  0.0347],\n",
       "                      [-0.0760, -0.0927, -0.0532,  ..., -0.0357, -0.0083, -0.0632],\n",
       "                      ...,\n",
       "                      [ 0.0045, -0.0228, -0.1101,  ..., -0.0294, -0.0473,  0.0159],\n",
       "                      [-0.0207,  0.0103,  0.0192,  ...,  0.0072, -0.0100, -0.0049],\n",
       "                      [ 0.0154,  0.0291, -0.0099,  ...,  0.0097, -0.0531,  0.0229]],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden_layers.3.bias',\n",
       "              tensor([ 1.3825e-02,  1.0186e-04, -1.5609e-02, -1.6581e-02,  3.6815e-02,\n",
       "                      -1.6815e-02, -6.1277e-02,  3.6280e-02,  3.2117e-02, -2.5590e-02,\n",
       "                       1.9281e-02,  3.4274e-02,  1.4077e-02,  4.7967e-02,  3.3045e-02,\n",
       "                      -6.6248e-02, -4.9041e-02,  5.4910e-02,  2.8043e-02,  2.2189e-05,\n",
       "                       2.4627e-03,  2.5091e-02, -1.8858e-02, -2.8103e-02, -4.0257e-03,\n",
       "                       3.6404e-02,  5.4838e-02,  5.6410e-02,  7.9067e-02,  5.3800e-02,\n",
       "                      -6.9391e-04,  5.3211e-02], device='cuda:0')),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-0.1285,  0.0005, -0.1194,  0.1549, -0.0596,  0.0696,  0.1638,  0.0547,\n",
       "                        0.0708,  0.0871, -0.0908, -0.1292,  0.0831,  0.0935, -0.1450, -0.1351,\n",
       "                       -0.1778, -0.1930,  0.0575,  0.0230, -0.1113,  0.0969, -0.0460, -0.0774,\n",
       "                       -0.0624, -0.1425, -0.1948,  0.0732, -0.1230,  0.1381,  0.0247,  0.0770]],\n",
       "                     device='cuda:0')),\n",
       "             ('output_layer.bias', tensor([4.2581e-07], device='cuda:0'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAm_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad6898",
   "metadata": {},
   "source": [
    "- Create Encoder of DNAm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "739c2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNAmEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DNAmEncoder, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "        #self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "        self.selu = nn.SELU()\n",
    "        \n",
    "        self.dropout = nn.AlphaDropout(0.2)\n",
    "    \n",
    "    def forward(self, a, b):\n",
    "        x = outer(a, b) # use outer product to get the interaction term (2nd order) between a and b (1st order)\n",
    "        x = self.selu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.selu(layer(x))\n",
    "        #x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf154860",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_encoder = DNAmEncoder(input_size = len(DNAm_Data_train.__getitem__(1)[0])*len(DNAm_Data_train.__getitem__(2)[1]), \n",
    "                           hidden_sizes = [512, 256, 128, 64, 32], \n",
    "                           output_size = 1).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96eb1076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['output_layer.weight', 'output_layer.bias'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAm_encoder.load_state_dict(DNAm_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91667c33",
   "metadata": {},
   "source": [
    "### HiTIMED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5dd05",
   "metadata": {},
   "source": [
    "- Load Pretrained Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b77505e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HiTIMED_state_dict = torch.load('/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/HiTIMED/Model_Saving/No_Dropout_with_AgeStandSexStage_CellPhenoInteraction/model_best.pth', map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcc5ea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_layer.weight',\n",
       "              tensor([[-0.1308,  0.0645, -0.0009,  ..., -0.0048, -0.1004, -0.0590],\n",
       "                      [-0.0685,  0.0467, -0.0676,  ...,  0.1801,  0.0233, -0.0017],\n",
       "                      [ 0.0065, -0.1329,  0.1967,  ...,  0.3356,  0.0911, -0.0187],\n",
       "                      ...,\n",
       "                      [-0.1026,  0.0764,  0.0295,  ..., -0.0297,  0.0640, -0.0605],\n",
       "                      [-0.1162,  0.0783, -0.0867,  ..., -0.0596,  0.2322,  0.0220],\n",
       "                      [-0.0858,  0.0363, -0.0085,  ...,  0.1014, -0.1380, -0.0527]],\n",
       "                     device='cuda:0')),\n",
       "             ('input_layer.bias',\n",
       "              tensor([-1.1542e-01, -2.8186e-04, -5.1804e-02, -3.5750e-03, -1.2161e-01,\n",
       "                      -3.0322e-02, -2.0715e-02, -1.6112e-02,  2.8139e-02, -7.8413e-02,\n",
       "                      -1.1794e-01, -1.5811e-01, -1.4265e-01, -8.4523e-02, -3.3547e-02,\n",
       "                      -1.1752e-01, -1.8095e-01,  2.0527e-02, -2.4520e-01, -1.0212e-01,\n",
       "                       1.3608e-01, -6.1452e-03, -1.2879e-01, -1.4390e-01, -6.8467e-03,\n",
       "                      -1.7142e-01,  1.6212e-03,  4.8625e-04,  5.5550e-02,  3.2750e-03,\n",
       "                      -4.1837e-02, -8.3962e-02,  1.1969e-02, -1.5761e-01, -1.2635e-01,\n",
       "                      -1.4021e-01, -3.0017e-02, -9.7508e-02, -9.2368e-02,  4.1614e-02,\n",
       "                       2.9892e-02, -5.0885e-02, -1.1899e-03,  4.8284e-02,  2.9355e-02,\n",
       "                      -4.1801e-02, -1.1579e-01, -2.9213e-01, -7.5079e-02, -9.5073e-02,\n",
       "                      -1.4359e-01,  1.7161e-02,  3.1260e-02, -1.7241e-01, -5.0468e-02,\n",
       "                      -2.3392e-01, -1.7696e-01, -7.8031e-02,  2.0708e-02, -6.8402e-03,\n",
       "                      -1.8387e-01, -4.9962e-02,  7.1702e-03, -1.1559e-01], device='cuda:0')),\n",
       "             ('hidden_layers.0.weight',\n",
       "              tensor([[ 9.4837e-02,  8.6327e-02,  9.8311e-02,  ..., -2.2931e-04,\n",
       "                        6.4559e-02, -2.4224e-01],\n",
       "                      [-5.2142e-02,  6.9211e-02,  5.3437e-02,  ...,  5.2501e-02,\n",
       "                       -1.0089e-01,  6.3143e-02],\n",
       "                      [ 2.5517e-02, -1.3403e-01, -4.6979e-02,  ..., -9.8168e-02,\n",
       "                       -1.1544e-01, -1.5585e-01],\n",
       "                      ...,\n",
       "                      [-6.2813e-02, -1.0991e-01,  1.1996e-01,  ..., -1.1755e-01,\n",
       "                        6.3164e-02, -1.7131e-01],\n",
       "                      [ 6.5237e-02, -2.0250e-01, -4.5688e-02,  ..., -5.9231e-02,\n",
       "                       -1.5829e-01,  1.2403e-01],\n",
       "                      [ 6.9185e-02,  6.8889e-02, -3.5215e-03,  ..., -5.0168e-01,\n",
       "                        1.2369e-01, -1.7523e-01]], device='cuda:0')),\n",
       "             ('hidden_layers.0.bias',\n",
       "              tensor([-1.9993e-01, -3.1551e-02,  5.2005e-02, -2.7783e-01,  5.8852e-03,\n",
       "                      -1.1925e-01, -8.1723e-02, -1.0062e-01,  2.1235e-02, -1.4176e-01,\n",
       "                       6.5704e-02, -7.7256e-02, -1.4658e-01, -1.4394e-01,  9.4476e-02,\n",
       "                       2.2755e-02, -1.2333e-01, -4.9031e-03,  1.0605e-01,  2.2220e-02,\n",
       "                      -1.3695e-01, -1.6920e-01, -2.6687e-02,  1.1031e-01, -2.7716e-04,\n",
       "                       1.2428e-01,  3.9792e-02, -7.4985e-02, -4.4923e-02, -1.0307e-01,\n",
       "                       1.0637e-02,  6.8164e-02], device='cuda:0')),\n",
       "             ('hidden_layers.1.weight',\n",
       "              tensor([[-0.1962, -0.0630,  0.1505,  ...,  0.0688, -0.1478, -0.1362],\n",
       "                      [-0.0302, -0.0096, -0.0972,  ...,  0.0904, -0.0748,  0.0927],\n",
       "                      [-0.0007, -0.1552, -0.1717,  ...,  0.1025, -0.1268, -0.0234],\n",
       "                      ...,\n",
       "                      [ 0.2114,  0.1441,  0.2008,  ...,  0.2298, -0.3252,  0.2086],\n",
       "                      [-0.0097,  0.0789,  0.1385,  ...,  0.0712,  0.0445, -0.1413],\n",
       "                      [-0.0053, -0.1501, -0.0131,  ...,  0.1261,  0.0989, -0.0669]],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden_layers.1.bias',\n",
       "              tensor([-0.0544,  0.0368, -0.1711, -0.2121, -0.1076,  0.3005,  0.2747,  0.0100,\n",
       "                       0.0846, -0.2439, -0.1858,  0.0576,  0.0110, -0.0732,  0.1953,  0.0672,\n",
       "                       0.0172, -0.0176,  0.1788, -0.0761,  0.0723, -0.1038, -0.3451, -0.0164,\n",
       "                      -0.1100, -0.1233,  0.3298,  0.0282,  0.0248,  0.1154, -0.0951, -0.1388],\n",
       "                     device='cuda:0')),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-0.0243, -0.1017,  0.0534,  0.0079,  0.0315,  0.1767, -0.0819, -0.0575,\n",
       "                        0.0021,  0.1431,  0.1011, -0.1938, -0.2399, -0.0106,  0.1378,  0.0924,\n",
       "                       -0.0123,  0.0546, -0.1470, -0.0395, -0.1860,  0.1341, -0.0311, -0.0797,\n",
       "                        0.0385, -0.1371,  0.1212,  0.1250, -0.2532, -0.1798, -0.0255,  0.0226]],\n",
       "                     device='cuda:0')),\n",
       "             ('output_layer.bias', tensor([0.1281], device='cuda:0'))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiTIMED_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c00d7",
   "metadata": {},
   "source": [
    "- Create Encoder of HiTIMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a17929f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiTIMED_Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super(HiTIMED_Encoder, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "        #self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = outer(x, y)\n",
    "        x = self.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.relu(layer(x))\n",
    "        #x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c557832",
   "metadata": {},
   "outputs": [],
   "source": [
    "HiTIMED_encoder = HiTIMED_Encoder(input_size = len(HiTIMED_Data_train.__getitem__(2)[0])*len(HiTIMED_Data_train.__getitem__(2)[1]),\n",
    "                                  hidden_sizes = [64,32,32]).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df92d485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['output_layer.weight', 'output_layer.bias'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HiTIMED_encoder.load_state_dict(HiTIMED_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in HiTIMED_encoder.named_parameters():\n",
    "    print(name)\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14475d3c",
   "metadata": {},
   "source": [
    "- Freeze the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdd6dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [HiTIMED_encoder, DNAm_encoder, wsi_encoder]\n",
    "for m in encoders:\n",
    "    for param in m.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e75f5a6",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23407459",
   "metadata": {},
   "source": [
    "- nn.Bilinear: A bilinear function is a function of two inputs 𝑥 and 𝑦 that is linear in each input separately. \n",
    "https://datascience.stackexchange.com/questions/31641/what-is-difference-between-fully-connected-layer-and-bilinear-layer-in-cnn\n",
    "\n",
    "Simple bilinear functions on vectors are the dot product or the element-wise product. Performs a bilinear transformation. It computes a bilinear product between the input tensors, allowing for interactions between different modalities or features within the data. Imagine a bilinear tensor layer as a way for the neural network to capture complex interactions and relationships between different modalities or features in the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44280d77",
   "metadata": {},
   "source": [
    "- torch.bmm: PyTorch bmm is used for matrix multiplication in batches where the scenario involves that the matrices to be multiplied have the size of 3 dimensions that is x, y, and z and the dimension of the first dimension for matrices to be multiplied should be the same.\n",
    "https://www.educba.com/pytorch-bmm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784aeb76",
   "metadata": {},
   "source": [
    "- torch.unsqueeze: a method used to change the dimensions of a tensor. By using Pytorch unsqueeze, we can insert a new tensor at a specific location\n",
    "https://www.educba.com/pytorch-unsqueeze/\n",
    "\n",
    "https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f8925cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalPairwiseTrilinear(nn.Module):\n",
    "    def __init__(self, HiTIMEDEncoder, DNAMEncoder, WSIEncoder, HiTIMEDdim, DNAMdim, WSIdim, hidden_dim):\n",
    "        super(MultimodalPairwiseTrilinear,self).__init__()\n",
    "        self.HiTIMEDEncoder = HiTIMEDEncoder\n",
    "        self.DNAMEncoder = DNAMEncoder\n",
    "        self.WSIEncoder = WSIEncoder\n",
    "        \n",
    "        self.HiTIMED_project = nn.Linear(HiTIMEDdim,hidden_dim)\n",
    "        self.dnam_project = nn.Linear(DNAMdim,hidden_dim)\n",
    "        self.wsi_project = nn.Linear(WSIdim,hidden_dim)\n",
    "        \n",
    "        self.linear_z1 = nn.Bilinear(hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.linear_o1 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(p=0.4))\n",
    "\n",
    "        self.linear_z2 = nn.Bilinear(hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.linear_o2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(p=0.4))\n",
    "\n",
    "        self.linear_z3 = nn.Bilinear(hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.linear_o3 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(p=0.4))\n",
    "\n",
    "        self.post_fusion_dropout = nn.Dropout(p=0.25)\n",
    "        self.encoder1 = nn.Sequential(nn.Linear((hidden_dim+1)*(hidden_dim+1)*(hidden_dim+1), hidden_dim), nn.ReLU(), nn.Dropout(p=0.4))\n",
    "        self.encoder2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(p=0.4))\n",
    "        self.fc1 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim,1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, HiTIMED, DNAM, WSI, edge_index, batch, demographic):\n",
    "        HiTIMED_encoded = self.HiTIMEDEncoder(HiTIMED, demographic)\n",
    "        DNAM_encoded = self.DNAMEncoder(DNAM, demographic)\n",
    "        WSI_encoded = self.WSIEncoder(WSI, edge_index, batch, demographic)\n",
    "        \n",
    "        HiTIMED_encoded = self.HiTIMED_project(HiTIMED_encoded)\n",
    "        DNAM_encoded = self.dnam_project(DNAM_encoded)\n",
    "        WSI_encoded = self.wsi_project(WSI_encoded)\n",
    "        vec1 = HiTIMED_encoded; h1 = vec1\n",
    "        vec2 = DNAM_encoded; h2 = vec2\n",
    "        vec3 = WSI_encoded; h3=vec3\n",
    "        \n",
    "        z1 = self.linear_z1(vec1, vec3) # Gate HiTIMED with WSI\n",
    "        o1 = self.linear_o1(nn.Sigmoid()(z1)*h1)\n",
    "\n",
    "        z2 = self.linear_z2(vec2, vec1) # Gate DNAM with HiTIMED\n",
    "        o2 = self.linear_o2(nn.Sigmoid()(z2)*h2)\n",
    "\n",
    "        z3 = self.linear_z3(vec2, vec3) # Gate HiTIMED With WSI\n",
    "        o3 = self.linear_o3(nn.Sigmoid()(z3)*h3)\n",
    "\n",
    "        ### Fusion\n",
    "        o1 = torch.cat((o1, torch.cuda.FloatTensor(o1.shape[0], 1).fill_(1)), 1)\n",
    "        o2 = torch.cat((o2, torch.cuda.FloatTensor(o2.shape[0], 1).fill_(1)), 1)\n",
    "        o3 = torch.cat((o3, torch.cuda.FloatTensor(o3.shape[0], 1).fill_(1)), 1)\n",
    "        o12 = torch.bmm(o1.unsqueeze(2), o2.unsqueeze(1)).flatten(start_dim=1)\n",
    "        o123 = torch.bmm(o12.unsqueeze(2), o3.unsqueeze(1)).flatten(start_dim=1)\n",
    "        out = self.post_fusion_dropout(o123)\n",
    "        \n",
    "        out = self.encoder1(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.encoder2(out)\n",
    "        out = self.dropout(out)\n",
    "        x = out\n",
    "        \n",
    "        hazard = self.out(x)\n",
    "        return hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266ead0",
   "metadata": {},
   "source": [
    "### Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d82d1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_encoders(model):\n",
    "    for param in model.HiTIMEDEncoder.parameters():\n",
    "            param.requires_grad = True\n",
    "    for param in model.DNAMEncoder.parameters():\n",
    "            param.requires_grad = True\n",
    "    for param in model.WSIEncoder.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25bc9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_loss(survtime, censor, hazard_pred, device):\n",
    "    # This calculation credit to Travers Ching https://github.com/traversc/cox-nnet\n",
    "    # Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data\n",
    "    #current_batch_len = len(survtime)\n",
    "    #hazard_pred = hazard_pred.to(device)\n",
    "    \n",
    "    current_batch_len = len(censor)\n",
    "    R_mat = np.zeros([current_batch_len, current_batch_len], dtype=int)\n",
    "    for i in range(current_batch_len):\n",
    "        for j in range(current_batch_len):\n",
    "            R_mat[i,j] = survtime[j] >= survtime[i]\n",
    "    R_mat = torch.FloatTensor(R_mat).to(device)\n",
    "    theta = hazard_pred.reshape(-1)\n",
    "    exp_theta = torch.exp(theta)\n",
    "    loss_cox = -torch.mean((theta - torch.log(torch.sum(exp_theta*R_mat, dim=1))) * censor.to(device))\n",
    "    R_mat.detach()\n",
    "    return loss_cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1c6e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loader,device):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        #model.eval()\n",
    "        #model.train(False)\n",
    "        for idx, data in enumerate(loader):\n",
    "            HiTIMED_data = data[0].to(device)\n",
    "            dnam_data = data[1].to(device)\n",
    "            wsi_data = data[2]\n",
    "            demog = data[3].to(device)\n",
    "            censors = torch.Tensor(wsi_data.censor)\n",
    "            times = wsi_data.duration\n",
    "            edge_index = wsi_data.edge_index.to(device)\n",
    "            batch = wsi_data.batch\n",
    "            wsi_data = wsi_data.x.double().to(device)\n",
    "            \n",
    "            if torch.any(times.isnan()):\n",
    "                times = torch.nan_to_num(times)\n",
    "            if torch.any(censors.isnan()):\n",
    "                censors = torch.nan_to_num(censors)\n",
    "            \n",
    "            batch = batch.to(device)\n",
    "            hazard_pred = model(HiTIMED_data, dnam_data, wsi_data, edge_index, batch, demog)\n",
    "            loss = cox_loss(times, censors, hazard_pred, device)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            HiTIMED_data.detach()\n",
    "            dnam_data.detach()\n",
    "            edge_index.detach()\n",
    "            wsi_data.detach()\n",
    "            \n",
    "    #model.train(True)\n",
    "    return total_loss/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d6bcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "def c_index(loader, model, device):\n",
    "    # val loader batch size is always equal to length of val loader\n",
    "    cs = []\n",
    "    hs = []\n",
    "    ts = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "            \n",
    "            HiTIMED_data = data[0].to(device).double()\n",
    "            dnam_data = data[1].to(device)\n",
    "            wsi_data = data[2]\n",
    "            demog = data[3].to(device).double()\n",
    "            \n",
    "            censors = torch.Tensor(wsi_data.censor)\n",
    "            times = wsi_data.duration\n",
    "            edge_index = wsi_data.edge_index.to(device)\n",
    "            batch = wsi_data.batch.to(device)\n",
    "            wsi_data = wsi_data.x.double().to(device)\n",
    "            \n",
    "            if torch.any(times.isnan()):\n",
    "                times = torch.nan_to_num(times)\n",
    "            if torch.any(censors.isnan()):\n",
    "                censors = torch.nan_to_num(censors)\n",
    "    \n",
    "            hazards = model(HiTIMED_data, dnam_data, wsi_data, edge_index, batch, demog)\n",
    "   \n",
    "            censors = censors.cpu().detach().numpy()\n",
    "            times = times.cpu().detach().numpy()\n",
    "            hazards = hazards.cpu().detach().numpy().reshape((-1,))\n",
    "            censors = censors.astype(bool)\n",
    "            \n",
    "            for c in censors:\n",
    "                cs.append(c)\n",
    "            for h in hazards:\n",
    "                hs.append(h)\n",
    "            for t in times:\n",
    "                ts.append(t)\n",
    "            \n",
    "            HiTIMED_data.detach()\n",
    "            dnam_data.detach()\n",
    "            edge_index.detach()\n",
    "            batch.detach()\n",
    "            wsi_data.detach()\n",
    "            \n",
    "    cidx = concordance_index_censored(cs,ts,hs)\n",
    "    cidx_value = cidx[0]\n",
    "    \n",
    "    return cidx_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49054446",
   "metadata": {},
   "source": [
    "### Training Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9176d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/Multimodal/model_saving/Pheno_Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f7e1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultimodalPairwiseTrilinear(HiTIMED_encoder.to(device),\n",
    "                                    DNAm_encoder.to(device),\n",
    "                                    wsi_encoder.to(device),\n",
    "                                    32,32,32,\n",
    "                                    hidden_dim = 50).to(device).double()\n",
    "epochs = 20\n",
    "accum_num = 8\n",
    "lr = 0.0001\n",
    "optim = Adam(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "scheduler = CosineAnnealingWarmRestarts(optim, 20, eta_min=5e-5, T_mult = 2)\n",
    "save_dir = '/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/Multimodal/model_saving/Pheno_Interaction'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215229ab",
   "metadata": {},
   "source": [
    "#### Delete unused variables/objects to release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5b60f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DNAm_TCGA \n",
    "del DNAm_TCGA_New \n",
    "del DNAm_df \n",
    "del Data_TCGA_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8d229",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d42157f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train loss: 0.19464681566313474\n",
      "val loss: 0.178271357126671\n",
      "train c-index: 0.8561482270582864\n",
      "val c-index: 0.8581136738056013\n",
      "test c-index: 0.7493773349937733\n",
      "____________________________Got new best____________________________\n",
      "epoch 1\n",
      "train loss: 0.1755619354394264\n",
      "val loss: 0.1645963172699821\n",
      "train c-index: 0.832940191751636\n",
      "val c-index: 0.8369028006589786\n",
      "test c-index: 0.7417496886674969\n",
      "epoch 2\n",
      "train loss: 0.17176648779126819\n",
      "val loss: 0.15311537280977397\n",
      "train c-index: 0.8309618018566428\n",
      "val c-index: 0.835667215815486\n",
      "test c-index: 0.7345890410958904\n",
      "epoch 3\n",
      "train loss: 0.15656122489536034\n",
      "val loss: 0.14551371003070643\n",
      "train c-index: 0.8351088114442247\n",
      "val c-index: 0.8362850082372323\n",
      "test c-index: 0.7344333748443338\n",
      "epoch 4\n",
      "train loss: 0.1934974255179781\n",
      "val loss: 0.14680243498471768\n",
      "train c-index: 0.8658499467356566\n",
      "val c-index: 0.8624382207578254\n",
      "test c-index: 0.7347447073474471\n",
      "____________________________Got new best____________________________\n",
      "epoch 5\n",
      "train loss: 0.14296063773546105\n",
      "val loss: 0.1405196322386173\n",
      "train c-index: 0.8785192512555167\n",
      "val c-index: 0.8706754530477759\n",
      "test c-index: 0.7394146948941469\n",
      "____________________________Got new best____________________________\n",
      "epoch 6\n",
      "train loss: 0.1485892883937662\n",
      "val loss: 0.13828227005861357\n",
      "train c-index: 0.8355653629584538\n",
      "val c-index: 0.8515238879736409\n",
      "test c-index: 0.6500622665006227\n",
      "epoch 7\n",
      "train loss: 0.16159291789301836\n",
      "val loss: 0.1334881803831259\n",
      "train c-index: 0.8354512250798966\n",
      "val c-index: 0.8492586490939045\n",
      "test c-index: 0.6930261519302615\n",
      "epoch 8\n",
      "train loss: 0.4307831741496755\n",
      "val loss: 0.1174467874778149\n",
      "train c-index: 0.8289073200426115\n",
      "val c-index: 0.8492586490939045\n",
      "test c-index: 0.7050124533001245\n",
      "epoch 9\n",
      "train loss: 0.14371240585600858\n",
      "val loss: 0.11370288034920317\n",
      "train c-index: 0.8348044437680718\n",
      "val c-index: 0.8568780889621087\n",
      "test c-index: 0.7045454545454546\n",
      "epoch 10\n",
      "train loss: 0.13279237834087482\n",
      "val loss: 0.10390734540055112\n",
      "train c-index: 0.8379242124486379\n",
      "val c-index: 0.8614085667215815\n",
      "test c-index: 0.7048567870485679\n",
      "epoch 11\n",
      "train loss: 0.1219745428758767\n",
      "val loss: 0.10552582836602864\n",
      "train c-index: 0.8388753614366155\n",
      "val c-index: 0.8587314662273476\n",
      "test c-index: 0.6994084682440846\n",
      "epoch 12\n",
      "train loss: 0.12445729392493486\n",
      "val loss: 0.114338831169746\n",
      "train c-index: 0.8397884644650738\n",
      "val c-index: 0.8612026359143328\n",
      "test c-index: 0.6933374844333748\n",
      "epoch 13\n",
      "train loss: 0.12569567042509358\n",
      "val loss: 0.13010943526113938\n",
      "train c-index: 0.8332445594277887\n",
      "val c-index: 0.8525535420098846\n",
      "test c-index: 0.6962951432129514\n",
      "epoch 14\n",
      "train loss: 0.09881744213608887\n",
      "val loss: 0.1314770261574636\n",
      "train c-index: 0.8373535230558514\n",
      "val c-index: 0.8537891268533773\n",
      "test c-index: 0.6869551681195517\n",
      "epoch 15\n",
      "train loss: 0.1458882164267561\n",
      "val loss: 0.12515329314638288\n",
      "train c-index: 0.8475117942474509\n",
      "val c-index: 0.85667215815486\n",
      "test c-index: 0.6880448318804483\n",
      "epoch 16\n",
      "train loss: 0.09849403896754017\n",
      "val loss: 0.1449239863252821\n",
      "train c-index: 0.8358697306346066\n",
      "val c-index: 0.8478171334431631\n",
      "test c-index: 0.6861768368617683\n",
      "epoch 17\n",
      "train loss: 0.13445703257440078\n",
      "val loss: 0.13412742612538084\n",
      "train c-index: 0.8405113376959367\n",
      "val c-index: 0.8441103789126854\n",
      "test c-index: 0.6864881693648817\n",
      "epoch 18\n",
      "train loss: 0.09029328277702375\n",
      "val loss: 0.11228140367902098\n",
      "train c-index: 0.842185359914777\n",
      "val c-index: 0.8521416803953872\n",
      "test c-index: 0.6906911581569116\n",
      "epoch 19\n",
      "train loss: 0.10648708251567905\n",
      "val loss: 0.1164176297667324\n",
      "train c-index: 0.8411200730482423\n",
      "val c-index: 0.8527594728171335\n",
      "test c-index: 0.689134495641345\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_c_indices = []\n",
    "val_c_indices = []\n",
    "test_c_indices = []\n",
    "#test_c_indices_trunc_10year = []\n",
    "best_val_cox = 0\n",
    "best_model_dict = copy.deepcopy(model).cpu().state_dict()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch > int(epochs/int(4)):\n",
    "        unfreeze_encoders(model)\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        HiTIMED_data = data[0].to(device)\n",
    "        dnam_data = data[1].to(device)\n",
    "        wsi_data = data[2]\n",
    "        demog = data[3].to(device)\n",
    "        \n",
    "        censors = torch.Tensor(wsi_data.censor)\n",
    "        times = wsi_data.duration\n",
    "        edge_index = wsi_data.edge_index.to(device)\n",
    "        batch = wsi_data.batch.to(device)\n",
    "        wsi_data = wsi_data.x.double().to(device)\n",
    "        \n",
    "        if torch.any(times.isnan()):\n",
    "            times = torch.nan_to_num(times)\n",
    "        if torch.any(censors.isnan()): # pop up an error: 'list' object has no attribute 'isnan'\n",
    "            censors = torch.nan_to_num(censors)\n",
    "        \n",
    "        hazard_pred = model(HiTIMED_data, dnam_data, wsi_data, edge_index, batch, demog)\n",
    "        loss = cox_loss(times, censors, hazard_pred, device)\n",
    "        \n",
    "        if str(loss.item()) == 'nan':\n",
    "            print(hazard_pred)\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        if (batch_idx%accum_num == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        HiTIMED_data.detach()\n",
    "        dnam_data.detach()\n",
    "        edge_index.detach()\n",
    "        batch.detach()\n",
    "        wsi_data.detach()\n",
    "            \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    print('epoch ' + str(epoch))\n",
    "    print('train loss: ' + str(train_loss))\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    print('val loss: '+str(val_loss))\n",
    "    \n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Calculate c-index\n",
    "    try:\n",
    "        train_cidx = c_index(train_loader, model, device)\n",
    "        val_cidx = c_index(val_loader, model, device)\n",
    "        test_cidx = c_index(test_loader, model, device)\n",
    "        #test_cidx_trunc_10year = c_index(test_loader_trunc_10year, model, device)\n",
    "        print('train c-index: ' + str(train_cidx))\n",
    "        print('val c-index: ' + str(val_cidx))\n",
    "        print('test c-index: ' + str(test_cidx))\n",
    "        #print('test c-index (for truncation at 10 years): ' + str(test_cidx_trunc_10year))\n",
    "        \n",
    "    except:\n",
    "        print(c_index(val_loader, model, device))\n",
    "        val_cidx = 'NA'\n",
    "        print('val c-index: NA')\n",
    "    \n",
    "    # Record the best model info.\n",
    "    if val_cidx > best_val_cox:\n",
    "        best_model_dict=copy.deepcopy(model).cpu().state_dict()\n",
    "        best_val_cox=val_cidx\n",
    "        torch.save(model.state_dict(), save_dir + '/model_best' + '.pth')\n",
    "        print('____________________________Got new best____________________________')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    train_c_indices.append(train_cidx)\n",
    "    val_c_indices.append(val_cidx)\n",
    "    test_c_indices.append(test_cidx)\n",
    "    #test_c_indices_trunc_10year.append(test_cidx_trunc_10year)\n",
    "    \n",
    "    # Record metrics\n",
    "    f = open(save_dir + '/training_history.txt','a')\n",
    "    f.write('Epoch ' + str(epoch) + \" Train Loss: \" + str(train_loss) + \" Val Loss: \" + str(val_loss) +\n",
    "            \" Val c-index: \" + str(val_cidx) + \" Test c-index: \" + str(test_cidx) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # Save model\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save(model.state_dict(), save_dir + '/model_epoch_' + str(epoch) + '.pth')\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc555f97",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee016a",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd7181bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632275a",
   "metadata": {},
   "source": [
    "### c-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b157fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_c_indices, label='Training c-indices')\n",
    "plt.plot(val_c_indices, label='Validation c-indices')\n",
    "plt.plot(test_c_indices, label='Testing c-indices')\n",
    "#plt.plot(test_c_indices_trunc_10year, label='Testing c-indices (for truncation at 10 years)')\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('c-index')\n",
    "plt.title('Training, Validation, and Testing c-indices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d9e356",
   "metadata": {},
   "source": [
    "# Get the predicted hazard of DH dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342c213",
   "metadata": {},
   "source": [
    "##### Build prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e1cbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = MultimodalPairwiseTrilinear(HiTIMED_encoder.to(device),\n",
    "                                               DNAm_encoder.to(device),\n",
    "                                               wsi_encoder.to(device),\n",
    "                                               32,32,32,\n",
    "                                               hidden_dim = 50).to(device).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9c6ff",
   "metadata": {},
   "source": [
    "##### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb4d9b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('HiTIMEDEncoder.input_layer.weight',\n",
       "              tensor([[-0.1308,  0.0645, -0.0009,  ..., -0.0048, -0.1004, -0.0590],\n",
       "                      [-0.0685,  0.0467, -0.0676,  ...,  0.1801,  0.0233, -0.0017],\n",
       "                      [ 0.0065, -0.1329,  0.1967,  ...,  0.3356,  0.0911, -0.0187],\n",
       "                      ...,\n",
       "                      [-0.1026,  0.0764,  0.0295,  ..., -0.0297,  0.0640, -0.0605],\n",
       "                      [-0.1162,  0.0783, -0.0867,  ..., -0.0596,  0.2322,  0.0220],\n",
       "                      [-0.0858,  0.0363, -0.0085,  ...,  0.1014, -0.1380, -0.0527]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('HiTIMEDEncoder.input_layer.bias',\n",
       "              tensor([-1.1542e-01, -2.8186e-04, -5.1804e-02, -3.5750e-03, -1.2161e-01,\n",
       "                      -3.0322e-02, -2.0715e-02, -1.6112e-02,  2.8139e-02, -7.8413e-02,\n",
       "                      -1.1794e-01, -1.5811e-01, -1.4265e-01, -8.4523e-02, -3.3547e-02,\n",
       "                      -1.1752e-01, -1.8095e-01,  2.0527e-02, -2.4520e-01, -1.0212e-01,\n",
       "                       1.3608e-01, -6.1452e-03, -1.2879e-01, -1.4390e-01, -6.8467e-03,\n",
       "                      -1.7142e-01,  1.6212e-03,  4.8625e-04,  5.5550e-02,  3.2750e-03,\n",
       "                      -4.1837e-02, -8.3962e-02,  1.1969e-02, -1.5761e-01, -1.2635e-01,\n",
       "                      -1.4021e-01, -3.0017e-02, -9.7508e-02, -9.2368e-02,  4.1614e-02,\n",
       "                       2.9892e-02, -5.0885e-02, -1.1899e-03,  4.8284e-02,  2.9355e-02,\n",
       "                      -4.1801e-02, -1.1579e-01, -2.9213e-01, -7.5079e-02, -9.5073e-02,\n",
       "                      -1.4359e-01,  1.7161e-02,  3.1260e-02, -1.7241e-01, -5.0468e-02,\n",
       "                      -2.3392e-01, -1.7696e-01, -7.8031e-02,  2.0708e-02, -6.8402e-03,\n",
       "                      -1.8387e-01, -4.9962e-02,  7.1702e-03, -1.1559e-01], device='cuda:0',\n",
       "                     dtype=torch.float64)),\n",
       "             ('HiTIMEDEncoder.hidden_layers.0.weight',\n",
       "              tensor([[ 9.4837e-02,  8.6327e-02,  9.8311e-02,  ..., -2.2931e-04,\n",
       "                        6.4559e-02, -2.4224e-01],\n",
       "                      [-5.2142e-02,  6.9211e-02,  5.3437e-02,  ...,  5.2501e-02,\n",
       "                       -1.0089e-01,  6.3143e-02],\n",
       "                      [ 2.5517e-02, -1.3403e-01, -4.6979e-02,  ..., -9.8168e-02,\n",
       "                       -1.1544e-01, -1.5585e-01],\n",
       "                      ...,\n",
       "                      [-6.2813e-02, -1.0991e-01,  1.1996e-01,  ..., -1.1755e-01,\n",
       "                        6.3164e-02, -1.7131e-01],\n",
       "                      [ 6.5237e-02, -2.0250e-01, -4.5688e-02,  ..., -5.9231e-02,\n",
       "                       -1.5829e-01,  1.2403e-01],\n",
       "                      [ 6.9185e-02,  6.8889e-02, -3.5215e-03,  ..., -5.0168e-01,\n",
       "                        1.2369e-01, -1.7523e-01]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('HiTIMEDEncoder.hidden_layers.0.bias',\n",
       "              tensor([-1.9993e-01, -3.1551e-02,  5.2005e-02, -2.7783e-01,  5.8852e-03,\n",
       "                      -1.1925e-01, -8.1723e-02, -1.0062e-01,  2.1235e-02, -1.4176e-01,\n",
       "                       6.5704e-02, -7.7256e-02, -1.4658e-01, -1.4394e-01,  9.4476e-02,\n",
       "                       2.2755e-02, -1.2333e-01, -4.9031e-03,  1.0605e-01,  2.2220e-02,\n",
       "                      -1.3695e-01, -1.6920e-01, -2.6687e-02,  1.1031e-01, -2.7716e-04,\n",
       "                       1.2428e-01,  3.9792e-02, -7.4985e-02, -4.4923e-02, -1.0307e-01,\n",
       "                       1.0637e-02,  6.8164e-02], device='cuda:0', dtype=torch.float64)),\n",
       "             ('HiTIMEDEncoder.hidden_layers.1.weight',\n",
       "              tensor([[-0.1962, -0.0630,  0.1505,  ...,  0.0688, -0.1478, -0.1362],\n",
       "                      [-0.0302, -0.0096, -0.0972,  ...,  0.0904, -0.0748,  0.0927],\n",
       "                      [-0.0007, -0.1552, -0.1717,  ...,  0.1025, -0.1268, -0.0234],\n",
       "                      ...,\n",
       "                      [ 0.2114,  0.1441,  0.2008,  ...,  0.2298, -0.3252,  0.2086],\n",
       "                      [-0.0097,  0.0789,  0.1385,  ...,  0.0712,  0.0445, -0.1413],\n",
       "                      [-0.0053, -0.1501, -0.0131,  ...,  0.1261,  0.0989, -0.0669]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('HiTIMEDEncoder.hidden_layers.1.bias',\n",
       "              tensor([-0.0544,  0.0368, -0.1711, -0.2121, -0.1076,  0.3005,  0.2747,  0.0100,\n",
       "                       0.0846, -0.2439, -0.1858,  0.0576,  0.0110, -0.0732,  0.1953,  0.0672,\n",
       "                       0.0172, -0.0176,  0.1788, -0.0761,  0.0723, -0.1038, -0.3451, -0.0164,\n",
       "                      -0.1100, -0.1233,  0.3298,  0.0282,  0.0248,  0.1154, -0.0951, -0.1388],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.input_layer.weight',\n",
       "              tensor([[-1.2237e-02,  1.8509e-02, -1.3463e-03,  ..., -6.9043e-03,\n",
       "                        6.2724e-03, -2.0016e-03],\n",
       "                      [-2.1274e-02,  7.8136e-03,  5.0463e-04,  ..., -7.1853e-03,\n",
       "                        5.8833e-04,  1.7078e-03],\n",
       "                      [-1.4273e-03, -1.8128e-03, -2.5361e-05,  ...,  9.5532e-04,\n",
       "                       -1.6643e-03,  1.1436e-03],\n",
       "                      ...,\n",
       "                      [-2.9441e-03, -1.9795e-02, -1.0337e-03,  ..., -1.8619e-03,\n",
       "                       -1.9366e-02,  6.2859e-04],\n",
       "                      [-1.2955e-02, -1.1432e-02, -8.0653e-04,  ..., -3.8350e-03,\n",
       "                        4.8401e-03, -1.8675e-03],\n",
       "                      [ 6.7060e-03, -2.4896e-03, -8.6429e-05,  ...,  6.6217e-03,\n",
       "                        6.5142e-03, -4.6955e-04]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.input_layer.bias',\n",
       "              tensor([ 2.1097e-03,  9.5755e-03, -7.9015e-05, -6.0903e-04, -1.8484e-02,\n",
       "                      -5.7254e-03, -1.0619e-02, -1.3715e-03, -5.7922e-03,  6.6749e-03,\n",
       "                       1.4155e-02, -2.2344e-03, -1.0256e-02,  1.6234e-02, -6.9683e-04,\n",
       "                      -1.2234e-02, -1.9086e-02,  9.8589e-03,  2.1296e-03,  7.3085e-03,\n",
       "                       1.3122e-02,  1.8925e-02,  1.1904e-02,  5.5825e-03,  3.1632e-03,\n",
       "                       5.0380e-05,  1.1669e-04,  1.3965e-02,  2.5308e-03,  2.1220e-02,\n",
       "                      -3.4491e-03,  5.1861e-03,  1.1380e-02, -4.2715e-03,  2.2814e-03,\n",
       "                      -8.0783e-03,  1.0025e-02, -6.1282e-03, -5.4770e-03, -1.0823e-03,\n",
       "                      -1.0029e-02,  3.7323e-03, -1.0023e-02,  1.5061e-02, -1.3677e-02,\n",
       "                      -1.1639e-02,  2.1817e-03, -1.8584e-02, -9.6820e-04,  2.8759e-04,\n",
       "                      -1.3816e-03,  9.1198e-03,  1.5549e-02,  1.6698e-03, -1.0270e-03,\n",
       "                      -1.8219e-02,  3.7847e-03, -8.9723e-03, -5.6841e-03,  1.8566e-02,\n",
       "                      -1.0281e-03,  3.1158e-03, -1.4057e-04,  2.8812e-03, -8.7964e-03,\n",
       "                      -1.4786e-03,  9.1404e-03, -6.7033e-03, -1.4219e-02,  3.3384e-04,\n",
       "                       5.0450e-03, -1.3414e-02,  1.7168e-02, -8.2665e-04, -1.2783e-03,\n",
       "                       1.5959e-02, -6.5999e-03,  9.7424e-04,  1.9100e-03,  8.9571e-03,\n",
       "                      -6.2426e-03, -7.0758e-03, -8.3550e-03, -1.1734e-02, -3.0673e-03,\n",
       "                      -7.3424e-03,  9.1545e-04,  6.7831e-03,  2.0013e-03, -2.1560e-03,\n",
       "                       1.4905e-03, -2.4750e-03,  4.4915e-03,  7.3525e-03, -1.6001e-02,\n",
       "                       1.8561e-03,  1.0330e-02,  1.7135e-02,  3.7351e-03,  3.3042e-03,\n",
       "                      -2.9688e-03,  3.5733e-03,  6.3050e-03, -3.3018e-03,  5.9455e-03,\n",
       "                      -1.4738e-04, -7.7224e-04,  2.1214e-03,  4.7908e-04, -9.0337e-03,\n",
       "                       7.9988e-03,  1.7170e-02,  1.7895e-03, -2.4996e-02, -1.1973e-03,\n",
       "                       3.4987e-03,  4.3864e-03,  6.2498e-03, -6.7448e-04, -5.8431e-03,\n",
       "                       1.2959e-02,  1.6419e-02, -8.6032e-03, -2.0321e-03, -5.8959e-03,\n",
       "                       2.2246e-03,  1.0532e-03,  1.2203e-02,  5.5620e-03,  1.7329e-02,\n",
       "                       4.6936e-05,  2.3263e-03, -2.0897e-02,  1.4874e-02,  2.3792e-03,\n",
       "                      -1.3655e-02,  2.6357e-03, -1.2619e-02,  4.0084e-03, -1.4594e-02,\n",
       "                      -7.6100e-03, -3.8684e-04,  3.7987e-03,  1.9077e-02, -2.4174e-03,\n",
       "                       8.5378e-04,  1.4218e-02, -8.4850e-03, -1.0559e-02,  4.6866e-03,\n",
       "                      -6.8410e-03,  4.3737e-03, -1.5090e-03, -5.6705e-03,  1.5007e-02,\n",
       "                      -1.9490e-03,  4.2824e-03,  9.9466e-03, -1.8536e-02,  5.4081e-03,\n",
       "                       2.2672e-03, -7.5446e-03,  1.6555e-04,  1.2197e-03,  5.5293e-03,\n",
       "                       7.6066e-03, -4.5522e-04,  7.4225e-04,  1.9200e-02,  4.2398e-03,\n",
       "                       7.9984e-03,  7.4444e-03, -7.2279e-03, -5.4665e-03, -4.8970e-03,\n",
       "                       2.0406e-04,  7.7163e-04,  4.6649e-03,  7.7261e-03,  1.4484e-03,\n",
       "                       6.6016e-03,  1.1850e-02, -2.0967e-02,  1.0223e-02,  7.8495e-03,\n",
       "                       7.8315e-03, -2.5094e-03,  3.3787e-03,  1.4482e-02, -1.1655e-02,\n",
       "                      -3.2755e-03,  1.7698e-03, -6.1422e-03, -9.5176e-03, -1.0966e-02,\n",
       "                       1.4933e-03,  9.3528e-04, -9.4931e-03,  1.5541e-04,  1.6068e-02,\n",
       "                       2.4692e-03, -3.8811e-03,  6.7443e-03,  2.6620e-03,  5.5527e-03,\n",
       "                      -7.7177e-03,  1.5118e-02,  3.6460e-03, -9.7144e-03,  2.2078e-03,\n",
       "                      -9.6285e-03,  1.1218e-02, -1.0857e-03, -1.0368e-02,  9.6157e-03,\n",
       "                      -1.7828e-02,  6.7770e-03,  4.8941e-03, -7.8711e-03,  6.5536e-03,\n",
       "                      -1.1448e-03,  4.4275e-04,  1.7760e-02,  8.4230e-03,  2.4862e-03,\n",
       "                       1.7261e-02, -8.7505e-04, -1.0075e-03, -7.7158e-03, -4.9450e-03,\n",
       "                      -6.9752e-03,  6.4242e-03, -1.6765e-02,  1.4900e-03, -9.4979e-03,\n",
       "                       4.6703e-03, -7.2623e-03, -1.1936e-02,  4.4352e-03,  5.2495e-03,\n",
       "                      -2.6354e-03,  1.3280e-02, -2.2279e-02,  6.2197e-03,  1.0048e-02,\n",
       "                       1.5167e-03,  6.3554e-03,  5.2142e-03,  3.7483e-03, -1.2910e-02,\n",
       "                       2.2077e-03, -2.2464e-03,  7.7705e-03, -7.0661e-03,  2.0390e-03,\n",
       "                      -1.1085e-02,  6.2662e-03,  5.9874e-03, -1.9147e-02,  2.3263e-03,\n",
       "                       1.8215e-02,  2.1982e-03, -1.0176e-03, -1.4066e-03, -1.7466e-02,\n",
       "                       3.2325e-03, -1.0526e-03, -1.5792e-03,  5.6096e-03,  1.1820e-02,\n",
       "                      -5.8868e-04, -1.5079e-02,  4.8493e-04, -7.5013e-03, -1.1495e-02,\n",
       "                      -9.7877e-03, -1.8922e-03,  8.8735e-04,  5.8138e-03, -9.3715e-03,\n",
       "                      -6.2431e-03, -9.6409e-03, -1.7462e-02,  1.8906e-02, -6.6486e-03,\n",
       "                      -1.6925e-02,  6.4954e-04,  1.3756e-02,  3.3416e-03, -4.6561e-03,\n",
       "                       8.4118e-03,  7.3689e-04,  1.5423e-02, -1.3245e-02, -5.9708e-03,\n",
       "                      -1.4812e-02,  8.0796e-03,  3.1934e-03,  7.5994e-03,  2.9331e-04,\n",
       "                       7.1777e-03, -7.5716e-04,  7.6480e-03, -2.4384e-03, -5.8463e-04,\n",
       "                       9.2645e-03, -1.2622e-02, -6.5272e-03,  7.2829e-03,  1.4600e-03,\n",
       "                       8.6198e-03, -7.2817e-03, -1.2970e-02,  9.6400e-03, -1.5293e-02,\n",
       "                      -1.1739e-02, -6.7703e-03,  8.1849e-03,  4.7195e-03,  3.8418e-03,\n",
       "                       4.6945e-05, -7.1717e-03, -1.0973e-02,  4.5303e-03,  1.7208e-02,\n",
       "                      -4.7859e-03,  5.8240e-04,  7.2271e-03, -1.2486e-02,  1.3140e-04,\n",
       "                       9.1374e-03,  1.1927e-04,  1.0997e-03,  4.1646e-03, -1.1645e-02,\n",
       "                      -7.2363e-04,  9.2887e-04, -1.5858e-02, -4.9536e-03,  6.4670e-04,\n",
       "                      -5.3272e-04, -1.1009e-02, -1.2503e-02,  4.2915e-03, -7.6522e-03,\n",
       "                       6.2079e-03,  1.6344e-03,  1.4088e-02,  1.1629e-02, -9.9706e-03,\n",
       "                      -1.8939e-02, -1.7549e-03, -1.9124e-02, -4.8941e-03,  1.4864e-04,\n",
       "                      -3.3819e-03, -9.6911e-03,  3.9131e-03,  2.4825e-03,  1.5223e-03,\n",
       "                      -1.7998e-02,  3.2270e-03, -1.2778e-02, -5.2623e-03, -2.3919e-03,\n",
       "                       6.4860e-03,  1.5448e-02, -5.7397e-03,  2.1659e-03,  1.1425e-02,\n",
       "                       9.8476e-03, -1.0712e-02, -2.2769e-03,  4.8532e-03, -1.8945e-02,\n",
       "                       2.5662e-03,  2.8445e-03, -8.2046e-04, -2.7057e-03, -8.0624e-03,\n",
       "                      -1.4510e-02,  2.7584e-03, -4.1037e-04,  8.1133e-03, -3.7806e-04,\n",
       "                      -8.3208e-03,  1.4288e-03,  5.4385e-03,  4.0159e-03,  2.1306e-03,\n",
       "                      -2.7626e-02,  2.1917e-03, -3.5677e-04, -8.1100e-03,  3.2976e-03,\n",
       "                       6.7287e-03,  1.1840e-02,  1.2954e-02,  1.1364e-02, -1.3821e-02,\n",
       "                       5.8537e-03, -1.6501e-02, -9.7073e-03,  1.2398e-02, -4.7226e-03,\n",
       "                      -1.5783e-02, -1.9718e-02,  5.9305e-03, -1.7697e-02,  1.0554e-02,\n",
       "                       3.4057e-03, -6.5726e-03,  4.6761e-03, -1.4502e-03,  1.5603e-02,\n",
       "                       2.2334e-02, -8.3268e-03,  1.5516e-04, -1.0878e-02, -3.0504e-03,\n",
       "                       1.3106e-03, -2.0200e-03, -5.8883e-03, -7.5172e-03, -8.2053e-03,\n",
       "                      -7.6387e-03,  8.9778e-03,  2.6406e-03,  8.1319e-03, -2.1466e-03,\n",
       "                      -1.1778e-02, -2.3308e-02,  1.8594e-02,  7.4881e-03,  2.1955e-03,\n",
       "                      -1.5203e-03, -1.0526e-04, -1.5739e-02,  1.4925e-02, -8.5867e-03,\n",
       "                      -1.6836e-02, -3.0783e-03, -1.9200e-03, -6.2285e-04,  5.4937e-03,\n",
       "                       1.3653e-03,  1.4241e-02, -1.4934e-02,  1.2007e-03,  2.8318e-03,\n",
       "                      -1.9870e-02, -1.7470e-02, -8.8023e-03,  3.9439e-03,  2.7626e-03,\n",
       "                      -1.9169e-02,  1.8295e-02, -3.8934e-03,  1.2510e-03, -5.5513e-03,\n",
       "                      -7.9627e-03, -3.9762e-03,  1.3892e-02, -7.1646e-03,  4.0208e-03,\n",
       "                       1.3167e-02,  4.8169e-03, -2.0420e-02, -1.5648e-02, -3.9825e-03,\n",
       "                      -1.6057e-03, -1.4738e-02,  6.2301e-04,  2.0455e-03, -6.8785e-03,\n",
       "                      -3.6813e-03,  1.2214e-02,  3.2978e-03, -1.2741e-03,  2.7251e-03,\n",
       "                       1.6693e-02, -8.8653e-03,  3.4522e-03, -1.4271e-03, -5.4109e-03,\n",
       "                      -1.2220e-02, -1.9697e-03, -9.5623e-03,  5.2618e-03,  2.1302e-03,\n",
       "                      -1.1630e-02, -6.6143e-03, -1.7948e-03,  2.2969e-03, -8.2180e-03,\n",
       "                      -1.2820e-03, -9.6044e-03, -1.2396e-02,  1.5355e-03,  8.8322e-03,\n",
       "                       5.0310e-03,  2.2729e-03, -1.7629e-03, -3.6840e-03, -2.1506e-02,\n",
       "                       2.9082e-03,  9.5656e-04, -3.0112e-03, -9.4646e-03,  9.9568e-03,\n",
       "                      -5.8621e-03, -1.0885e-03], device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.0.weight',\n",
       "              tensor([[ 2.2646e-02,  1.7619e-03, -2.7089e-03,  ..., -4.6199e-03,\n",
       "                        1.7723e-02, -4.9834e-03],\n",
       "                      [-1.2033e-02,  6.6284e-03, -1.7161e-02,  ..., -2.8535e-02,\n",
       "                       -7.6436e-03,  3.4992e-03],\n",
       "                      [-8.9934e-04,  2.0099e-04, -6.4014e-05,  ..., -2.3684e-03,\n",
       "                       -1.1522e-03,  1.3787e-04],\n",
       "                      ...,\n",
       "                      [-1.0194e-02,  6.5186e-03, -4.0461e-05,  ...,  9.3478e-03,\n",
       "                       -1.5064e-02, -7.9628e-03],\n",
       "                      [-8.4206e-03, -7.8428e-04, -5.8885e-03,  ..., -2.3544e-03,\n",
       "                       -1.7658e-02, -8.3972e-04],\n",
       "                      [-5.5909e-04,  1.1156e-04, -2.1887e-04,  ...,  1.9918e-04,\n",
       "                        9.6598e-04, -5.1472e-05]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.0.bias',\n",
       "              tensor([-0.0080, -0.0046,  0.0023, -0.0069,  0.0129,  0.0103, -0.0125,  0.0242,\n",
       "                       0.0067,  0.0005,  0.0161, -0.0092, -0.0052,  0.0014,  0.0009, -0.0064,\n",
       "                       0.0236,  0.0041,  0.0182,  0.0129,  0.0079, -0.0005,  0.0057,  0.0017,\n",
       "                      -0.0054, -0.0049,  0.0097,  0.0020,  0.0080, -0.0123, -0.0163,  0.0079,\n",
       "                      -0.0261,  0.0107, -0.0053,  0.0022,  0.0024, -0.0079, -0.0173, -0.0219,\n",
       "                       0.0110, -0.0297,  0.0008, -0.0018, -0.0133,  0.0116,  0.0079, -0.0017,\n",
       "                       0.0108,  0.0142, -0.0111, -0.0011, -0.0111,  0.0007, -0.0097,  0.0052,\n",
       "                      -0.0026,  0.0032, -0.0098, -0.0034, -0.0287, -0.0158, -0.0145, -0.0037,\n",
       "                      -0.0073, -0.0026, -0.0223,  0.0053,  0.0044,  0.0192, -0.0174, -0.0171,\n",
       "                      -0.0008,  0.0077, -0.0003, -0.0189, -0.0012, -0.0214,  0.0053, -0.0325,\n",
       "                      -0.0083,  0.0028, -0.0115,  0.0160, -0.0043, -0.0121,  0.0147,  0.0109,\n",
       "                      -0.0127,  0.0100, -0.0137, -0.0215, -0.0107,  0.0033, -0.0108, -0.0097,\n",
       "                       0.0070, -0.0026,  0.0003,  0.0213,  0.0098, -0.0143,  0.0103,  0.0056,\n",
       "                      -0.0196, -0.0025, -0.0005, -0.0044, -0.0018,  0.0011, -0.0252, -0.0028,\n",
       "                      -0.0053, -0.0216,  0.0207, -0.0130, -0.0056, -0.0135,  0.0155,  0.0133,\n",
       "                       0.0072, -0.0016, -0.0008, -0.0010,  0.0014,  0.0074,  0.0091, -0.0069,\n",
       "                       0.0068,  0.0193, -0.0005, -0.0158, -0.0030, -0.0106,  0.0292,  0.0023,\n",
       "                      -0.0024, -0.0040, -0.0195,  0.0037,  0.0049, -0.0095,  0.0196,  0.0106,\n",
       "                      -0.0136, -0.0102, -0.0209, -0.0176,  0.0154, -0.0069, -0.0050, -0.0099,\n",
       "                       0.0154,  0.0049, -0.0146,  0.0163, -0.0054, -0.0261, -0.0004,  0.0252,\n",
       "                       0.0013, -0.0294, -0.0059,  0.0016, -0.0187, -0.0110, -0.0104, -0.0122,\n",
       "                       0.0262,  0.0073, -0.0013,  0.0059, -0.0008, -0.0131, -0.0262, -0.0126,\n",
       "                      -0.0078, -0.0083,  0.0074,  0.0001, -0.0002, -0.0057,  0.0068, -0.0241,\n",
       "                       0.0272,  0.0046,  0.0087,  0.0098,  0.0117, -0.0113,  0.0018, -0.0363,\n",
       "                       0.0053, -0.0111,  0.0067, -0.0094, -0.0153,  0.0178, -0.0015, -0.0083,\n",
       "                       0.0042,  0.0075,  0.0130, -0.0169, -0.0151, -0.0226,  0.0183,  0.0140,\n",
       "                      -0.0259, -0.0304, -0.0196,  0.0063,  0.0015,  0.0004,  0.0039, -0.0265,\n",
       "                       0.0031, -0.0090,  0.0115,  0.0061, -0.0251, -0.0090,  0.0011, -0.0093,\n",
       "                      -0.0154, -0.0011,  0.0085, -0.0061,  0.0159, -0.0005,  0.0120, -0.0165,\n",
       "                      -0.0192,  0.0086,  0.0076,  0.0091, -0.0073,  0.0247,  0.0027,  0.0193,\n",
       "                       0.0016,  0.0079, -0.0150,  0.0163, -0.0056, -0.0155,  0.0008, -0.0097,\n",
       "                       0.0022, -0.0179, -0.0049,  0.0143, -0.0132, -0.0220, -0.0110,  0.0034],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.1.weight',\n",
       "              tensor([[-1.0527e-02,  2.5756e-02, -5.2101e-05,  ...,  1.1145e-02,\n",
       "                        1.0028e-02,  5.2271e-03],\n",
       "                      [-3.6894e-03,  7.3654e-03,  2.8188e-04,  ...,  1.0041e-03,\n",
       "                       -1.7661e-03, -1.5192e-03],\n",
       "                      [-2.1751e-03,  3.2951e-02, -2.6392e-03,  ...,  1.7816e-02,\n",
       "                        9.7078e-03, -8.7589e-03],\n",
       "                      ...,\n",
       "                      [ 1.3050e-02, -2.5393e-02,  3.5919e-04,  ..., -2.7451e-03,\n",
       "                       -2.2843e-03,  7.1458e-05],\n",
       "                      [-7.8984e-03,  1.8627e-03, -3.1201e-04,  ..., -4.5420e-03,\n",
       "                       -1.1428e-02, -1.8099e-03],\n",
       "                      [ 1.4079e-03, -4.3156e-04,  5.0548e-05,  ..., -4.1817e-04,\n",
       "                       -6.1306e-04, -6.9868e-05]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.1.bias',\n",
       "              tensor([ 0.0306,  0.0015,  0.0015,  0.0252, -0.0289, -0.0111, -0.0064,  0.0188,\n",
       "                       0.0064,  0.0104, -0.0365, -0.0102, -0.0392,  0.0309, -0.0264, -0.0117,\n",
       "                      -0.0181, -0.0264,  0.0001, -0.0213, -0.0181,  0.0048,  0.0130,  0.0057,\n",
       "                      -0.0013, -0.0104, -0.0011, -0.0259,  0.0115, -0.0263, -0.0273, -0.0230,\n",
       "                       0.0048, -0.0055,  0.0177,  0.0119, -0.0048,  0.0217, -0.0037, -0.0073,\n",
       "                      -0.0241, -0.0339, -0.0056,  0.0068, -0.0398, -0.0146, -0.0086, -0.0320,\n",
       "                      -0.0122, -0.0226,  0.0030, -0.0320, -0.0003,  0.0106, -0.0267, -0.0236,\n",
       "                       0.0270, -0.0281, -0.0155, -0.0268,  0.0003, -0.0008, -0.0331,  0.0088,\n",
       "                       0.0075,  0.0060,  0.0139,  0.0038, -0.0110,  0.0059, -0.0417, -0.0352,\n",
       "                      -0.0031, -0.0171,  0.0088, -0.0333,  0.0183, -0.0106, -0.0310,  0.0153,\n",
       "                       0.0272,  0.0002,  0.0099, -0.0061, -0.0199,  0.0028, -0.0357,  0.0241,\n",
       "                      -0.0476,  0.0177, -0.0126, -0.0210, -0.0214,  0.0043, -0.0261,  0.0118,\n",
       "                      -0.0266,  0.0052, -0.0302,  0.0127, -0.0045,  0.0051, -0.0337, -0.0029,\n",
       "                      -0.0247, -0.0079, -0.0145, -0.0416, -0.0023, -0.0193, -0.0212,  0.0190,\n",
       "                      -0.0450,  0.0036,  0.0339,  0.0092, -0.0400,  0.0220, -0.0114, -0.0268,\n",
       "                       0.0143,  0.0345,  0.0210,  0.0011, -0.0083,  0.0149, -0.0106,  0.0025],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.2.weight',\n",
       "              tensor([[ 0.0096,  0.0188, -0.0317,  ...,  0.0630, -0.0093,  0.0045],\n",
       "                      [-0.0093, -0.0095, -0.0165,  ...,  0.0145, -0.0038,  0.0041],\n",
       "                      [ 0.0027,  0.0242,  0.0224,  ..., -0.0517, -0.0215, -0.0064],\n",
       "                      ...,\n",
       "                      [ 0.0006, -0.0053, -0.0012,  ...,  0.0023, -0.0037,  0.0002],\n",
       "                      [ 0.0159,  0.0026,  0.0284,  ...,  0.0017,  0.0152, -0.0012],\n",
       "                      [-0.0142, -0.0106, -0.0575,  ...,  0.0546, -0.0214,  0.0030]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.2.bias',\n",
       "              tensor([ 0.0275, -0.0033, -0.0448,  0.0206, -0.0443,  0.0241, -0.0110, -0.0085,\n",
       "                      -0.0071, -0.0300, -0.0270, -0.0182,  0.0320,  0.0236, -0.0206, -0.0260,\n",
       "                       0.0014,  0.0477,  0.0088,  0.0201,  0.0298, -0.0093, -0.0049, -0.0630,\n",
       "                      -0.0071, -0.0137, -0.0163, -0.0394, -0.0598,  0.0308, -0.0238,  0.0175,\n",
       "                      -0.0303, -0.0057,  0.0465, -0.0358, -0.0086,  0.0388, -0.0106, -0.0234,\n",
       "                       0.0081, -0.0543,  0.0414, -0.0145, -0.0188, -0.0468, -0.0493, -0.0035,\n",
       "                       0.0079,  0.0442,  0.0167, -0.0250, -0.0335,  0.0022,  0.0069, -0.0090,\n",
       "                      -0.0024, -0.0185,  0.0010, -0.0428,  0.0429, -0.0211, -0.0245, -0.0274],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.3.weight',\n",
       "              tensor([[-0.0235,  0.0069,  0.0854,  ...,  0.0154,  0.0245, -0.0909],\n",
       "                      [-0.0028, -0.0007,  0.0019,  ..., -0.0073, -0.0124,  0.0347],\n",
       "                      [-0.0760, -0.0927, -0.0532,  ..., -0.0357, -0.0083, -0.0632],\n",
       "                      ...,\n",
       "                      [ 0.0045, -0.0228, -0.1101,  ..., -0.0294, -0.0473,  0.0159],\n",
       "                      [-0.0207,  0.0103,  0.0192,  ...,  0.0072, -0.0100, -0.0049],\n",
       "                      [ 0.0154,  0.0291, -0.0099,  ...,  0.0097, -0.0531,  0.0229]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('DNAMEncoder.hidden_layers.3.bias',\n",
       "              tensor([ 1.3825e-02,  1.0186e-04, -1.5609e-02, -1.6581e-02,  3.6815e-02,\n",
       "                      -1.6815e-02, -6.1277e-02,  3.6280e-02,  3.2117e-02, -2.5590e-02,\n",
       "                       1.9281e-02,  3.4274e-02,  1.4077e-02,  4.7967e-02,  3.3045e-02,\n",
       "                      -6.6248e-02, -4.9041e-02,  5.4910e-02,  2.8043e-02,  2.2189e-05,\n",
       "                       2.4627e-03,  2.5091e-02, -1.8858e-02, -2.8103e-02, -4.0257e-03,\n",
       "                       3.6404e-02,  5.4838e-02,  5.6410e-02,  7.9067e-02,  5.3800e-02,\n",
       "                      -6.9391e-04,  5.3211e-02], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv1.lin_l.weight',\n",
       "              tensor([[-0.0084,  0.1024, -0.0935,  ..., -0.0861, -0.0004,  0.0488],\n",
       "                      [-0.0823, -0.0877, -0.0770,  ..., -0.0469, -0.0821,  0.0318],\n",
       "                      [-0.0706, -0.0675, -0.0582,  ..., -0.0568, -0.0832, -0.0468],\n",
       "                      ...,\n",
       "                      [-0.0544, -0.0535,  0.0542,  ..., -0.0831, -0.1057, -0.0549],\n",
       "                      [-0.0582, -0.0863, -0.0457,  ...,  0.0214, -0.0566, -0.0721],\n",
       "                      [ 0.0628, -0.0527, -0.0076,  ...,  0.0333,  0.0475, -0.0329]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv1.lin_l.bias',\n",
       "              tensor([ 1.4507e-03, -6.1996e-04, -4.7271e-04, -1.0241e-03, -4.4189e-04,\n",
       "                       2.0766e-04, -9.4094e-04, -4.0474e-04, -2.0211e-04, -6.9797e-06,\n",
       "                      -1.2518e-03, -2.1925e-04, -1.4888e-03, -8.5834e-04, -9.5103e-04,\n",
       "                       1.1241e-03, -7.8168e-04, -2.4209e-03, -1.8910e-03, -1.4700e-03,\n",
       "                      -1.5231e-03, -4.7852e-04,  1.0257e-03, -3.4122e-04,  1.2126e-03,\n",
       "                       3.7827e-04, -2.7776e-03, -4.6337e-04, -2.2042e-03, -1.4649e-03,\n",
       "                       9.9770e-04,  9.8744e-04, -1.9060e-03, -7.1300e-04, -3.4881e-04,\n",
       "                       1.8411e-03, -1.3203e-03,  3.4329e-04, -1.5503e-03, -1.3813e-03,\n",
       "                      -1.6568e-03,  7.7193e-04,  6.3360e-04, -1.4087e-04, -2.5664e-03,\n",
       "                       3.1726e-03, -1.5083e-03,  1.2507e-03,  1.4508e-03, -5.8831e-04,\n",
       "                      -1.9946e-04,  1.0798e-03, -1.0996e-04, -3.4495e-04, -4.4965e-04,\n",
       "                      -5.1798e-05, -4.4710e-04, -1.5716e-04, -2.7454e-07,  1.0427e-04,\n",
       "                       4.8283e-04, -4.2180e-04, -1.4995e-04,  1.1296e-03, -4.8332e-04,\n",
       "                       7.6965e-04, -3.9708e-04, -8.5739e-04, -5.0759e-04,  1.0005e-03,\n",
       "                      -9.0535e-04, -4.1457e-05, -8.0475e-04, -2.4421e-04, -1.6746e-03,\n",
       "                       1.0649e-03, -1.5342e-03, -9.9203e-04,  4.7130e-04, -1.0953e-03,\n",
       "                      -6.0804e-04, -1.4008e-03, -2.9695e-04, -1.1565e-03, -5.2903e-04,\n",
       "                       1.0700e-03,  1.3699e-03, -4.9527e-04, -3.0114e-04, -3.9401e-04,\n",
       "                      -2.4416e-03, -2.1181e-03, -3.4231e-04, -5.1291e-04, -6.6825e-04,\n",
       "                      -3.1098e-04,  1.0974e-03,  2.2353e-04, -2.8137e-04, -2.0979e-03,\n",
       "                      -1.1981e-03, -1.4850e-03, -1.8394e-03, -2.7327e-04,  4.3615e-04,\n",
       "                       2.0918e-03,  2.7937e-04,  1.9344e-03, -1.3560e-03, -2.9952e-04,\n",
       "                       3.0047e-04, -1.3470e-03, -3.4859e-04, -1.0606e-04, -2.2564e-03,\n",
       "                      -3.4724e-04, -1.5295e-03,  1.0996e-03, -6.3506e-04, -4.4515e-04,\n",
       "                      -2.8748e-04, -7.8896e-04, -1.7516e-04,  4.8668e-04, -9.8890e-05,\n",
       "                      -3.4849e-04, -1.9690e-04,  1.2948e-03, -4.0408e-04, -1.1959e-04,\n",
       "                       6.9450e-04, -9.5382e-05, -7.7654e-04,  2.5484e-05, -1.6757e-04,\n",
       "                      -4.8993e-04, -1.3635e-03, -8.1467e-04, -4.7035e-04,  4.5719e-04,\n",
       "                      -6.1843e-05,  1.6245e-04,  4.1722e-03, -1.4754e-03, -1.2193e-04,\n",
       "                       2.3564e-03, -4.9494e-04, -1.1073e-05, -9.4977e-04,  9.1191e-04,\n",
       "                       4.2831e-03,  3.8306e-05, -9.0525e-04,  9.9848e-04, -5.9686e-04,\n",
       "                      -6.3186e-04,  9.9519e-04, -1.4784e-04, -6.4221e-04, -7.5281e-04,\n",
       "                       8.1992e-04, -1.0152e-03, -8.9502e-05, -3.5792e-05, -3.4086e-04,\n",
       "                      -9.9425e-04,  5.4758e-04,  1.0091e-03, -9.2515e-05,  8.0656e-04,\n",
       "                       2.2109e-03,  2.4496e-03,  6.2328e-04, -6.7575e-04,  2.3141e-03,\n",
       "                       3.9098e-04, -3.6375e-04, -4.9531e-04,  8.9618e-04, -2.0259e-03,\n",
       "                      -1.5279e-03, -4.8403e-06, -2.1840e-03, -2.3651e-04,  2.4595e-04,\n",
       "                      -2.1450e-05,  6.7234e-05, -1.4314e-04, -3.4173e-06, -4.7040e-05,\n",
       "                      -1.1826e-03, -3.4618e-04, -2.8367e-04, -1.7895e-04, -1.8235e-03,\n",
       "                       2.5912e-03, -8.1964e-04,  9.5886e-04,  1.9734e-04, -7.0330e-04,\n",
       "                       7.3085e-05, -1.4589e-04,  2.6599e-03, -4.0609e-04,  1.3315e-03,\n",
       "                      -1.9291e-03, -6.3686e-04, -1.9668e-03, -1.2005e-04,  2.6192e-04,\n",
       "                      -8.3311e-05,  2.7599e-03, -2.4665e-04,  1.2436e-03, -1.6814e-04,\n",
       "                      -9.5503e-04,  4.1748e-03,  9.6093e-04,  2.3887e-04, -1.6455e-03,\n",
       "                      -3.1841e-04,  1.1008e-03, -1.5268e-04, -8.9866e-04, -4.0288e-04,\n",
       "                      -4.8914e-04, -6.6575e-04, -1.3109e-04, -1.5132e-04, -2.0918e-04,\n",
       "                       6.2127e-04,  1.4219e-03, -9.3262e-04,  1.1980e-04, -2.2953e-04,\n",
       "                      -2.4511e-04,  3.2033e-03, -5.9862e-04, -4.8073e-05, -1.1349e-03,\n",
       "                       2.1326e-03, -5.5286e-04,  2.1779e-03, -1.3059e-04, -9.8038e-04,\n",
       "                       7.2168e-04, -6.5954e-04, -8.0062e-04, -8.4219e-05, -1.9807e-03,\n",
       "                       1.4702e-04, -9.3106e-04, -1.9513e-04, -1.2145e-03, -1.5268e-04,\n",
       "                      -4.2541e-05], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv1.lin_r.weight',\n",
       "              tensor([[ 0.0021,  0.0841, -0.0950,  ..., -0.0750, -0.0106,  0.0476],\n",
       "                      [-0.0709, -0.0553, -0.0717,  ..., -0.0782, -0.0487,  0.0307],\n",
       "                      [-0.0452, -0.0715, -0.0546,  ..., -0.0555, -0.0571, -0.0417],\n",
       "                      ...,\n",
       "                      [-0.0584, -0.0490,  0.0702,  ..., -0.0910, -0.1065, -0.0505],\n",
       "                      [-0.0440, -0.0636, -0.0755,  ...,  0.0254, -0.0775, -0.0725],\n",
       "                      [ 0.0434, -0.0381, -0.0093,  ...,  0.0361,  0.0877, -0.0562]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv2.lin_l.weight',\n",
       "              tensor([[ 0.0490,  0.0318,  0.0587,  ...,  0.0161, -0.1059,  0.0551],\n",
       "                      [ 0.0496,  0.0633,  0.0710,  ...,  0.0211,  0.1172,  0.0754],\n",
       "                      [-0.0250, -0.0229, -0.0370,  ...,  0.0830, -0.0140, -0.1013],\n",
       "                      ...,\n",
       "                      [-0.0780, -0.0852, -0.0302,  ..., -0.0051,  0.0013, -0.0043],\n",
       "                      [ 0.0193,  0.0195,  0.0857,  ..., -0.0893,  0.0881,  0.1015],\n",
       "                      [ 0.0148,  0.0321,  0.0226,  ...,  0.0313,  0.0032,  0.0748]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv2.lin_l.bias',\n",
       "              tensor([-6.2700e-02,  1.0420e-01,  6.2483e-02, -2.6969e-02, -6.9312e-02,\n",
       "                      -1.3212e-01, -4.9117e-02, -8.9018e-02, -4.4716e-02, -1.1891e-01,\n",
       "                      -5.1345e-02, -9.3366e-03, -3.8656e-02, -7.6526e-02, -9.7729e-02,\n",
       "                       1.3333e-01, -1.1424e-01, -4.0438e-02,  1.0645e-01,  5.9765e-02,\n",
       "                      -3.7686e-02, -4.6413e-02,  1.1135e-01,  3.9790e-02, -4.3166e-02,\n",
       "                      -9.0323e-02,  1.1110e-02, -9.7862e-03, -7.0018e-02, -5.9770e-02,\n",
       "                       1.7130e-02, -7.3706e-02,  1.0294e-01, -5.9446e-02,  1.2786e-01,\n",
       "                      -3.0630e-02, -9.3430e-02,  4.7042e-02, -1.1120e-01,  4.5077e-02,\n",
       "                      -1.1839e-01,  3.1832e-02,  5.8790e-02, -1.9897e-02, -1.0207e-02,\n",
       "                       3.1086e-02, -6.3041e-02, -1.0421e-01,  9.6998e-02,  1.2765e-01,\n",
       "                      -9.2914e-02, -1.1504e-01, -3.4252e-02, -1.1090e-01,  9.8260e-02,\n",
       "                      -5.4562e-02, -3.1705e-02,  1.9185e-02, -1.2360e-03, -7.0122e-02,\n",
       "                       1.1871e-01,  1.9530e-02, -2.1490e-02,  8.4269e-02,  2.5457e-02,\n",
       "                       1.0264e-01,  8.2634e-02, -4.3109e-02, -7.2162e-05, -8.2590e-02,\n",
       "                      -8.6868e-02,  1.2563e-01, -6.3092e-02, -4.3023e-02, -1.1478e-01,\n",
       "                       1.0688e-01, -8.3811e-02, -4.9447e-02, -1.1516e-01,  1.4727e-02,\n",
       "                      -4.2660e-02, -4.2762e-02, -5.1544e-02,  7.4320e-02, -9.3070e-02,\n",
       "                       3.0871e-02,  8.5819e-02,  6.9240e-02, -6.8768e-02, -8.4148e-02,\n",
       "                       3.4085e-02, -1.7013e-02,  8.7786e-03, -2.1535e-02, -1.5443e-02,\n",
       "                      -1.7560e-02,  1.1494e-02,  7.8462e-02, -1.0107e-01,  5.8747e-02,\n",
       "                       3.0132e-02, -8.4433e-02, -8.9666e-02, -1.2176e-02, -8.9678e-02,\n",
       "                      -2.5318e-02,  4.8021e-02, -4.2164e-02, -1.1881e-01,  2.9971e-02,\n",
       "                       5.7595e-02,  4.8453e-03,  4.5751e-02, -7.6163e-02,  7.3710e-02,\n",
       "                      -1.0532e-01,  9.1572e-02, -1.1650e-01, -5.7106e-02,  3.3650e-02,\n",
       "                      -3.9703e-02,  2.9186e-02, -2.6424e-02, -9.3812e-02, -9.9542e-02,\n",
       "                      -7.5216e-02, -1.2143e-01,  1.1501e-02, -9.0369e-02, -9.4376e-02,\n",
       "                       2.1121e-02, -1.0871e-01, -1.2888e-01, -9.6921e-02,  8.1338e-02,\n",
       "                      -7.2838e-02,  1.8056e-02, -3.8409e-02,  3.0739e-02,  9.4630e-02,\n",
       "                      -3.3733e-02, -3.0491e-02,  6.7782e-02, -4.6651e-02, -8.2460e-02,\n",
       "                       1.1953e-01, -5.0491e-02, -3.9550e-02, -1.1420e-01,  3.3721e-02,\n",
       "                      -2.5647e-02,  1.1614e-01, -1.0101e-01, -3.2694e-02, -1.0299e-01,\n",
       "                      -3.2987e-02, -9.5080e-02,  2.8681e-02, -1.7203e-02,  8.5640e-02,\n",
       "                      -1.1082e-01, -1.2755e-01,  4.2925e-02, -4.5660e-02, -3.6041e-02,\n",
       "                      -1.1274e-01, -9.6304e-02,  3.9863e-02,  3.8047e-02,  5.3141e-02,\n",
       "                      -5.7754e-02, -7.5231e-02, -5.2626e-02, -5.9338e-02, -8.5639e-02,\n",
       "                       3.9344e-02, -1.9016e-02, -1.1708e-01,  1.1666e-01, -4.8617e-03,\n",
       "                      -2.2308e-02, -1.1982e-01,  7.0394e-02, -1.3476e-02, -5.2091e-02,\n",
       "                       8.0379e-02,  1.5182e-02, -2.0170e-02,  3.8521e-02,  1.3175e-01,\n",
       "                      -1.0978e-01, -1.2003e-01, -4.1482e-02, -1.0589e-01,  7.0255e-02,\n",
       "                       2.9193e-02,  6.3789e-02,  1.1023e-01, -7.3870e-02, -2.6088e-02,\n",
       "                      -2.2125e-02, -1.0650e-02,  1.3606e-01,  4.8247e-02, -5.2804e-02,\n",
       "                      -5.7468e-02,  9.6914e-02, -1.1791e-01,  9.9519e-02, -6.5602e-02,\n",
       "                      -1.3599e-02,  1.3877e-01,  9.0975e-02, -6.1383e-02, -2.2486e-02,\n",
       "                       2.5794e-02,  1.2701e-01,  7.8384e-02,  2.9465e-02, -5.6049e-03,\n",
       "                       6.9392e-02, -1.2054e-01, -4.0653e-02, -1.0178e-01, -6.0577e-02,\n",
       "                      -3.9240e-02, -4.4236e-02, -6.0212e-02,  5.5953e-02, -1.0491e-01,\n",
       "                      -2.9245e-02, -1.0337e-01,  3.1231e-02,  1.9537e-02, -9.3638e-03,\n",
       "                      -1.0919e-01, -6.5015e-02, -2.1307e-02, -1.3187e-02,  1.9512e-02,\n",
       "                      -1.2278e-01, -9.6575e-02, -1.3485e-01, -7.4853e-02, -2.0877e-02,\n",
       "                      -1.0097e-01,  1.3711e-01, -4.6461e-02, -3.7870e-02, -8.7641e-02,\n",
       "                      -1.2066e-02, -7.5395e-02, -1.3852e-01, -1.1630e-01, -3.8768e-02,\n",
       "                      -6.9560e-02], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv2.lin_r.weight',\n",
       "              tensor([[ 0.0194,  0.0968,  0.0199,  ...,  0.0184, -0.0112,  0.0897],\n",
       "                      [ 0.0945,  0.1250,  0.0456,  ...,  0.0860,  0.1049,  0.0857],\n",
       "                      [ 0.0298, -0.0941, -0.0592,  ...,  0.0162, -0.1020, -0.0471],\n",
       "                      ...,\n",
       "                      [-0.0523, -0.0703, -0.0114,  ..., -0.0309,  0.0135, -0.0272],\n",
       "                      [ 0.1244,  0.0691,  0.1130,  ..., -0.0441,  0.0224,  0.0251],\n",
       "                      [ 0.0986,  0.0878,  0.0909,  ...,  0.0079,  0.0464,  0.0570]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv3.lin_l.weight',\n",
       "              tensor([[-0.1027, -0.0539,  0.0785,  ..., -0.1424,  0.0676, -0.0411],\n",
       "                      [ 0.1206,  0.1281, -0.0391,  ...,  0.1154, -0.0505,  0.1047],\n",
       "                      [ 0.1089,  0.0424, -0.0352,  ...,  0.0769, -0.1221,  0.0086],\n",
       "                      ...,\n",
       "                      [-0.1045, -0.0246,  0.0964,  ..., -0.0853,  0.0578, -0.0911],\n",
       "                      [ 0.0513,  0.0350, -0.1003,  ...,  0.0626,  0.0507,  0.0363],\n",
       "                      [-0.1086, -0.0243,  0.1261,  ..., -0.0615, -0.0042, -0.0621]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv3.lin_l.bias',\n",
       "              tensor([ 0.1074,  0.0265,  0.0211,  0.0187,  0.1358,  0.1053,  0.0124,  0.1114,\n",
       "                       0.0367,  0.0681,  0.1045,  0.0226,  0.0545, -0.1165, -0.1053,  0.1233,\n",
       "                      -0.0375,  0.1239,  0.1232, -0.1030,  0.1285,  0.0586,  0.0770,  0.0853,\n",
       "                       0.0841, -0.0439, -0.0829,  0.0571,  0.1066, -0.1160,  0.0124,  0.0286,\n",
       "                      -0.0207,  0.0077, -0.0529,  0.1196,  0.0213, -0.0220,  0.0008, -0.0528,\n",
       "                       0.0754, -0.0725, -0.0917, -0.1105, -0.0520,  0.0710, -0.1237,  0.0413,\n",
       "                       0.0704, -0.0639, -0.0979,  0.0260, -0.0626, -0.1389,  0.0260,  0.0389,\n",
       "                      -0.0786,  0.0783,  0.0345, -0.0362, -0.0322, -0.0271, -0.1083,  0.0295,\n",
       "                      -0.0313, -0.0923, -0.0794, -0.0982, -0.0549, -0.0736, -0.1156, -0.1305,\n",
       "                      -0.0762, -0.0665, -0.0116,  0.1111,  0.0205, -0.1039, -0.0356,  0.0301,\n",
       "                      -0.0796,  0.0364, -0.0835,  0.0864,  0.0886,  0.0112, -0.0187,  0.1090,\n",
       "                      -0.0693, -0.0170,  0.1161,  0.0144, -0.0695, -0.0975,  0.0532, -0.0250,\n",
       "                      -0.0425, -0.1060, -0.0973, -0.1304, -0.0159, -0.0168, -0.0891,  0.0043,\n",
       "                       0.1252,  0.0282, -0.0321,  0.1266,  0.0591,  0.0646, -0.0423,  0.0501,\n",
       "                      -0.0184, -0.0919, -0.1373, -0.0686, -0.0421, -0.0140, -0.0895,  0.0616,\n",
       "                       0.0221,  0.0160, -0.1043,  0.0266, -0.0241, -0.0578, -0.1024,  0.1173,\n",
       "                       0.1258, -0.0665,  0.1001,  0.0640,  0.0745,  0.0414,  0.0258,  0.0569,\n",
       "                       0.0275,  0.0139, -0.0676, -0.1013, -0.1181, -0.0085,  0.0255,  0.1003,\n",
       "                      -0.0519,  0.1216,  0.1263,  0.1335,  0.1208, -0.0205, -0.1118, -0.0986,\n",
       "                       0.1129,  0.0250,  0.0043,  0.0861,  0.1043,  0.0231,  0.0382, -0.0885,\n",
       "                       0.1116,  0.0266, -0.0596, -0.0449, -0.0552, -0.0674, -0.0523,  0.0859,\n",
       "                      -0.1046,  0.1020, -0.1093,  0.0763, -0.0565,  0.1401,  0.0534,  0.0288,\n",
       "                      -0.1019, -0.1223, -0.0718, -0.0211, -0.1156,  0.1005, -0.0675, -0.1340,\n",
       "                      -0.0912,  0.0327, -0.0380,  0.1025,  0.0934, -0.0900, -0.1377,  0.0858,\n",
       "                      -0.0718, -0.0715,  0.0815, -0.0983, -0.0693, -0.0762,  0.0941,  0.0317,\n",
       "                      -0.0993,  0.1280,  0.0332,  0.1123, -0.1047,  0.1271, -0.0349, -0.1302,\n",
       "                       0.0475, -0.0714,  0.1133, -0.0483, -0.1010,  0.1271,  0.0555, -0.0779,\n",
       "                      -0.0177, -0.0055, -0.0364,  0.1165, -0.0740, -0.0369,  0.0521,  0.1217,\n",
       "                       0.0664, -0.1135,  0.0365, -0.1102,  0.0255, -0.0265,  0.0085, -0.0622,\n",
       "                       0.0990, -0.0115, -0.1180,  0.0713,  0.1216, -0.0281,  0.0831, -0.0614,\n",
       "                      -0.1148,  0.0140,  0.1043,  0.0515,  0.0970, -0.0235,  0.0837, -0.0765,\n",
       "                      -0.0587, -0.0416, -0.0339, -0.0480,  0.1340,  0.1053,  0.0170,  0.1447],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.conv3.lin_r.weight',\n",
       "              tensor([[-0.1398, -0.0162,  0.0822,  ..., -0.0452,  0.0247, -0.1300],\n",
       "                      [ 0.1064,  0.1176, -0.0802,  ...,  0.0712, -0.1148,  0.0884],\n",
       "                      [ 0.0241,  0.0165, -0.1027,  ...,  0.0117, -0.0286, -0.0717],\n",
       "                      ...,\n",
       "                      [-0.1036, -0.1165,  0.0375,  ..., -0.0912, -0.0026, -0.1066],\n",
       "                      [ 0.0126,  0.0281, -0.0272,  ...,  0.0573,  0.0417,  0.0301],\n",
       "                      [-0.0489, -0.0328,  0.1119,  ..., -0.0906,  0.0197, -0.0969]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool.gnn.lin_rel.weight',\n",
       "              tensor([[-0.0539, -0.0963, -0.1290,  0.1017,  0.0738, -0.0501, -0.1174, -0.0039,\n",
       "                        0.0417,  0.0832,  0.0191, -0.0993,  0.0186, -0.0668,  0.0420,  0.0606,\n",
       "                        0.0267,  0.0184,  0.0784, -0.0549, -0.1132, -0.0818, -0.0235,  0.0550,\n",
       "                        0.0465,  0.0922,  0.1096, -0.0901, -0.0597,  0.0073, -0.0383,  0.0989,\n",
       "                        0.0051, -0.0800, -0.1098,  0.1040, -0.0293,  0.0876,  0.0131, -0.0418,\n",
       "                        0.0318, -0.0277, -0.0652, -0.0774,  0.0156,  0.1191,  0.0087, -0.0443,\n",
       "                       -0.0534, -0.0279, -0.1049, -0.0364, -0.0806, -0.0686, -0.1245, -0.0453,\n",
       "                       -0.0519,  0.1203, -0.0442,  0.0822, -0.0460, -0.0811, -0.0627,  0.1032,\n",
       "                       -0.0439,  0.1253, -0.1134, -0.0397,  0.0291, -0.0399,  0.0360,  0.1164,\n",
       "                       -0.0988, -0.0299, -0.0463, -0.0388, -0.1081,  0.0481,  0.1131, -0.0597,\n",
       "                       -0.1210,  0.0156, -0.0442,  0.0732, -0.0351,  0.0621, -0.0782,  0.0822,\n",
       "                       -0.0638, -0.0979,  0.0125, -0.1135, -0.0869, -0.1016, -0.0651,  0.0660,\n",
       "                        0.1209, -0.0324, -0.0587,  0.0167, -0.0961, -0.0547,  0.0210, -0.0792,\n",
       "                        0.0865, -0.0186, -0.0618,  0.1016,  0.0832, -0.0569, -0.1156,  0.0427,\n",
       "                       -0.0428, -0.0436,  0.0162, -0.0922,  0.0145, -0.0771,  0.0410, -0.0927,\n",
       "                       -0.0995,  0.0949, -0.0631, -0.0161, -0.0844, -0.0526, -0.0743, -0.0598,\n",
       "                       -0.0844, -0.0353, -0.0746, -0.0184, -0.1202, -0.0897, -0.1023,  0.1132,\n",
       "                       -0.0475,  0.1097, -0.0953, -0.0727, -0.1212, -0.0865, -0.0479,  0.0142,\n",
       "                       -0.1058, -0.0041, -0.0168, -0.1218, -0.0949,  0.1062,  0.0452,  0.0677,\n",
       "                        0.0501,  0.1093, -0.1085, -0.0948, -0.0477,  0.0302, -0.1041,  0.0216,\n",
       "                        0.0725, -0.0875, -0.1081, -0.0348, -0.0052,  0.0245, -0.0746,  0.1198,\n",
       "                       -0.0205,  0.1187, -0.0084,  0.1194, -0.0168,  0.0743,  0.0443, -0.0093,\n",
       "                       -0.0887, -0.0148,  0.1197,  0.0086, -0.0495, -0.0692, -0.1198, -0.1153,\n",
       "                       -0.0522, -0.0251,  0.0971,  0.1149, -0.1062, -0.0934, -0.1223, -0.0323,\n",
       "                        0.0345, -0.0919, -0.0607,  0.1134,  0.0269, -0.0680,  0.0904, -0.0142,\n",
       "                       -0.0989, -0.0806, -0.0117, -0.0568, -0.0983,  0.1141, -0.1069, -0.0220,\n",
       "                       -0.0571,  0.0620, -0.0970,  0.0882, -0.0476,  0.1261, -0.0782, -0.0338,\n",
       "                        0.1189, -0.0328, -0.0605, -0.1209, -0.0509,  0.0863, -0.0517, -0.1087,\n",
       "                       -0.0822, -0.1249, -0.1120, -0.0050, -0.0329, -0.0419,  0.0525,  0.1113,\n",
       "                        0.0225, -0.0266, -0.0520, -0.0133,  0.1173,  0.0466, -0.0882,  0.0168,\n",
       "                       -0.0192, -0.0554, -0.0748, -0.0465, -0.1294,  0.0909, -0.1067,  0.0595,\n",
       "                       -0.0878,  0.0093,  0.0751, -0.1132, -0.0311, -0.0668, -0.0196, -0.0373]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool.gnn.lin_rel.bias',\n",
       "              tensor([0.0933], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool.gnn.lin_root.weight',\n",
       "              tensor([[-0.0759, -0.1174, -0.0485,  0.0679,  0.0830, -0.0606, -0.0398, -0.0235,\n",
       "                        0.0490,  0.1044,  0.0419, -0.0317,  0.1120, -0.0290,  0.0160,  0.0836,\n",
       "                        0.0181,  0.0550,  0.0573, -0.0379, -0.1211, -0.0128, -0.0316,  0.0478,\n",
       "                       -0.0389,  0.0874,  0.1186, -0.1232, -0.1059,  0.0179, -0.0713,  0.1252,\n",
       "                        0.0603, -0.1167, -0.0096,  0.1265, -0.0566,  0.0263,  0.0369, -0.1049,\n",
       "                        0.0217, -0.1080, -0.0263, -0.0102,  0.0312,  0.0645,  0.1128, -0.0311,\n",
       "                       -0.0702, -0.0997, -0.0691, -0.0075, -0.1118, -0.1239, -0.0105, -0.0485,\n",
       "                       -0.1154,  0.0210, -0.0831,  0.1257, -0.0474, -0.0509, -0.1147,  0.0470,\n",
       "                       -0.0620,  0.1114, -0.0824, -0.0829,  0.1240, -0.0556,  0.0533,  0.0598,\n",
       "                       -0.1063, -0.0806, -0.0133, -0.0383, -0.1042,  0.0663,  0.0604, -0.0145,\n",
       "                       -0.1154,  0.0404, -0.0832,  0.0175, -0.0478,  0.0985, -0.0679,  0.0889,\n",
       "                       -0.0379, -0.0253,  0.0138, -0.0430, -0.0238, -0.0602, -0.0066,  0.0462,\n",
       "                        0.1069, -0.0123, -0.0290,  0.0820, -0.0224, -0.0332,  0.0277, -0.0035,\n",
       "                        0.1108, -0.0793, -0.0392,  0.1168,  0.0972, -0.0422, -0.0892,  0.0500,\n",
       "                       -0.1254, -0.0170,  0.0122, -0.0338, -0.0041, -0.0766,  0.0118, -0.1189,\n",
       "                       -0.0598,  0.0781, -0.1177, -0.0992, -0.0229, -0.0453, -0.0576, -0.0818,\n",
       "                       -0.1038, -0.0860, -0.0623, -0.0255, -0.0282, -0.0550, -0.0294,  0.0142,\n",
       "                       -0.1168,  0.1145, -0.0287, -0.0100, -0.0650, -0.0967, -0.0861,  0.0545,\n",
       "                       -0.0108, -0.0778, -0.0735, -0.0902, -0.0967,  0.0558,  0.1214,  0.0512,\n",
       "                        0.0422,  0.0796, -0.0555, -0.0709, -0.0656,  0.0121, -0.0621,  0.1262,\n",
       "                        0.1228, -0.0871, -0.0312, -0.1146, -0.0706,  0.0648, -0.0720,  0.0213,\n",
       "                       -0.0637,  0.0505, -0.1074,  0.0503, -0.0786,  0.0904,  0.0961, -0.0353,\n",
       "                       -0.0205, -0.0845,  0.1250,  0.0413, -0.0007, -0.0915, -0.0552, -0.0644,\n",
       "                       -0.0659, -0.1261,  0.1244,  0.0853, -0.0469, -0.0551, -0.0166, -0.0633,\n",
       "                        0.0201, -0.0653, -0.1078,  0.0922,  0.0602, -0.0072,  0.1061, -0.0444,\n",
       "                       -0.1110, -0.0366, -0.1243, -0.1249, -0.0806,  0.1223, -0.0301, -0.0831,\n",
       "                       -0.0247,  0.0840, -0.1270,  0.1159, -0.0910,  0.0464, -0.0914, -0.1284,\n",
       "                        0.0136, -0.1074, -0.0640, -0.0876, -0.0677,  0.0414, -0.0958, -0.0654,\n",
       "                       -0.1129, -0.0375, -0.0637, -0.1194, -0.1148, -0.1061,  0.1117,  0.0689,\n",
       "                        0.1053, -0.1282, -0.1004, -0.0661,  0.0305,  0.0153, -0.0570,  0.1008,\n",
       "                       -0.0868, -0.0641, -0.0046, -0.0212, -0.1001,  0.0800, -0.0088,  0.0494,\n",
       "                       -0.1108,  0.1294,  0.0839, -0.1066, -0.1157, -0.0939, -0.0865, -0.0781]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool2.gnn.lin_rel.weight',\n",
       "              tensor([[-0.1050, -0.1203,  0.0970,  0.0301,  0.0399,  0.0091, -0.0326, -0.0183,\n",
       "                       -0.0335,  0.0438,  0.0199, -0.0782, -0.0359, -0.1322, -0.1374,  0.1240,\n",
       "                       -0.1011, -0.0584, -0.0510,  0.1233, -0.1230,  0.0256, -0.0704,  0.0946,\n",
       "                        0.0398, -0.0874, -0.1149,  0.0199, -0.0842, -0.1048, -0.0632,  0.0505,\n",
       "                       -0.0655, -0.1302, -0.0154, -0.0294,  0.0245,  0.0750, -0.0259, -0.0741,\n",
       "                       -0.0809, -0.0704, -0.0552,  0.0554,  0.0404,  0.1151, -0.1323, -0.1140,\n",
       "                       -0.0453, -0.0704, -0.1383, -0.0887, -0.0898, -0.0981, -0.0148, -0.0540,\n",
       "                       -0.0609, -0.0475, -0.1112, -0.1305, -0.0452,  0.1153, -0.0499, -0.0308,\n",
       "                        0.1104, -0.0801,  0.1000, -0.0831, -0.0973, -0.0081, -0.0912,  0.1163,\n",
       "                        0.0491, -0.1068, -0.0640,  0.1170, -0.1246, -0.1134, -0.0254, -0.1282,\n",
       "                       -0.1245, -0.0242, -0.0437,  0.1157, -0.0353, -0.0236,  0.0980, -0.0214,\n",
       "                        0.0317, -0.1098, -0.0728, -0.0824, -0.1077, -0.0344, -0.0892, -0.0958,\n",
       "                       -0.0583,  0.1093, -0.1172,  0.1015, -0.1085, -0.1172,  0.0543,  0.0393,\n",
       "                        0.0143, -0.0606, -0.1149,  0.0214, -0.1331, -0.0632,  0.1022, -0.0560,\n",
       "                       -0.0728, -0.0703, -0.0196, -0.1200, -0.0258, -0.0784, -0.1293,  0.0737,\n",
       "                       -0.1090, -0.0418, -0.0875, -0.0570, -0.1028, -0.0994, -0.0430, -0.0585,\n",
       "                        0.0100, -0.1405,  0.0826, -0.0446,  0.0422,  0.0116, -0.1061,  0.0465,\n",
       "                       -0.0257, -0.1002, -0.1408,  0.0586, -0.0552, -0.1385,  0.0683, -0.1296,\n",
       "                       -0.1010, -0.0964, -0.1011,  0.0595, -0.0540, -0.0829,  0.0540, -0.1037,\n",
       "                       -0.0199, -0.0726, -0.1202, -0.0650, -0.1379, -0.0578, -0.1122,  0.0912,\n",
       "                       -0.1308,  0.0178, -0.0509, -0.0685, -0.1291, -0.1219,  0.0669,  0.1226,\n",
       "                        0.0942,  0.1172, -0.0564,  0.0257, -0.0606,  0.0261, -0.0973,  0.1097,\n",
       "                       -0.1198,  0.0462,  0.1211, -0.0714, -0.0809, -0.1068, -0.0386,  0.0583,\n",
       "                       -0.1081, -0.0741, -0.0718, -0.0937, -0.0567,  0.1007, -0.1270,  0.0704,\n",
       "                       -0.1247, -0.0995,  0.0882, -0.0134, -0.0517,  0.1186, -0.0488, -0.1398,\n",
       "                        0.0273, -0.1281,  0.1119,  0.0713, -0.0587, -0.0993, -0.0798, -0.1000,\n",
       "                        0.1153, -0.0575, -0.1084,  0.0995, -0.0708, -0.0928,  0.0221,  0.1339,\n",
       "                       -0.0160,  0.0804,  0.1363, -0.0265, -0.0239,  0.0482, -0.0637, -0.0975,\n",
       "                        0.0545,  0.0227,  0.0419, -0.0664,  0.0885, -0.0431, -0.0377,  0.0387,\n",
       "                       -0.0230,  0.1071, -0.1120,  0.0515, -0.1022,  0.0405, -0.1340, -0.0215,\n",
       "                       -0.1390, -0.0307, -0.1185, -0.0970, -0.0483, -0.0831,  0.0797, -0.0965,\n",
       "                       -0.0128, -0.0733, -0.1417,  0.0496, -0.1052, -0.1088,  0.0525, -0.1119]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool2.gnn.lin_rel.bias',\n",
       "              tensor([0.1082], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool2.gnn.lin_root.weight',\n",
       "              tensor([[-0.1321, -0.0329,  0.0824,  0.0451,  0.1236,  0.0317, -0.0450, -0.0931,\n",
       "                       -0.0455,  0.0736,  0.0280, -0.0762, -0.0180, -0.0949, -0.0383,  0.0374,\n",
       "                       -0.1084, -0.0677, -0.1225,  0.0914, -0.0586,  0.1287, -0.0336,  0.0388,\n",
       "                        0.1257, -0.0811, -0.1065,  0.0891, -0.0535, -0.1111, -0.0860,  0.0642,\n",
       "                       -0.0569, -0.1213, -0.1274, -0.1311,  0.0773,  0.0278, -0.0324, -0.0140,\n",
       "                       -0.0837, -0.0828, -0.0931,  0.0324,  0.0827,  0.0570, -0.1101, -0.1007,\n",
       "                       -0.0200, -0.0713, -0.1071, -0.0736, -0.0250, -0.0309, -0.0445, -0.0676,\n",
       "                       -0.0849, -0.0901, -0.0477, -0.1288, -0.0434,  0.0680, -0.0505, -0.0593,\n",
       "                        0.0630, -0.1316,  0.1234, -0.0419, -0.0818, -0.0790, -0.1192,  0.0197,\n",
       "                        0.0326, -0.1140, -0.0650,  0.0703, -0.0739, -0.0577, -0.0656, -0.0462,\n",
       "                       -0.0629, -0.0956, -0.0500,  0.1288, -0.0872, -0.0528,  0.1259, -0.0305,\n",
       "                        0.0568, -0.0117, -0.1089, -0.1165, -0.0225, -0.0565, -0.1165, -0.0754,\n",
       "                       -0.0660,  0.1094, -0.0275,  0.0530, -0.1265, -0.1131,  0.0244,  0.0783,\n",
       "                        0.1142, -0.0879, -0.1076,  0.0332, -0.0303, -0.0569,  0.0587, -0.0554,\n",
       "                       -0.0801, -0.0158, -0.0486, -0.0855, -0.0660, -0.0726, -0.1237,  0.1145,\n",
       "                       -0.0338, -0.0424, -0.0596, -0.0315, -0.0965, -0.1119, -0.0906, -0.0678,\n",
       "                        0.0556, -0.0900,  0.0377, -0.0372,  0.0682,  0.0714, -0.0487,  0.0406,\n",
       "                       -0.0490, -0.0302, -0.1309,  0.1325, -0.1238, -0.1292,  0.0681, -0.0374,\n",
       "                       -0.0527, -0.1127, -0.0166,  0.1129, -0.0543, -0.0998,  0.1053, -0.0936,\n",
       "                       -0.0776, -0.0592, -0.0864, -0.0749, -0.0879, -0.0734, -0.0651,  0.1348,\n",
       "                       -0.1322,  0.1283, -0.0945, -0.0446, -0.1247, -0.0246,  0.0842,  0.0682,\n",
       "                        0.0678,  0.1111, -0.1064,  0.0831, -0.1154,  0.1111, -0.1191,  0.0582,\n",
       "                       -0.0459,  0.0287,  0.1170, -0.1218, -0.0999, -0.1149, -0.1297,  0.1124,\n",
       "                       -0.0783, -0.1290, -0.1287, -0.0291, -0.1133,  0.1152, -0.0403,  0.0350,\n",
       "                       -0.1283, -0.0924,  0.0715, -0.0538, -0.0690,  0.0654, -0.0972, -0.0453,\n",
       "                        0.0227, -0.0953,  0.1161,  0.1317, -0.1016, -0.0099, -0.0989, -0.0505,\n",
       "                        0.0803, -0.1301, -0.0672,  0.0396, -0.1310, -0.1153,  0.0964,  0.0946,\n",
       "                       -0.0471,  0.0941,  0.0345, -0.1385, -0.1293,  0.1372, -0.1223, -0.0757,\n",
       "                        0.0237,  0.1169,  0.0484, -0.1302,  0.0502, -0.0592, -0.0595,  0.0851,\n",
       "                       -0.0452,  0.1312, -0.0433,  0.1092, -0.0489,  0.0789, -0.1235, -0.0492,\n",
       "                       -0.0879, -0.0814, -0.1126, -0.1184, -0.0618, -0.0917,  0.0296, -0.0795,\n",
       "                       -0.0780, -0.0782, -0.0192,  0.1232, -0.0632, -0.0572,  0.0325, -0.1060]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool3.gnn.lin_rel.weight',\n",
       "              tensor([[ 0.0304,  0.0440,  0.1086,  0.0587, -0.1118, -0.0690,  0.0338, -0.1275,\n",
       "                       -0.0930,  0.0603, -0.1209,  0.0335, -0.0789,  0.0912, -0.0276,  0.0286,\n",
       "                        0.0925,  0.0396, -0.1028,  0.0893,  0.0539,  0.0847,  0.1031, -0.1391,\n",
       "                        0.0735,  0.0980, -0.0567,  0.0134,  0.0166, -0.0501,  0.0836,  0.1193,\n",
       "                        0.0226,  0.0281,  0.0616, -0.0895,  0.0073,  0.1054,  0.0980,  0.1049,\n",
       "                        0.0349, -0.0572,  0.0783,  0.0258,  0.0898, -0.1223,  0.0969,  0.0534,\n",
       "                       -0.1265,  0.0374,  0.1033,  0.0865,  0.1036, -0.0376, -0.0595, -0.1355,\n",
       "                       -0.0331, -0.1194,  0.0522,  0.0945,  0.1266,  0.1085,  0.1289,  0.0236,\n",
       "                       -0.0622,  0.1292, -0.0390,  0.0869, -0.0429, -0.0247,  0.0663, -0.0619,\n",
       "                       -0.0224, -0.0343,  0.1218, -0.1044,  0.0271, -0.0212,  0.1193,  0.1347,\n",
       "                        0.1200,  0.1120,  0.1295,  0.0812, -0.1202, -0.1102,  0.1156,  0.0271,\n",
       "                        0.0818,  0.1266,  0.0247,  0.0101,  0.0560,  0.0158,  0.0692, -0.0426,\n",
       "                       -0.0675, -0.0187,  0.0663, -0.1010,  0.1339,  0.0529, -0.0772,  0.1134,\n",
       "                       -0.0851, -0.1105, -0.0574, -0.0914, -0.1072,  0.1214,  0.1101, -0.1419,\n",
       "                        0.0912, -0.0637, -0.0279, -0.0716,  0.1254,  0.0935,  0.1193,  0.0780,\n",
       "                        0.0180,  0.0894,  0.1104, -0.1331,  0.0875,  0.0952,  0.1160,  0.0359,\n",
       "                        0.0737,  0.1014,  0.0400, -0.0922, -0.1134,  0.0429,  0.0714, -0.0803,\n",
       "                       -0.1038, -0.0139,  0.0668,  0.1243, -0.0455,  0.1377, -0.0733, -0.0896,\n",
       "                       -0.0159,  0.0539,  0.0314, -0.1113, -0.1325,  0.1164, -0.0693,  0.1308,\n",
       "                       -0.1043,  0.0560,  0.1325,  0.0605,  0.0670, -0.0225,  0.0546,  0.0895,\n",
       "                       -0.0843,  0.0479,  0.0772,  0.1182,  0.0916,  0.0052, -0.0603,  0.0344,\n",
       "                       -0.0462,  0.0509, -0.0159,  0.0399, -0.0464, -0.1168,  0.0490,  0.1060,\n",
       "                       -0.0362, -0.0372, -0.0776, -0.0243,  0.1165,  0.0762, -0.0701, -0.0237,\n",
       "                        0.1254,  0.0205,  0.1013,  0.0591,  0.0310, -0.0655, -0.0324, -0.1377,\n",
       "                       -0.0257,  0.1065, -0.0767, -0.0348,  0.1272,  0.1147, -0.1326, -0.0711,\n",
       "                       -0.0248, -0.0980,  0.0611,  0.0102,  0.1107, -0.0798, -0.0679, -0.0524,\n",
       "                        0.1010, -0.0176, -0.1256, -0.0585,  0.0872,  0.0383, -0.0842, -0.0447,\n",
       "                        0.0968,  0.1019,  0.1117,  0.0463, -0.0200, -0.0566, -0.1373, -0.1077,\n",
       "                       -0.0978,  0.0721,  0.0566, -0.0405,  0.0206,  0.1196,  0.0712, -0.0285,\n",
       "                        0.1069,  0.1394,  0.1025,  0.0419,  0.0769, -0.0222,  0.1028,  0.0979,\n",
       "                       -0.0564,  0.0710, -0.1186,  0.0318,  0.0194, -0.0154, -0.0725,  0.1093,\n",
       "                        0.1102, -0.0487,  0.1376, -0.0857, -0.0768, -0.1040,  0.0913,  0.0246]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool3.gnn.lin_rel.bias',\n",
       "              tensor([-0.0369], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.pool3.gnn.lin_root.weight',\n",
       "              tensor([[ 0.0430,  0.0730,  0.0844,  0.1115, -0.1413, -0.0860,  0.1003, -0.0681,\n",
       "                       -0.0223,  0.0878, -0.0547,  0.0576, -0.0513,  0.0907, -0.1131,  0.0973,\n",
       "                        0.0240,  0.0877, -0.0466,  0.0109,  0.0561,  0.0455,  0.0574, -0.0809,\n",
       "                        0.0156,  0.0604, -0.0921,  0.0286,  0.0505, -0.0673,  0.0187,  0.0878,\n",
       "                        0.0620,  0.1216,  0.0808, -0.0755,  0.0772,  0.0556,  0.0513,  0.0614,\n",
       "                        0.1322, -0.0280,  0.1178,  0.0413,  0.1241, -0.0745,  0.0836,  0.0660,\n",
       "                       -0.0859,  0.0750,  0.0298,  0.0331,  0.1011, -0.0703, -0.0991, -0.0964,\n",
       "                       -0.0926, -0.0982,  0.0968,  0.0131,  0.0536,  0.1234,  0.0524,  0.0875,\n",
       "                       -0.1402,  0.0403, -0.0161, -0.0180, -0.0190, -0.0390,  0.1077, -0.1007,\n",
       "                       -0.0553, -0.0791,  0.0238, -0.0320, -0.0060, -0.0489,  0.0859,  0.0299,\n",
       "                        0.0891,  0.1086,  0.1408,  0.0441, -0.0645, -0.1317,  0.0693,  0.0819,\n",
       "                        0.0614,  0.0626,  0.0506,  0.1121,  0.0740,  0.1256, -0.1027, -0.0809,\n",
       "                       -0.0861, -0.0504,  0.0923, -0.0209,  0.1363,  0.0290, -0.0554,  0.0268,\n",
       "                       -0.0288, -0.0962, -0.0259, -0.0584, -0.0081,  0.1164,  0.1115, -0.0993,\n",
       "                        0.1217, -0.0580, -0.0267, -0.0554,  0.0261,  0.0981,  0.0637,  0.0771,\n",
       "                        0.1294,  0.0335,  0.0429, -0.0970,  0.0983,  0.0263,  0.0235,  0.0400,\n",
       "                        0.0295,  0.0594,  0.0134, -0.0704, -0.0899,  0.0947,  0.1111, -0.1079,\n",
       "                       -0.1019,  0.0208,  0.0576,  0.1081, -0.1147,  0.0731, -0.1008, -0.0920,\n",
       "                        0.0357,  0.0738,  0.1230, -0.0349, -0.0891,  0.0289, -0.0238,  0.1049,\n",
       "                       -0.0589,  0.0200,  0.0534,  0.0333,  0.0469,  0.0999,  0.0371,  0.0687,\n",
       "                       -0.0980,  0.0496,  0.0385,  0.0718,  0.0412,  0.0624, -0.0941,  0.0656,\n",
       "                       -0.0468,  0.0399, -0.0623,  0.0470, -0.0865, -0.1156,  0.0993,  0.0935,\n",
       "                       -0.1235, -0.0770, -0.0852, -0.0734,  0.0860,  0.1360, -0.0588, -0.0411,\n",
       "                        0.1158,  0.0277,  0.1023,  0.0476,  0.0893, -0.0237,  0.0303, -0.0361,\n",
       "                       -0.0579,  0.1287, -0.0840, -0.1361,  0.0683,  0.0457, -0.0956, -0.0297,\n",
       "                       -0.0762, -0.0781,  0.0369,  0.0888,  0.0629, -0.0810, -0.1034, -0.0937,\n",
       "                        0.0770, -0.0984, -0.0891, -0.1419,  0.0439,  0.0452, -0.0536, -0.0015,\n",
       "                        0.0571,  0.0226,  0.0949, -0.0210, -0.0250, -0.1183, -0.0821, -0.0774,\n",
       "                       -0.0959,  0.1141,  0.1165, -0.0946,  0.0291,  0.0522,  0.1071, -0.1154,\n",
       "                        0.0643,  0.1403,  0.0937,  0.0565, -0.0580, -0.1216,  0.0673,  0.0145,\n",
       "                       -0.0574,  0.0573, -0.0249,  0.0230,  0.0636, -0.0443, -0.1191,  0.0614,\n",
       "                        0.0573, -0.0755,  0.1004, -0.0595, -0.0232, -0.0820,  0.0979,  0.1300]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.fc.weight',\n",
       "              tensor([[-0.0653,  0.0541, -0.0820,  ..., -0.0385, -0.0613,  0.0229],\n",
       "                      [-0.0634,  0.0339, -0.0673,  ..., -0.0619,  0.0231,  0.0637],\n",
       "                      [-0.0944, -0.0028, -0.0303,  ...,  0.0238, -0.0869,  0.0098],\n",
       "                      ...,\n",
       "                      [ 0.0735,  0.0045,  0.1008,  ...,  0.0069, -0.0578, -0.0236],\n",
       "                      [ 0.0843,  0.0046,  0.1007,  ..., -0.0722,  0.0873, -0.0690],\n",
       "                      [-0.1049, -0.0460, -0.0389,  ..., -0.0375,  0.0555,  0.0716]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.fc.bias',\n",
       "              tensor([-0.0256, -0.0760, -0.0960, -0.0491, -0.0383, -0.0581,  0.0448,  0.0624,\n",
       "                      -0.0988,  0.0262, -0.0473, -0.0763, -0.0343, -0.0728, -0.0744, -0.0753,\n",
       "                      -0.1023,  0.0374, -0.0636,  0.0417, -0.1018,  0.0234, -0.0796, -0.0688,\n",
       "                       0.0015,  0.0816,  0.0308,  0.0119, -0.0888,  0.0253, -0.0132, -0.0706,\n",
       "                      -0.0721, -0.0712,  0.0721,  0.0521,  0.0657,  0.0489,  0.0839, -0.0280,\n",
       "                       0.0743,  0.0536, -0.0584, -0.0653, -0.0999, -0.0881, -0.0388, -0.0524,\n",
       "                      -0.0837, -0.0587, -0.0778, -0.0610,  0.0688, -0.0545, -0.0749,  0.0233,\n",
       "                      -0.0622, -0.0606, -0.0672, -0.0206, -0.1020, -0.0716, -0.0261,  0.0343,\n",
       "                      -0.0822,  0.0066, -0.0678,  0.0131,  0.0564, -0.0393, -0.0912, -0.0164,\n",
       "                      -0.0818, -0.0677, -0.0671, -0.0380, -0.0649, -0.0546,  0.0414, -0.0677,\n",
       "                       0.0814, -0.0928, -0.0626,  0.0750, -0.0845, -0.0915, -0.0652, -0.0717,\n",
       "                      -0.0902, -0.0596, -0.0682,  0.0480,  0.0061, -0.0133,  0.0597, -0.0281,\n",
       "                      -0.0615,  0.0139,  0.0539, -0.0621, -0.0528,  0.0133, -0.0673, -0.0826,\n",
       "                      -0.1005,  0.0654, -0.0929, -0.0309, -0.0602, -0.0898, -0.0902, -0.0157,\n",
       "                       0.0038, -0.0427, -0.0425, -0.1005, -0.0960, -0.0692, -0.0839, -0.0629,\n",
       "                      -0.0695,  0.0142, -0.0865, -0.0467, -0.0165, -0.0400,  0.0657, -0.0562,\n",
       "                      -0.0243, -0.0816, -0.0723, -0.0780,  0.0730, -0.0966, -0.0600, -0.0586,\n",
       "                      -0.0027, -0.0046, -0.0642, -0.0646, -0.0919, -0.0092, -0.0435, -0.0678,\n",
       "                       0.0263, -0.0778, -0.0868, -0.0906, -0.0373, -0.0877, -0.0566, -0.0589,\n",
       "                      -0.0967, -0.0686, -0.0228, -0.0450, -0.0592,  0.0199, -0.0242, -0.0806,\n",
       "                       0.0498, -0.0779,  0.0470, -0.0800,  0.0453, -0.0125, -0.1084,  0.0072,\n",
       "                      -0.0033, -0.0671, -0.0522,  0.0414, -0.0341, -0.0840, -0.0429,  0.0224,\n",
       "                       0.0271, -0.0839, -0.0937, -0.0987,  0.0166, -0.0908,  0.0413, -0.0873,\n",
       "                      -0.0847, -0.0691, -0.0236, -0.0410, -0.0327, -0.0196,  0.0271, -0.0976,\n",
       "                      -0.0371, -0.0815, -0.0553, -0.0683, -0.0612, -0.0637, -0.0898, -0.0638,\n",
       "                      -0.0851, -0.0906,  0.0290, -0.0881, -0.0148, -0.0193,  0.0403, -0.0191,\n",
       "                       0.0559,  0.0464, -0.0808, -0.0288, -0.0474, -0.0382, -0.0733, -0.0767,\n",
       "                      -0.0661, -0.0979,  0.0392, -0.0695,  0.0413,  0.0039, -0.0561, -0.0591,\n",
       "                       0.0784, -0.0665, -0.0434, -0.0213,  0.0411, -0.0201, -0.0812, -0.0188,\n",
       "                      -0.0354, -0.0676, -0.0602,  0.0094, -0.0897,  0.0303, -0.0595, -0.0904,\n",
       "                      -0.0753, -0.0646, -0.0166, -0.0805, -0.0843, -0.0052,  0.0376, -0.0786,\n",
       "                      -0.0614, -0.0876,  0.0134,  0.0062, -0.0804,  0.0025, -0.0337, -0.0643],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.fc2.weight',\n",
       "              tensor([[-0.0833, -0.0751,  0.0049,  ...,  0.0231,  0.0118,  0.0001],\n",
       "                      [-0.0158, -0.0403, -0.0401,  ..., -0.0055,  0.0469, -0.0430],\n",
       "                      [-0.1107, -0.0588, -0.0377,  ..., -0.0592, -0.0612,  0.0160],\n",
       "                      ...,\n",
       "                      [ 0.0916, -0.0448, -0.0332,  ...,  0.0817,  0.0056, -0.0757],\n",
       "                      [ 0.0357, -0.0843, -0.0948,  ..., -0.0779, -0.0841,  0.0701],\n",
       "                      [-0.1112,  0.0158,  0.0030,  ..., -0.1368, -0.1322, -0.0822]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.fc2.bias',\n",
       "              tensor([ 0.0082, -0.0257, -0.0918, -0.0989, -0.0644, -0.0309, -0.0833,  0.0465,\n",
       "                       0.0006, -0.0309,  0.0431,  0.0948, -0.0998, -0.0015, -0.1156,  0.0846,\n",
       "                      -0.0530,  0.0968,  0.1192,  0.0477, -0.1099,  0.0371, -0.0421, -0.0715,\n",
       "                      -0.0083, -0.1028, -0.0588, -0.0458, -0.0696, -0.0144, -0.0251, -0.0447,\n",
       "                      -0.1156,  0.0518, -0.0923, -0.0166, -0.0676,  0.0282, -0.0526, -0.0424,\n",
       "                      -0.0906,  0.0812,  0.0165, -0.0878, -0.0222, -0.0979, -0.0065,  0.0825,\n",
       "                      -0.0574,  0.0077, -0.0896, -0.1033,  0.0469, -0.0718, -0.0182, -0.0594,\n",
       "                       0.0269,  0.0054, -0.0074, -0.0499, -0.0659, -0.0387, -0.0176,  0.0098,\n",
       "                      -0.1228,  0.1286, -0.0515, -0.0361, -0.0442, -0.0651, -0.0014, -0.0440,\n",
       "                       0.0242, -0.0779, -0.0766, -0.0913,  0.0033,  0.0549, -0.0993,  0.0012,\n",
       "                      -0.0953, -0.1040, -0.0259, -0.0371, -0.0618, -0.0431, -0.0758,  0.0948,\n",
       "                      -0.0164, -0.0180,  0.0383,  0.0730,  0.0181, -0.0835, -0.0523,  0.0770,\n",
       "                      -0.1035, -0.0719,  0.0075, -0.0454,  0.0710,  0.0267, -0.1107, -0.0439,\n",
       "                       0.0168, -0.0767, -0.0423, -0.1016, -0.0479, -0.0609, -0.0989, -0.0952,\n",
       "                      -0.0209, -0.1257,  0.0103, -0.0860,  0.0942, -0.0788,  0.0534, -0.1141,\n",
       "                       0.0545, -0.0830, -0.0101, -0.0625, -0.0222,  0.0839, -0.0520, -0.0998,\n",
       "                       0.0406, -0.0554,  0.0460,  0.0242,  0.0105, -0.0950,  0.0171,  0.0498,\n",
       "                       0.0243, -0.0490, -0.0127,  0.0926,  0.0002, -0.1056, -0.1142, -0.1324,\n",
       "                      -0.0336,  0.0895, -0.1193,  0.0646,  0.0435, -0.0450, -0.0918, -0.0034,\n",
       "                       0.0598, -0.0290, -0.0080, -0.1273, -0.0721, -0.0496,  0.1017, -0.0615,\n",
       "                      -0.0929, -0.0791, -0.1035, -0.0866,  0.0408,  0.0463,  0.0330, -0.0338,\n",
       "                       0.0038,  0.1118, -0.0425, -0.0085, -0.1160, -0.1272,  0.1083, -0.1057,\n",
       "                      -0.0190, -0.0532,  0.0936, -0.1047, -0.0678, -0.0175,  0.0231, -0.1110,\n",
       "                      -0.0454, -0.1276, -0.0544,  0.0010, -0.0835,  0.0564, -0.0448, -0.0680,\n",
       "                      -0.0659, -0.0384, -0.0407,  0.0676,  0.0977, -0.0561,  0.0730, -0.1137,\n",
       "                      -0.0183, -0.0091,  0.0625,  0.0242,  0.1023, -0.0832, -0.1198,  0.0227,\n",
       "                      -0.1101,  0.0391, -0.0469, -0.0692, -0.0425, -0.0321, -0.0474, -0.0635,\n",
       "                      -0.0720, -0.0425, -0.1254, -0.1251,  0.0252,  0.0086, -0.0425,  0.0998,\n",
       "                      -0.1248, -0.0966, -0.0370, -0.0352, -0.0234,  0.0070,  0.1133,  0.0793,\n",
       "                       0.0060, -0.0885,  0.1182, -0.0929, -0.0865, -0.0257, -0.0051, -0.0353,\n",
       "                       0.1008, -0.0302, -0.0211, -0.0364,  0.0422,  0.0064, -0.0803,  0.0749,\n",
       "                       0.0732,  0.0165, -0.0803, -0.0427, -0.0084, -0.0380,  0.0244, -0.1129],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.fc3.weight',\n",
       "              tensor([[ 2.5465e-02, -4.2086e-02,  3.7688e-02,  ..., -3.8575e-02,\n",
       "                       -5.1735e-02, -1.2024e-01],\n",
       "                      [ 5.3402e-02, -1.0149e-01, -1.7311e-02,  ..., -8.9461e-02,\n",
       "                       -3.5742e-02, -2.7239e-02],\n",
       "                      [-3.0030e-05,  1.3240e-05, -5.6466e-06,  ...,  1.9189e-03,\n",
       "                       -3.0283e-03,  1.0675e-09],\n",
       "                      ...,\n",
       "                      [-6.7600e-03, -3.9082e-02, -5.5106e-02,  ...,  8.7849e-02,\n",
       "                       -1.3374e-01, -1.1362e-01],\n",
       "                      [-6.8570e-02, -1.0377e-01, -8.0102e-02,  ..., -6.2668e-02,\n",
       "                       -5.2141e-02, -1.7395e-02],\n",
       "                      [-9.5655e-02, -9.0036e-02,  8.3673e-02,  ..., -9.9011e-02,\n",
       "                       -1.2364e-01,  6.8014e-02]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('WSIEncoder.fc3.bias',\n",
       "              tensor([-0.0699, -0.0412, -0.1148, -0.0456,  0.0828,  0.0625,  0.0595, -0.1152,\n",
       "                       0.0349, -0.0168, -0.0018, -0.0031, -0.0750,  0.0781,  0.0007, -0.0772,\n",
       "                       0.1418,  0.0712,  0.0687, -0.0775, -0.0047,  0.0039,  0.0541, -0.1106,\n",
       "                      -0.0611,  0.0181,  0.0945, -0.0775, -0.0776, -0.0608, -0.0904, -0.1034],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('HiTIMED_project.weight',\n",
       "              tensor([[-4.6107e-02,  1.1203e-01, -5.7173e-02,  ...,  1.1134e-01,\n",
       "                        1.4869e-01,  1.2014e-01],\n",
       "                      [ 5.0148e-05,  1.3907e-01, -7.5227e-02,  ..., -1.6408e-01,\n",
       "                        1.2334e-01, -2.7773e-02],\n",
       "                      [ 2.7173e-02,  5.4596e-02,  1.1518e-01,  ...,  7.2520e-02,\n",
       "                        1.6315e-02, -1.5728e-01],\n",
       "                      ...,\n",
       "                      [-1.3208e-01,  5.2166e-02,  2.6013e-02,  ...,  1.3464e-02,\n",
       "                        1.0145e-01, -8.3947e-02],\n",
       "                      [ 1.1443e-01, -3.3267e-02, -5.9038e-02,  ...,  1.3217e-01,\n",
       "                       -5.8300e-02,  1.4475e-01],\n",
       "                      [-1.4879e-02,  1.5781e-02,  8.5828e-02,  ...,  1.5197e-01,\n",
       "                        1.5289e-01,  1.1406e-01]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('HiTIMED_project.bias',\n",
       "              tensor([-0.0655, -0.0972, -0.0578, -0.1016,  0.0771,  0.1295, -0.1064, -0.0616,\n",
       "                       0.0734, -0.1098, -0.1001, -0.0815, -0.0682, -0.1627,  0.0210,  0.0725,\n",
       "                      -0.0809, -0.1380,  0.0474,  0.1329, -0.0230, -0.0778, -0.0189,  0.0864,\n",
       "                       0.0073,  0.0412,  0.0368,  0.1328, -0.0941,  0.0406,  0.0863,  0.0800,\n",
       "                      -0.0868,  0.0819,  0.0113,  0.1223,  0.0679,  0.1726,  0.0669, -0.0734,\n",
       "                       0.1699,  0.1209,  0.1167, -0.0791,  0.0452, -0.0988, -0.0310, -0.0544,\n",
       "                       0.1226, -0.0421], device='cuda:0', dtype=torch.float64)),\n",
       "             ('dnam_project.weight',\n",
       "              tensor([[ 0.0857,  0.0461,  0.0564,  ..., -0.0613,  0.0732,  0.1514],\n",
       "                      [-0.0523, -0.1003, -0.1396,  ..., -0.0303,  0.0392,  0.1387],\n",
       "                      [-0.0569, -0.0745,  0.1678,  ...,  0.1603,  0.1275, -0.0153],\n",
       "                      ...,\n",
       "                      [-0.0223, -0.0531, -0.0366,  ..., -0.1147,  0.1082, -0.1016],\n",
       "                      [-0.0457,  0.1205,  0.0308,  ...,  0.1415, -0.0543, -0.0503],\n",
       "                      [ 0.1607,  0.0521, -0.0807,  ...,  0.1406,  0.0169, -0.1250]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('dnam_project.bias',\n",
       "              tensor([-0.0356,  0.0888, -0.0357, -0.1481, -0.1115,  0.0472,  0.0610, -0.1241,\n",
       "                       0.0944, -0.1625, -0.1254, -0.1332, -0.0018, -0.0255, -0.0876, -0.0138,\n",
       "                       0.0946, -0.0975, -0.1742,  0.1009, -0.1331,  0.0607, -0.0139,  0.1712,\n",
       "                       0.0456,  0.0878,  0.0144, -0.1188, -0.1458,  0.1528, -0.1034, -0.0015,\n",
       "                      -0.1282, -0.1070,  0.0233, -0.0392, -0.0412,  0.1004, -0.1106,  0.0171,\n",
       "                       0.0161,  0.1420,  0.0622, -0.0539, -0.0501, -0.1367,  0.0559,  0.1397,\n",
       "                       0.1388,  0.0475], device='cuda:0', dtype=torch.float64)),\n",
       "             ('wsi_project.weight',\n",
       "              tensor([[ 1.5510e-01,  7.4077e-03,  9.0442e-02,  ...,  9.9722e-02,\n",
       "                       -1.0151e-01,  5.2062e-02],\n",
       "                      [ 3.7781e-02,  2.3178e-04, -3.3038e-02,  ..., -1.5641e-01,\n",
       "                        3.5087e-02, -8.9027e-02],\n",
       "                      [-1.1670e-01,  4.7529e-02, -7.0340e-02,  ..., -9.8509e-03,\n",
       "                       -1.1308e-02,  4.2151e-02],\n",
       "                      ...,\n",
       "                      [-1.5706e-01, -1.1071e-01, -6.9000e-02,  ...,  1.0544e-01,\n",
       "                       -1.5625e-01, -3.0483e-02],\n",
       "                      [ 7.7669e-02, -2.3645e-06, -3.8212e-03,  ...,  8.9390e-03,\n",
       "                       -1.2071e-01,  1.9630e-02],\n",
       "                      [ 8.3901e-02,  5.7342e-02,  1.8027e-02,  ..., -5.3977e-04,\n",
       "                        5.2477e-06, -1.2588e-01]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('wsi_project.bias',\n",
       "              tensor([-0.1687, -0.0581,  0.1047,  0.1636,  0.1356, -0.0107,  0.0665, -0.1530,\n",
       "                      -0.1212,  0.0555, -0.0702,  0.1376,  0.1337, -0.0500, -0.1012, -0.1048,\n",
       "                       0.0031,  0.0492,  0.0090, -0.1099,  0.0913,  0.1455, -0.1083, -0.1183,\n",
       "                       0.0096,  0.0046, -0.0625, -0.1466,  0.1125, -0.0363, -0.1112, -0.1201,\n",
       "                      -0.0130,  0.1301, -0.1442,  0.1164, -0.1680,  0.0770, -0.0726, -0.0510,\n",
       "                      -0.0016, -0.0401, -0.1670,  0.0194, -0.0329,  0.1635,  0.0259,  0.0343,\n",
       "                      -0.1046, -0.1005], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_z1.weight',\n",
       "              tensor([[[-0.1072,  0.0499,  0.0035,  ..., -0.0726, -0.0411,  0.0863],\n",
       "                       [-0.0750,  0.0937, -0.0382,  ..., -0.1289, -0.1091,  0.0974],\n",
       "                       [ 0.1006, -0.0288,  0.0314,  ..., -0.0254,  0.0287, -0.0221],\n",
       "                       ...,\n",
       "                       [ 0.0147, -0.0005,  0.0614,  ..., -0.0605, -0.0718, -0.0527],\n",
       "                       [ 0.1285,  0.0550, -0.0597,  ...,  0.0810, -0.0484, -0.0475],\n",
       "                       [ 0.0676, -0.1022,  0.1165,  ..., -0.0475, -0.0603, -0.0844]],\n",
       "              \n",
       "                      [[ 0.0820, -0.0021, -0.0705,  ...,  0.0247,  0.0129, -0.0140],\n",
       "                       [ 0.1083, -0.0509,  0.0103,  ..., -0.0454,  0.0844, -0.0887],\n",
       "                       [ 0.0809, -0.1176,  0.1233,  ..., -0.0926,  0.0407, -0.0571],\n",
       "                       ...,\n",
       "                       [ 0.0186, -0.0267,  0.0309,  ...,  0.0033, -0.1046, -0.1234],\n",
       "                       [ 0.0079,  0.0651,  0.0902,  ..., -0.0042,  0.0352, -0.0469],\n",
       "                       [ 0.0939,  0.0524,  0.0764,  ..., -0.1168, -0.0058, -0.0746]],\n",
       "              \n",
       "                      [[-0.0639, -0.0511,  0.0390,  ..., -0.0870, -0.0839,  0.1139],\n",
       "                       [-0.0605, -0.0019,  0.0052,  ...,  0.0241,  0.1131,  0.0129],\n",
       "                       [ 0.0144, -0.1143,  0.0562,  ...,  0.1209,  0.1107,  0.0953],\n",
       "                       ...,\n",
       "                       [ 0.0534, -0.1271,  0.0969,  ...,  0.0914,  0.1188,  0.0387],\n",
       "                       [-0.0989, -0.1238, -0.0216,  ..., -0.0949, -0.0350,  0.0227],\n",
       "                       [ 0.0397,  0.0934, -0.1151,  ..., -0.1378, -0.0931,  0.1028]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0580,  0.0256,  0.1050,  ..., -0.0426,  0.1026,  0.0942],\n",
       "                       [-0.0960, -0.1228,  0.0201,  ..., -0.0200, -0.0798,  0.0972],\n",
       "                       [-0.0709, -0.0455, -0.0612,  ..., -0.1273,  0.0140, -0.0214],\n",
       "                       ...,\n",
       "                       [-0.0625, -0.0800,  0.0748,  ...,  0.0479,  0.1259,  0.0639],\n",
       "                       [ 0.1174,  0.0561,  0.0608,  ...,  0.0268, -0.0725, -0.0813],\n",
       "                       [-0.0751,  0.0679, -0.0703,  ...,  0.1273,  0.0887,  0.0443]],\n",
       "              \n",
       "                      [[-0.0002,  0.0199,  0.0699,  ...,  0.0393, -0.0664, -0.0637],\n",
       "                       [-0.0865, -0.0074,  0.1193,  ..., -0.0138, -0.0111,  0.1043],\n",
       "                       [ 0.0703, -0.1329, -0.0347,  ...,  0.0484, -0.1130, -0.0173],\n",
       "                       ...,\n",
       "                       [-0.0750,  0.0873, -0.0867,  ..., -0.0390, -0.1309,  0.1404],\n",
       "                       [ 0.0974,  0.0550,  0.1316,  ..., -0.0817, -0.0115, -0.0198],\n",
       "                       [-0.0639,  0.0758,  0.0706,  ..., -0.0422,  0.1264,  0.1049]],\n",
       "              \n",
       "                      [[ 0.1104, -0.0682,  0.0345,  ..., -0.0265, -0.0321,  0.0434],\n",
       "                       [ 0.1154, -0.0750, -0.0887,  ...,  0.0526,  0.0882,  0.0962],\n",
       "                       [ 0.1094,  0.0824,  0.0457,  ..., -0.0979, -0.1229, -0.0056],\n",
       "                       ...,\n",
       "                       [-0.0470, -0.0212,  0.0876,  ...,  0.1252, -0.0022, -0.0233],\n",
       "                       [ 0.0489,  0.1129,  0.1058,  ...,  0.0719, -0.0519,  0.0579],\n",
       "                       [-0.1258, -0.1215, -0.1129,  ...,  0.0127,  0.0597,  0.1326]]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_z1.bias',\n",
       "              tensor([ 0.1226,  0.0732, -0.0583,  0.0447, -0.0813,  0.0761, -0.0339, -0.1169,\n",
       "                       0.0866,  0.0772, -0.0975,  0.0130, -0.0452,  0.0696,  0.0403, -0.0961,\n",
       "                      -0.0668, -0.0293, -0.0537, -0.0190, -0.0324, -0.0695, -0.0824, -0.0718,\n",
       "                      -0.0171,  0.1219,  0.0853,  0.0583,  0.0782, -0.1074,  0.0128,  0.0771,\n",
       "                       0.0289,  0.0073,  0.0866,  0.0131, -0.0253, -0.1080,  0.1008,  0.0328,\n",
       "                       0.0215,  0.1301,  0.0044,  0.0503, -0.0765, -0.0481,  0.1088,  0.1052,\n",
       "                       0.0404,  0.0852], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_o1.0.weight',\n",
       "              tensor([[ 4.2512e-02,  4.9128e-02, -6.6294e-02,  ...,  1.0333e-01,\n",
       "                        3.0537e-03, -3.9818e-03],\n",
       "                      [ 5.8359e-02,  1.0676e-01,  8.9335e-02,  ..., -1.2345e-01,\n",
       "                        7.0668e-02, -8.5244e-02],\n",
       "                      [ 9.3198e-02, -6.9317e-02, -7.8279e-02,  ...,  1.0815e-04,\n",
       "                        8.9478e-04, -6.2237e-02],\n",
       "                      ...,\n",
       "                      [ 1.1851e-01,  5.8537e-02,  1.3901e-01,  ..., -6.2095e-02,\n",
       "                       -2.4814e-03,  1.1663e-01],\n",
       "                      [ 9.2291e-02,  6.9621e-02, -5.8062e-02,  ..., -2.8747e-03,\n",
       "                        6.5586e-03,  1.3275e-01],\n",
       "                      [ 1.3268e-01, -4.4248e-03,  4.0635e-02,  ...,  3.6179e-02,\n",
       "                        1.0256e-01,  2.2521e-02]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_o1.0.bias',\n",
       "              tensor([ 0.0267,  0.0377, -0.0471,  0.0019, -0.0687, -0.0853, -0.0614,  0.0901,\n",
       "                       0.1124,  0.1347,  0.1414, -0.0225,  0.0810, -0.1093,  0.0341, -0.1013,\n",
       "                       0.0616, -0.0228, -0.0875,  0.0726,  0.0552,  0.1330, -0.0877, -0.0727,\n",
       "                       0.0547,  0.1219,  0.0331, -0.0646,  0.1113, -0.0633,  0.0662, -0.0543,\n",
       "                       0.0131,  0.0205, -0.1177, -0.1073, -0.0173, -0.0679, -0.1037, -0.0066,\n",
       "                       0.0224,  0.0217, -0.0989,  0.1047,  0.0249,  0.0890,  0.1276,  0.1162,\n",
       "                       0.1234, -0.0675], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_z2.weight',\n",
       "              tensor([[[-0.0220, -0.0145, -0.1055,  ..., -0.0604, -0.1281,  0.0375],\n",
       "                       [ 0.0187, -0.1066, -0.0893,  ...,  0.0411, -0.1286,  0.0132],\n",
       "                       [ 0.0169, -0.0399, -0.0792,  ...,  0.0953, -0.0005, -0.0806],\n",
       "                       ...,\n",
       "                       [-0.0723, -0.1260, -0.0147,  ...,  0.0640,  0.0552,  0.0795],\n",
       "                       [-0.0443, -0.1281, -0.0944,  ...,  0.0039, -0.1352,  0.0030],\n",
       "                       [ 0.1107, -0.0951, -0.0877,  ..., -0.0013,  0.0132,  0.0540]],\n",
       "              \n",
       "                      [[ 0.0498,  0.0518,  0.0195,  ..., -0.0981, -0.0834, -0.0035],\n",
       "                       [ 0.0523, -0.0937,  0.0667,  ...,  0.0551,  0.1184, -0.1135],\n",
       "                       [-0.0654, -0.0925,  0.1256,  ..., -0.1287, -0.1099, -0.0615],\n",
       "                       ...,\n",
       "                       [ 0.0844, -0.0616, -0.0942,  ..., -0.1123,  0.0983,  0.1265],\n",
       "                       [ 0.0693, -0.0141, -0.0454,  ...,  0.0487, -0.0977, -0.0996],\n",
       "                       [ 0.0877,  0.0850, -0.0076,  ...,  0.0421,  0.1194, -0.0939]],\n",
       "              \n",
       "                      [[ 0.0897, -0.1173,  0.0017,  ...,  0.0234, -0.0871, -0.0232],\n",
       "                       [-0.0425, -0.0247, -0.0951,  ...,  0.0799,  0.0836,  0.0956],\n",
       "                       [-0.0603,  0.0476, -0.0590,  ..., -0.0734,  0.0176,  0.1020],\n",
       "                       ...,\n",
       "                       [ 0.0443,  0.0560,  0.0349,  ..., -0.0505,  0.0117, -0.1288],\n",
       "                       [ 0.1197,  0.0334, -0.0623,  ..., -0.0303, -0.1313,  0.0359],\n",
       "                       [ 0.0445, -0.1226,  0.0904,  ...,  0.0185,  0.1301, -0.1185]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0597, -0.0262,  0.0261,  ..., -0.0995, -0.0091, -0.0585],\n",
       "                       [-0.0864, -0.0139, -0.1267,  ..., -0.1002, -0.1255,  0.1112],\n",
       "                       [ 0.0518,  0.1165, -0.1040,  ...,  0.1023,  0.1268, -0.1069],\n",
       "                       ...,\n",
       "                       [-0.0242,  0.1093, -0.0060,  ...,  0.0053, -0.0009,  0.0598],\n",
       "                       [-0.0781, -0.0038,  0.0119,  ..., -0.0431, -0.0333, -0.0060],\n",
       "                       [ 0.1030,  0.0351,  0.0916,  ..., -0.0856,  0.0250, -0.1134]],\n",
       "              \n",
       "                      [[-0.0734,  0.0129, -0.0403,  ..., -0.0905, -0.0763,  0.0442],\n",
       "                       [ 0.0871, -0.0828, -0.0832,  ..., -0.0376,  0.0151, -0.0650],\n",
       "                       [-0.0172,  0.0377, -0.0639,  ...,  0.1111,  0.0427,  0.0405],\n",
       "                       ...,\n",
       "                       [ 0.0179, -0.1234, -0.0426,  ..., -0.0332, -0.0419,  0.0408],\n",
       "                       [ 0.0108,  0.1000, -0.1156,  ...,  0.0600,  0.0264,  0.0810],\n",
       "                       [ 0.0015, -0.0901, -0.0507,  ...,  0.1165,  0.0560,  0.1015]],\n",
       "              \n",
       "                      [[ 0.1260,  0.0446,  0.1127,  ..., -0.0823,  0.0620,  0.0238],\n",
       "                       [ 0.1026, -0.0378, -0.1168,  ...,  0.0458,  0.1154, -0.1196],\n",
       "                       [-0.1218, -0.0966,  0.1236,  ...,  0.0036, -0.0490, -0.1172],\n",
       "                       ...,\n",
       "                       [ 0.0865, -0.0843, -0.0979,  ..., -0.0347, -0.0193, -0.0006],\n",
       "                       [ 0.0114, -0.0293, -0.1183,  ...,  0.0161,  0.0454, -0.0604],\n",
       "                       [-0.0956,  0.0264,  0.1105,  ..., -0.1015,  0.0235,  0.0683]]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_z2.bias',\n",
       "              tensor([ 0.0718,  0.1032,  0.1145,  0.0608,  0.0176,  0.1209,  0.0411,  0.0180,\n",
       "                      -0.0256,  0.1010, -0.0566,  0.0587,  0.0447, -0.0292, -0.0455, -0.0940,\n",
       "                      -0.0830,  0.0507,  0.0912, -0.0929, -0.0333,  0.1236, -0.1018, -0.0117,\n",
       "                      -0.0232, -0.0586,  0.0098, -0.0176,  0.0038, -0.1283,  0.0541, -0.1289,\n",
       "                      -0.1079,  0.0341,  0.0679, -0.0909,  0.0574, -0.0488, -0.0190,  0.0502,\n",
       "                       0.1228, -0.0820, -0.0537, -0.0869,  0.0103,  0.1013, -0.0901,  0.0257,\n",
       "                      -0.1270,  0.0533], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_o2.0.weight',\n",
       "              tensor([[-0.0577,  0.0018,  0.0959,  ...,  0.1046,  0.0010, -0.0480],\n",
       "                      [ 0.1352, -0.0718, -0.0841,  ..., -0.0553, -0.1092, -0.0476],\n",
       "                      [ 0.0292,  0.0040,  0.0210,  ...,  0.0948,  0.1059,  0.0553],\n",
       "                      ...,\n",
       "                      [-0.1210, -0.0540,  0.0383,  ..., -0.0202, -0.0623,  0.0753],\n",
       "                      [-0.1318, -0.1220,  0.0310,  ..., -0.1338, -0.0938,  0.0600],\n",
       "                      [ 0.1260,  0.1185, -0.0281,  ...,  0.0161, -0.0826, -0.0318]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_o2.0.bias',\n",
       "              tensor([ 0.0143, -0.0596,  0.0381, -0.0952, -0.0724,  0.0614,  0.0517,  0.1079,\n",
       "                       0.1145,  0.0035, -0.0465, -0.0406, -0.1239, -0.0441,  0.0277,  0.0732,\n",
       "                      -0.0199, -0.1042, -0.0211,  0.0592, -0.0583, -0.1162, -0.0318,  0.0087,\n",
       "                      -0.1193,  0.1016,  0.0599, -0.0125,  0.0566,  0.0547, -0.0573,  0.0819,\n",
       "                       0.0108,  0.0005, -0.0170,  0.1244,  0.0527,  0.0583,  0.0073, -0.0032,\n",
       "                      -0.0944, -0.0401,  0.0619, -0.0388, -0.0901, -0.0483, -0.0971,  0.0474,\n",
       "                       0.0733, -0.0356], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_z3.weight',\n",
       "              tensor([[[-1.1694e-02,  4.4373e-02,  3.7893e-02,  ...,  1.1060e-03,\n",
       "                        -1.8008e-02, -1.3806e-02],\n",
       "                       [-3.1520e-02, -3.1134e-02,  2.7561e-02,  ..., -1.0424e-01,\n",
       "                         8.5280e-02,  8.9361e-02],\n",
       "                       [ 1.4561e-04,  1.2248e-01, -5.7805e-04,  ..., -3.4193e-02,\n",
       "                         4.6886e-02,  9.7144e-02],\n",
       "                       ...,\n",
       "                       [-1.1403e-01, -1.2171e-02, -1.0312e-03,  ...,  8.4206e-02,\n",
       "                         1.1011e-01,  3.7321e-03],\n",
       "                       [ 2.1872e-02, -1.1339e-01, -1.9474e-03,  ...,  3.6513e-02,\n",
       "                        -3.1405e-02,  4.7859e-02],\n",
       "                       [-1.2493e-01,  1.0249e-01,  1.0829e-01,  ..., -9.1216e-03,\n",
       "                         5.5184e-02, -7.2534e-02]],\n",
       "              \n",
       "                      [[-1.0777e-01,  9.4637e-03,  8.1394e-02,  ..., -6.4653e-02,\n",
       "                         6.6786e-03,  6.2852e-02],\n",
       "                       [ 1.1501e-01, -1.0560e-01, -2.6738e-02,  ..., -9.7271e-03,\n",
       "                        -9.2872e-02, -8.4128e-02],\n",
       "                       [-3.4258e-03,  9.6703e-02,  1.5151e-02,  ..., -7.7670e-02,\n",
       "                        -5.2574e-02, -8.5719e-02],\n",
       "                       ...,\n",
       "                       [ 9.7170e-02,  3.4641e-02, -6.1048e-02,  ..., -7.6082e-02,\n",
       "                        -1.0782e-04,  5.0975e-02],\n",
       "                       [ 1.1002e-01, -9.3245e-02, -1.2065e-01,  ...,  2.3109e-04,\n",
       "                        -3.8573e-04, -8.3453e-02],\n",
       "                       [ 2.8881e-02, -1.2794e-01,  3.1850e-02,  ...,  9.0105e-02,\n",
       "                         1.8930e-02, -2.0832e-02]],\n",
       "              \n",
       "                      [[-8.2968e-02,  8.8178e-03,  1.1676e-01,  ...,  1.0543e-01,\n",
       "                        -1.0034e-02,  1.1990e-02],\n",
       "                       [ 9.9821e-03, -9.8349e-02, -8.9622e-02,  ...,  2.6911e-02,\n",
       "                        -5.9390e-02,  7.3840e-02],\n",
       "                       [ 7.8962e-02, -8.6821e-03,  7.4200e-02,  ...,  1.2775e-01,\n",
       "                        -1.2560e-02, -2.3944e-02],\n",
       "                       ...,\n",
       "                       [ 9.1605e-02, -3.9121e-02,  3.3419e-02,  ...,  1.5125e-03,\n",
       "                        -8.4736e-02,  9.5267e-02],\n",
       "                       [ 7.9413e-02, -2.8470e-02,  1.0693e-01,  ...,  8.7130e-02,\n",
       "                         1.4268e-02, -5.2686e-02],\n",
       "                       [ 9.9795e-02,  9.9537e-02,  7.0970e-02,  ...,  5.2738e-02,\n",
       "                         6.2678e-02, -6.8835e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.0075e-01, -4.9205e-03,  1.0945e-01,  ..., -9.1626e-02,\n",
       "                         1.1866e-01,  1.0500e-02],\n",
       "                       [-4.6224e-02, -1.2427e-01, -5.0992e-02,  ..., -2.4124e-02,\n",
       "                         5.8095e-02,  1.0966e-01],\n",
       "                       [ 3.0136e-02,  8.6231e-03,  2.5005e-03,  ...,  3.6362e-02,\n",
       "                        -1.1127e-01, -9.6168e-02],\n",
       "                       ...,\n",
       "                       [-1.2837e-01, -8.2602e-02,  6.0599e-02,  ..., -3.8063e-02,\n",
       "                         8.6312e-02, -2.9628e-02],\n",
       "                       [ 9.8326e-02, -6.3388e-02,  5.3976e-02,  ...,  1.0007e-01,\n",
       "                         1.1525e-01, -1.2244e-02],\n",
       "                       [ 1.0273e-01,  7.9962e-02,  9.6174e-02,  ...,  1.2664e-02,\n",
       "                         3.6218e-02, -7.3266e-02]],\n",
       "              \n",
       "                      [[ 9.4363e-02,  7.1253e-04,  1.2484e-01,  ..., -8.8583e-03,\n",
       "                        -5.1170e-02, -7.9547e-04],\n",
       "                       [ 8.8430e-02, -7.5245e-02, -3.7269e-02,  ..., -3.7204e-02,\n",
       "                        -3.0766e-02, -4.0949e-02],\n",
       "                       [ 3.6912e-02, -8.0281e-02,  1.1872e-01,  ...,  1.1744e-03,\n",
       "                         8.8312e-02, -4.0240e-02],\n",
       "                       ...,\n",
       "                       [ 6.2481e-02, -1.0725e-01,  8.8351e-02,  ...,  1.0517e-01,\n",
       "                        -5.5987e-02, -1.3687e-02],\n",
       "                       [ 5.9160e-02, -1.2322e-01,  1.0309e-01,  ...,  1.0546e-01,\n",
       "                         1.3748e-02,  7.0432e-02],\n",
       "                       [-1.5217e-02,  1.5028e-02,  6.3062e-02,  ..., -4.3842e-02,\n",
       "                         1.4833e-02, -1.0574e-04]],\n",
       "              \n",
       "                      [[ 1.5609e-02, -2.7906e-02,  3.6401e-02,  ...,  1.1834e-01,\n",
       "                         7.3305e-02,  8.8286e-02],\n",
       "                       [-9.3973e-03, -5.5646e-02,  6.3647e-02,  ..., -4.0333e-02,\n",
       "                        -1.1209e-01, -8.4908e-02],\n",
       "                       [-1.2952e-01, -1.1220e-01, -1.2516e-02,  ..., -1.0922e-01,\n",
       "                         8.4746e-02, -2.2023e-02],\n",
       "                       ...,\n",
       "                       [-6.8488e-02,  3.9915e-02,  1.0716e-01,  ...,  7.3185e-02,\n",
       "                         1.1927e-02, -1.1346e-02],\n",
       "                       [ 4.8987e-03,  9.3128e-02,  1.1799e-01,  ...,  2.8905e-02,\n",
       "                        -8.4582e-02,  8.3151e-02],\n",
       "                       [ 1.4142e-02, -3.4432e-02,  4.8739e-02,  ...,  8.1084e-02,\n",
       "                        -2.5064e-03, -1.1165e-01]]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_z3.bias',\n",
       "              tensor([-0.0753, -0.1239, -0.0518,  0.0456, -0.1084,  0.0715, -0.0878, -0.0383,\n",
       "                       0.0586,  0.0557, -0.0705, -0.0757,  0.1165, -0.0991,  0.0269, -0.0290,\n",
       "                       0.1196,  0.0608,  0.0820, -0.1111, -0.0230,  0.0408,  0.0575,  0.0570,\n",
       "                       0.0996, -0.0305, -0.1101, -0.0619, -0.0333, -0.0935,  0.0680,  0.0499,\n",
       "                      -0.0833,  0.1274, -0.0163,  0.0325, -0.1307,  0.0212, -0.0388,  0.0692,\n",
       "                      -0.0715, -0.0484,  0.0249, -0.1226,  0.0726,  0.0692, -0.0010,  0.1104,\n",
       "                      -0.0611, -0.0771], device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_o3.0.weight',\n",
       "              tensor([[ 0.0937, -0.0811, -0.1266,  ..., -0.0184,  0.0015,  0.0095],\n",
       "                      [-0.1184,  0.1191,  0.0073,  ..., -0.0927,  0.0535,  0.0995],\n",
       "                      [-0.1134,  0.0028, -0.0732,  ...,  0.0591,  0.0255, -0.0716],\n",
       "                      ...,\n",
       "                      [ 0.0251,  0.0823,  0.0667,  ..., -0.0193,  0.0922,  0.0801],\n",
       "                      [ 0.0210, -0.0214,  0.0834,  ...,  0.0954, -0.0552, -0.1265],\n",
       "                      [-0.0302, -0.0800, -0.1009,  ...,  0.0585, -0.0735,  0.1408]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('linear_o3.0.bias',\n",
       "              tensor([ 0.0213,  0.1274, -0.1238,  0.0025,  0.0574, -0.0508,  0.1168, -0.0872,\n",
       "                      -0.0275,  0.0573, -0.0889,  0.0852, -0.1079, -0.0328, -0.0371, -0.0230,\n",
       "                      -0.0606, -0.1243, -0.1162, -0.0076,  0.1363, -0.1178,  0.1304,  0.0436,\n",
       "                       0.1247,  0.0864,  0.1113,  0.1107, -0.1097, -0.0282,  0.0159, -0.0255,\n",
       "                       0.1089, -0.0600, -0.1262, -0.0730, -0.0924,  0.0209, -0.1282, -0.1022,\n",
       "                       0.0599,  0.0965,  0.1177,  0.0757, -0.0312, -0.0250,  0.0716, -0.0091,\n",
       "                      -0.0754,  0.0043], device='cuda:0', dtype=torch.float64)),\n",
       "             ('encoder1.0.weight',\n",
       "              tensor([[ 1.3982e-06,  2.6612e-06, -1.7684e-06,  ..., -1.5009e-04,\n",
       "                       -2.9744e-03, -2.2280e-03],\n",
       "                      [-8.7525e-04, -1.1495e-03,  1.7464e-03,  ..., -5.8817e-04,\n",
       "                       -5.4229e-04,  1.9830e-04],\n",
       "                      [-2.4747e-04, -1.8930e-04,  7.8555e-04,  ..., -1.4728e-03,\n",
       "                       -1.3509e-03,  1.7526e-03],\n",
       "                      ...,\n",
       "                      [ 5.2774e-07,  1.2069e-03,  1.3971e-03,  ...,  4.0230e-03,\n",
       "                       -8.9526e-04,  1.4008e-03],\n",
       "                      [-1.8857e-07,  5.9279e-07,  6.0883e-07,  ..., -8.9848e-04,\n",
       "                       -2.7426e-04, -1.1184e-03],\n",
       "                      [ 5.2374e-04,  2.6705e-04,  1.7553e-03,  ...,  3.1730e-03,\n",
       "                        1.8199e-03,  3.1781e-03]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('encoder1.0.bias',\n",
       "              tensor([ 1.0434e-03,  1.0538e-03,  1.0982e-03,  1.3599e-03,  1.9048e-03,\n",
       "                      -2.1003e-03,  1.7261e-03,  2.4078e-03, -7.9998e-04,  6.2537e-04,\n",
       "                      -4.4234e-04,  2.1335e-03,  2.1805e-03,  1.0567e-03,  5.9821e-04,\n",
       "                      -2.5703e-03,  1.0567e-03, -1.1019e-03,  2.1589e-03, -1.4921e-03,\n",
       "                       4.9914e-04,  2.7749e-04, -1.5609e-03, -9.2723e-04, -1.0724e-03,\n",
       "                       1.8256e-03,  2.8099e-03, -1.0061e-03,  3.8835e-03,  1.0087e-03,\n",
       "                       2.1692e-03,  1.0053e-03, -5.8222e-04,  1.0465e-03,  1.7257e-03,\n",
       "                      -9.5415e-04, -2.9419e-03, -1.0168e-03, -1.3534e-03, -8.1536e-05,\n",
       "                       2.4171e-03,  3.7919e-03, -2.5550e-03, -1.9343e-03, -1.3573e-03,\n",
       "                      -8.2268e-04, -2.5119e-03,  4.1132e-03, -6.7037e-04,  2.7623e-03],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('encoder2.0.weight',\n",
       "              tensor([[-0.0031, -0.0767,  0.0597,  ..., -0.0389, -0.0592, -0.0292],\n",
       "                      [-0.0273,  0.0607,  0.0723,  ..., -0.0529, -0.0167, -0.1275],\n",
       "                      [ 0.1300, -0.1174, -0.0732,  ..., -0.0171,  0.1181,  0.0524],\n",
       "                      ...,\n",
       "                      [-0.0946, -0.0069, -0.1192,  ...,  0.1405, -0.0036, -0.1339],\n",
       "                      [-0.1386,  0.0795, -0.0300,  ...,  0.1442,  0.0791,  0.0275],\n",
       "                      [ 0.0186,  0.0004,  0.0444,  ..., -0.0467, -0.0283,  0.1200]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('encoder2.0.bias',\n",
       "              tensor([ 0.0867,  0.0471,  0.0101, -0.0120, -0.0439, -0.0110,  0.0516, -0.0166,\n",
       "                       0.1036, -0.0791, -0.0727,  0.0924, -0.1239, -0.0849, -0.0469,  0.0809,\n",
       "                       0.0814, -0.0670,  0.1057,  0.1087,  0.1318, -0.0549, -0.0636, -0.1033,\n",
       "                       0.1320,  0.1193,  0.0753,  0.0546,  0.0708,  0.1040, -0.1207,  0.0808,\n",
       "                      -0.0790, -0.0628,  0.1036, -0.1148, -0.0930,  0.0161,  0.1038,  0.0643,\n",
       "                       0.0813, -0.0565, -0.0405,  0.1320,  0.1354, -0.0796, -0.0679, -0.0419,\n",
       "                       0.0625, -0.0757], device='cuda:0', dtype=torch.float64)),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0187, -0.0586,  0.1236,  ..., -0.1251,  0.1346, -0.0406],\n",
       "                      [ 0.0096,  0.0337, -0.0931,  ...,  0.0228, -0.1053,  0.0374],\n",
       "                      [-0.0165,  0.0217, -0.0129,  ...,  0.0623, -0.1226, -0.0847],\n",
       "                      ...,\n",
       "                      [ 0.1045,  0.1414,  0.0093,  ...,  0.0771, -0.1170, -0.1243],\n",
       "                      [-0.0831,  0.0703,  0.1289,  ..., -0.0198,  0.1325, -0.1379],\n",
       "                      [ 0.0480,  0.1408, -0.0994,  ..., -0.0439, -0.0981,  0.1025]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.1173,  0.0452,  0.0654, -0.0015, -0.0700,  0.1201,  0.0922,  0.0769,\n",
       "                       0.0893, -0.0910,  0.0183, -0.0267, -0.0433,  0.0838,  0.0132,  0.0803,\n",
       "                      -0.0028,  0.0695,  0.0242,  0.1158,  0.0507, -0.0070, -0.0319,  0.1144,\n",
       "                       0.0999,  0.1175,  0.0244, -0.0294, -0.0964, -0.1315,  0.0247, -0.0565,\n",
       "                      -0.1390,  0.0590, -0.0766,  0.0229, -0.1258, -0.0123,  0.1212, -0.0525,\n",
       "                      -0.0887, -0.0919,  0.1391,  0.1318, -0.0478, -0.0045, -0.1131,  0.0125,\n",
       "                       0.0518, -0.1018], device='cuda:0', dtype=torch.float64)),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.1360, -0.1316,  0.0556,  ..., -0.1029,  0.0386,  0.0197],\n",
       "                      [-0.0358, -0.0718, -0.0741,  ...,  0.1029,  0.0717,  0.0084],\n",
       "                      [-0.0513,  0.0740,  0.0171,  ..., -0.0575, -0.0416,  0.1032],\n",
       "                      ...,\n",
       "                      [-0.0986, -0.0800,  0.1353,  ...,  0.0160,  0.0985,  0.0255],\n",
       "                      [ 0.0890, -0.1230, -0.0452,  ...,  0.0037,  0.0897, -0.1350],\n",
       "                      [-0.0066,  0.0124,  0.0849,  ..., -0.0469,  0.0074, -0.0675]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0742, -0.1375,  0.0084,  0.0086,  0.0281, -0.0778,  0.0922, -0.0356,\n",
       "                      -0.1139,  0.0938, -0.0935, -0.0633, -0.0343,  0.0303,  0.0330, -0.0362,\n",
       "                      -0.0235, -0.0989,  0.1171,  0.0103, -0.0195,  0.1115,  0.1173,  0.0418,\n",
       "                      -0.0983, -0.0807, -0.0654,  0.0483,  0.1141,  0.0739,  0.0424, -0.0847,\n",
       "                      -0.1013,  0.0827,  0.0625,  0.0363, -0.1018, -0.0799, -0.0227,  0.0243,\n",
       "                      -0.0676, -0.0663,  0.1231,  0.1367, -0.0368,  0.1039, -0.0170, -0.1330,\n",
       "                       0.1094,  0.0312], device='cuda:0', dtype=torch.float64)),\n",
       "             ('out.weight',\n",
       "              tensor([[-0.1342, -0.0919,  0.0309,  0.0168, -0.0268, -0.0680,  0.0188,  0.1230,\n",
       "                        0.0371, -0.0219,  0.0851, -0.0762, -0.0289, -0.0982, -0.1114,  0.0826,\n",
       "                       -0.0479,  0.0908,  0.0122, -0.1038,  0.0795,  0.0590,  0.0361,  0.1197,\n",
       "                        0.1065, -0.0128, -0.0876,  0.0484,  0.1342, -0.1010,  0.0630,  0.0200,\n",
       "                        0.0385, -0.0809,  0.1281,  0.0613,  0.0052,  0.0988, -0.0235,  0.0819,\n",
       "                       -0.1431, -0.0283,  0.0937,  0.0596,  0.0176, -0.0913, -0.0162,  0.0704,\n",
       "                        0.1393,  0.0011]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('out.bias',\n",
       "              tensor([-0.0724], device='cuda:0', dtype=torch.float64))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state_dict = torch.load('/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/Multimodal/model_saving/Pheno_Interaction/model_best.pth')\n",
    "best_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ce505ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1edec",
   "metadata": {},
   "source": [
    "### Get hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a9235f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = []\n",
    "prediction_model.eval()\n",
    "prediction_model.train(False)\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(test_loader):\n",
    "        \n",
    "        HiTIMED_data = data[0].to(device)\n",
    "        dnam_data = data[1].to(device)\n",
    "        wsi_data = data[2]\n",
    "        demog = data[3].to(device)\n",
    "        \n",
    "        \n",
    "        censors = torch.Tensor(wsi_data.censor)\n",
    "        times = wsi_data.duration\n",
    "        edge_index = wsi_data.edge_index.to(device)\n",
    "        batch = wsi_data.batch.to(device)\n",
    "        wsi_data = wsi_data.x.double().to(device)\n",
    "        \n",
    "        if torch.any(times.isnan()):\n",
    "            times = torch.nan_to_num(times)\n",
    "        if torch.any(censors.isnan()): # pop up an error: 'list' object has no attribute 'isnan'\n",
    "            censors = torch.nan_to_num(censors)\n",
    "            \n",
    "        hazard_pred = prediction_model(HiTIMED_data, dnam_data, wsi_data, edge_index, batch, demog)\n",
    "        \n",
    "        hazards_pred = hazard_pred.cpu().numpy()\n",
    "        \n",
    "        for i in hazards_pred:\n",
    "            hazards.append(i.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72becdf7",
   "metadata": {},
   "source": [
    "### Merge to the original data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b860285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFPE.DNA.ID</th>\n",
       "      <th>Blood.Sample.ID</th>\n",
       "      <th>death_stat</th>\n",
       "      <th>death_censor_time</th>\n",
       "      <th>TenDead</th>\n",
       "      <th>TenYearSurv</th>\n",
       "      <th>RFS_stat</th>\n",
       "      <th>RFS_censor_time</th>\n",
       "      <th>TenRFS</th>\n",
       "      <th>TenYearRFS</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>predicted_hazard_WSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLD050</td>\n",
       "      <td>A00000FBK</td>\n",
       "      <td>1</td>\n",
       "      <td>3816.344970</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3816.344970</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>77</td>\n",
       "      <td>-0.107488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>A00000FC3</td>\n",
       "      <td>1</td>\n",
       "      <td>4869.979467</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4869.979467</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "      <td>-9.339047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLD043</td>\n",
       "      <td>A00000FC3</td>\n",
       "      <td>1</td>\n",
       "      <td>4869.979467</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4869.979467</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "      <td>-9.322425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>A00000EH7</td>\n",
       "      <td>0</td>\n",
       "      <td>3780.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3780.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>female</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.230495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLD061</td>\n",
       "      <td>A00000EH7</td>\n",
       "      <td>0</td>\n",
       "      <td>3780.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3780.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>female</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.234401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>BLD048</td>\n",
       "      <td>BDB1P03023</td>\n",
       "      <td>1</td>\n",
       "      <td>3609.363450</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3609.363450</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>58</td>\n",
       "      <td>-3.063585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>BLD075</td>\n",
       "      <td>BDB1P04022</td>\n",
       "      <td>0</td>\n",
       "      <td>4230.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4230.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>51</td>\n",
       "      <td>-8.735399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>BLD024</td>\n",
       "      <td>BDB1P02094</td>\n",
       "      <td>0</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>68</td>\n",
       "      <td>-0.456061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BLD094</td>\n",
       "      <td>BDB1P03058</td>\n",
       "      <td>0</td>\n",
       "      <td>4410.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1999.232877</td>\n",
       "      <td>1</td>\n",
       "      <td>1999.232877</td>\n",
       "      <td>male</td>\n",
       "      <td>53</td>\n",
       "      <td>-6.837567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>BLD014</td>\n",
       "      <td>BDB1P01044</td>\n",
       "      <td>0</td>\n",
       "      <td>4770.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4770.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>68</td>\n",
       "      <td>-0.491523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FFPE.DNA.ID Blood.Sample.ID  death_stat  death_censor_time  TenDead  \\\n",
       "0        BLD050       A00000FBK           1        3816.344970        0   \n",
       "1        BLD043       A00000FC3           1        4869.979467        0   \n",
       "2        BLD043       A00000FC3           1        4869.979467        0   \n",
       "3        BLD061       A00000EH7           0        3780.000000        0   \n",
       "4        BLD061       A00000EH7           0        3780.000000        0   \n",
       "..          ...             ...         ...                ...      ...   \n",
       "131      BLD048      BDB1P03023           1        3609.363450        0   \n",
       "132      BLD075      BDB1P04022           0        4230.000000        0   \n",
       "133      BLD024      BDB1P02094           0        4500.000000        0   \n",
       "134      BLD094      BDB1P03058           0        4410.000000        0   \n",
       "135      BLD014      BDB1P01044           0        4770.000000        0   \n",
       "\n",
       "     TenYearSurv  RFS_stat  RFS_censor_time  TenRFS   TenYearRFS     Sex  Age  \\\n",
       "0         3600.0         1      3816.344970       0  3600.000000    male   77   \n",
       "1         3600.0         1      4869.979467       0  3600.000000  female   77   \n",
       "2         3600.0         1      4869.979467       0  3600.000000  female   77   \n",
       "3         3600.0         0      3780.000000       0  3600.000000  female   76   \n",
       "4         3600.0         0      3780.000000       0  3600.000000  female   76   \n",
       "..           ...       ...              ...     ...          ...     ...  ...   \n",
       "131       3600.0         1      3609.363450       0  3600.000000    male   58   \n",
       "132       3600.0         0      4230.000000       0  3600.000000    male   51   \n",
       "133       3600.0         0      4500.000000       0  3600.000000    male   68   \n",
       "134       3600.0         1      1999.232877       1  1999.232877    male   53   \n",
       "135       3600.0         0      4770.000000       0  3600.000000    male   68   \n",
       "\n",
       "     predicted_hazard_WSI  \n",
       "0               -0.107488  \n",
       "1               -9.339047  \n",
       "2               -9.322425  \n",
       "3               -0.230495  \n",
       "4               -0.234401  \n",
       "..                    ...  \n",
       "131             -3.063585  \n",
       "132             -8.735399  \n",
       "133             -0.456061  \n",
       "134             -6.837567  \n",
       "135             -0.491523  \n",
       "\n",
       "[136 rows x 13 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = Data_DH_final[['FFPE.DNA.ID','Blood.Sample.ID','death_stat','death_censor_time','TenDead','TenYearSurv','RFS_stat','RFS_censor_time','TenRFS','TenYearRFS','Sex','Age']].copy()\n",
    "predicted_hazards = hazards\n",
    "predicted_df['predicted_hazard_WSI'] = predicted_hazards\n",
    "predicted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14159313",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "667703b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_csv('/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Interns_2023/user/JiQing/TCGA_model/Multimodal/predicted_hazards_Multimodal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def93e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
